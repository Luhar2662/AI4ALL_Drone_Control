{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auBwOusIB9lp"
      },
      "source": [
        "Previous Code: Drone Controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCom1TgKCNpN"
      },
      "outputs": [],
      "source": [
        "group_number = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "5F_QYVQ3CNWH",
        "outputId": "99490f1c-ce68-4178-a380-594413ecc65a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cflib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1547373926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrazyflie\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrazyflie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrazyflie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cflib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# This is an example from the Crazyflie Python API.\n",
        "# See https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/basiclogSync.py\n",
        "\n",
        "import logging\n",
        "import time\n",
        "\n",
        "import cflib.crtp\n",
        "from cflib.crazyflie import Crazyflie\n",
        "from cflib.crazyflie.log import LogConfig\n",
        "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
        "from cflib.crazyflie.syncLogger import SyncLogger\n",
        "\n",
        "# Only output errors from the logging framework\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "\n",
        "# Initialize the low-level drivers (don't list the debug drivers)\n",
        "cflib.crtp.init_drivers(enable_debug_driver=False)\n",
        "# Scan for Crazyflies and use the first one found\n",
        "print('Scanning interfaces for Crazyflies...')\n",
        "available = cflib.crtp.scan_interfaces()\n",
        "print('Crazyflies found:')\n",
        "for i in available:\n",
        "    print(i[0])\n",
        "\n",
        "if len(available) == 0:\n",
        "    print('No Crazyflies found, cannot run example')\n",
        "else:\n",
        "    lg_stab = LogConfig(name='Stabilizer', period_in_ms=10)\n",
        "    lg_stab.add_variable('stabilizer.roll', 'float')\n",
        "    lg_stab.add_variable('stabilizer.pitch', 'float')\n",
        "    lg_stab.add_variable('stabilizer.yaw', 'float')\n",
        "\n",
        "    cf = Crazyflie(rw_cache='./cache')\n",
        "    with SyncCrazyflie(available[0][0], cf=cf) as scf:\n",
        "        with SyncLogger(scf, lg_stab) as logger:\n",
        "            endTime = time.time() + 10\n",
        "\n",
        "            for log_entry in logger:\n",
        "                timestamp = log_entry[0]\n",
        "                data = log_entry[1]\n",
        "                logconf_name = log_entry[2]\n",
        "\n",
        "                print('[%d][%s]: %s' % (timestamp, logconf_name, data))\n",
        "\n",
        "                if time.time() > endTime:\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAtJoPaBBzwI"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Code adapted from: https://github.com/bitcraze/crazyflie-lib-python/blob/master/examples/autonomousSequence.py\n",
        "\n",
        "import time\n",
        "# CrazyFlie imports:\n",
        "import cflib.crtp\n",
        "from cflib.crazyflie import Crazyflie\n",
        "from cflib.crazyflie.log import LogConfig\n",
        "from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n",
        "from cflib.crazyflie.syncLogger import SyncLogger\n",
        "\n",
        "## Some helper control functions:\n",
        "## -----------------------------------------------------------------------------------------\n",
        "\n",
        "# Determine initial position:\n",
        "def wait_for_position_estimator(scf):\n",
        "    print('Waiting for estimator to find position...')\n",
        "\n",
        "    log_config = LogConfig(name='Kalman Variance', period_in_ms=500)\n",
        "    log_config.add_variable('kalman.varPX', 'float')\n",
        "    log_config.add_variable('kalman.varPY', 'float')\n",
        "    log_config.add_variable('kalman.varPZ', 'float')\n",
        "\n",
        "    var_y_history = [1000] * 10\n",
        "    var_x_history = [1000] * 10\n",
        "    var_z_history = [1000] * 10\n",
        "\n",
        "    threshold = 0.001\n",
        "    with SyncLogger(scf, log_config) as logger:\n",
        "        for log_entry in logger:\n",
        "            data = log_entry[1]\n",
        "\n",
        "            var_x_history.append(data['kalman.varPX'])\n",
        "            var_x_history.pop(0)\n",
        "            var_y_history.append(data['kalman.varPY'])\n",
        "            var_y_history.pop(0)\n",
        "            var_z_history.append(data['kalman.varPZ'])\n",
        "            var_z_history.pop(0)\n",
        "\n",
        "            min_x = min(var_x_history)\n",
        "            max_x = max(var_x_history)\n",
        "            min_y = min(var_y_history)\n",
        "            max_y = max(var_y_history)\n",
        "            min_z = min(var_z_history)\n",
        "            max_z = max(var_z_history)\n",
        "\n",
        "            print(\"{} {} {}\".\n",
        "                format(max_x - min_x, max_y - min_y, max_z - min_z))\n",
        "\n",
        "            if (max_x - min_x) < threshold and (\n",
        "                    max_y - min_y) < threshold and (\n",
        "                    max_z - min_z) < threshold:\n",
        "                break\n",
        "\n",
        "# Initialize controller:\n",
        "def set_PID_controller(cf):\n",
        "    # Set the PID Controller:\n",
        "    print('Initializing PID Controller')\n",
        "    cf.param.set_value('stabilizer.controller', '1')\n",
        "    cf.param.set_value('kalman.resetEstimation', '1')\n",
        "    time.sleep(0.1)\n",
        "    cf.param.set_value('kalman.resetEstimation', '0')\n",
        "\n",
        "    wait_for_position_estimator(cf)\n",
        "    time.sleep(0.1)\n",
        "    return\n",
        "\n",
        "# Ascend and hover:\n",
        "def ascend_and_hover(cf):\n",
        "    # Ascend -- warmup drone:\n",
        "    for y in range(20):\n",
        "        cf.commander.send_hover_setpoint(0, 0, 0, y / 50)\n",
        "        time.sleep(0.1)\n",
        "    # Hover at 0.5 meters:\n",
        "    for _ in range(30):\n",
        "        #TODO: write the command to hover at .5 meters\n",
        "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
        "        time.sleep(0.1)\n",
        "    return\n",
        "\n",
        "# Follow the setpoint sequence trajectory:\n",
        "def run_sequence(scf, sequence, setpoint_delay):\n",
        "    cf = scf.cf\n",
        "    # TODO: write the for loop that loops over positions in the sequence\n",
        "    for position in sequence:\n",
        "        print(f'Setting position {(position[0], (position[1]))}')\n",
        "        # \"setpoint delay\" is a parameter to give the drone time to reach the set point\n",
        "        for i in range(setpoint_delay):\n",
        "            cf.commander.send_position_setpoint(position[0],\n",
        "                                                (position[1]),\n",
        "                                                0.5,\n",
        "                                                0.0)\n",
        "            time.sleep(0.1)\n",
        "\n",
        "# Hover, descend, and stop all motion:\n",
        "def hover_and_descend(cf):\n",
        "    # Hover at 0.5 meters:\n",
        "    for _ in range(30):\n",
        "        cf.commander.send_hover_setpoint(0, 0, 0, 0.5)\n",
        "        time.sleep(0.1)\n",
        "    # Descend:\n",
        "    for y in range(10):\n",
        "        cf.commander.send_hover_setpoint(0, 0, 0, (10 - y) / 25)\n",
        "        time.sleep(0.1)\n",
        "    # Stop all motion:\n",
        "    for i in range(10):\n",
        "        cf.commander.send_stop_setpoint()\n",
        "        time.sleep(0.1)\n",
        "    return\n",
        "\n",
        "def run_setpoint_trajectory(group_number, sequence):\n",
        "    # This is the main function to enable the drone to follow the trajectory.\n",
        "\n",
        "    # User inputs:\n",
        "    #\n",
        "    # - group_number: (int) the number corresponding to the drone radio settings.\n",
        "    #\n",
        "    # - sequence: a series of point locations (float) defined as a numpy array, with each row in the following format:\n",
        "    #     [x(meters), y(meters)]\n",
        "    #   Note: the input should be given in drone coordinates (where positive x is forward, and positive y is to the left).\n",
        "    # Example:\n",
        "    # sequence = [\n",
        "    #     [[ 0.          0.        ]\n",
        "    #      [0.18134891  0.08433607]]\n",
        "    #\n",
        "\n",
        "    # Outputs:\n",
        "    # None.\n",
        "\n",
        "    setpoint_delay = 3  # Number of 0.1s steps to spend at each setpoint\n",
        "\n",
        "    # Set the URI the Crazyflie will connect to\n",
        "    uri = f\"radio://0/{group_number}/2M\"\n",
        "\n",
        "    # Initialize Crazyflie radio drivers\n",
        "    cflib.crtp.init_drivers(enable_debug_driver=False)\n",
        "\n",
        "    # Connect to the drone and run the control loop\n",
        "    with SyncCrazyflie(uri, cf=Crazyflie(rw_cache='./cache')) as scf:\n",
        "        cf = scf.cf\n",
        "\n",
        "        # Initialize the PID controller and Kalman estimator\n",
        "        set_PID_controller(cf)\n",
        "\n",
        "        # TODO: Ascend to safe height before moving\n",
        "        ascend_and_hover(cf)\n",
        "\n",
        "        # TODO: Run the sequence of setpoints\n",
        "        run_sequence(scf, sequence, setpoint_delay)\n",
        "\n",
        "        # TODO: Descend and stop all motion\n",
        "        hover_and_descend(cf)\n",
        "\n",
        "    print(\"Done!\")\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PThgAlHsCMA5"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "class Drone_Controller:\n",
        "\n",
        "  def __init__(self, grid_width, rows, cols, group_number):\n",
        "      self.grid_width = grid_width\n",
        "      self.rows = rows\n",
        "      self.cols = cols\n",
        "      self.position = np.array([0,0])\n",
        "      self.group_number = group_number\n",
        "\n",
        "  def discretize_move(self, action, start_point, segments):\n",
        "\n",
        "    move_seq = np.zeros((segments+1,2))\n",
        "    cur = start_point\n",
        "    move_seq[0] = cur\n",
        "    increment = self.grid_width / segments\n",
        "\n",
        "    #TODO -- implement our discretizing strategy on a move!\n",
        "    # HINT: going \"up\" means positive in the x-value, \"left\" is positive in the y-value\n",
        "    #       Think about the Right hand rule!\n",
        "\n",
        "    if action == \"up\":\n",
        "      for i in range(1, segments + 1):\n",
        "        move_seq[i,0] = move_seq[i-1,0] + increment\n",
        "        move_seq[i,1] = move_seq[i-1,1]\n",
        "\n",
        "    elif action == \"down\":\n",
        "      for i in range(1, segments + 1):\n",
        "        move_seq[i,0] = move_seq[i-1,0] - increment\n",
        "        move_seq[i,1] = move_seq[i-1,1]\n",
        "\n",
        "    elif action == \"left\":\n",
        "      for i in range(1, segments + 1):\n",
        "        move_seq[i,0] = move_seq[i-1,0]\n",
        "        move_seq[i,1] = move_seq[i-1,1] + increment\n",
        "\n",
        "    elif action == \"right\":\n",
        "      for i in range(1, segments + 1):\n",
        "        move_seq[i,0] = move_seq[i-1,0]\n",
        "        move_seq[i,1] = move_seq[i-1,1] - increment\n",
        "    print(\"adding, \", move_seq)\n",
        "    return move_seq\n",
        "\n",
        "\n",
        "  def convert_traj_to_setpoint(self, policy, start, goal, segments, drone_init_pos):\n",
        "      \"\"\"\n",
        "      Converts a list of actions (up/down/left/right) into a sequence of setpoints.\n",
        "\n",
        "      Parameters:\n",
        "      - policy: policy recovered by QLearning\n",
        "      - start: grid position of start in the GridWorld, (x,y)\n",
        "      - goal: grid position of the end in the GridWorld, (x,y)\n",
        "      - segments: the amount by which we discretize each move\n",
        "      - drone_init_pos: the literal start point of the drone, usually (0,0)\n",
        "\n",
        "      \"\"\"\n",
        "      # TODO: make a trajectory and find a list of actions using trajectory.step()\n",
        "      trajectory = Trajectory(policy)\n",
        "      actions = trajectory.step(start, goal)\n",
        "\n",
        "      #initialize setpoints\n",
        "      setpoints = np.array(drone_init_pos).reshape((1,2))\n",
        "\n",
        "      # TODO: loop through the actions in our list, and calculate the next set of\n",
        "      #       setpoints. Add them to our setpoints using np.concatenate((array 1, array 2), axis = 0)\n",
        "      # HINT: we need to make sure we start each new setpoint from our last known position.\n",
        "      #       using the index [-1] gets us to the end of a list...\n",
        "      for a in actions:\n",
        "        print(\"calling disc move for action: \", a, \", from setpoint: \", setpoints[-1])\n",
        "        next_seg = self.discretize_move(a, setpoints[-1],segments)\n",
        "        setpoints = np.concatenate((setpoints, next_seg), axis = 0)\n",
        "\n",
        "      return setpoints\n",
        "\n",
        "  def convert_actions_to_setpoint(self, actions, segments, drone_init_pos):\n",
        "      setpoints = np.array(drone_init_pos).reshape((1,2))\n",
        "\n",
        "      # TODO: loop through the actions in our list, and calculate the next set of\n",
        "      #       setpoints. Add them to our setpoints using np.concatenate((array 1, array 2), axis = 0)\n",
        "      # HINT: we need to make sure we start each new setpoint from our last known position.\n",
        "      #       using the index [-1] gets us to the end of a list...\n",
        "\n",
        "      for a in actions:\n",
        "        print(\"calling disc move for action: \", a, \", from setpoint: \", setpoints[-1])\n",
        "        next_seg = self.discretize_move(a, setpoints[-1],segments)\n",
        "        setpoints = np.concatenate((setpoints, next_seg), axis = 0)\n",
        "\n",
        "      return setpoints\n",
        "\n",
        "\n",
        "  def execute_sequence(self, sequence):\n",
        "    run_setpoint_trajectory(self.group_number, sequence)\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUQwZcImCYx6"
      },
      "source": [
        "Previous Code for Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_26Rci1TChmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cd6d75-ae93-47b2-ac84-1fcb85b78069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting celluloid\n",
            "  Downloading celluloid-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from celluloid) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->celluloid) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->celluloid) (1.17.0)\n",
            "Downloading celluloid-0.2.0-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: celluloid\n",
            "Successfully installed celluloid-0.2.0\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from typing import Tuple\n",
        "%pip install celluloid\n",
        "from celluloid import Camera # getting the camera\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.colors import TwoSlopeNorm, Normalize\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "### Visualization Tools ###\n",
        "\n",
        "### Visualization Tools ###\n",
        "\n",
        "class Move_anim:\n",
        "    \"\"\"\n",
        "    This class provides functionality for visualizing the motion of a trained\n",
        "    agent in real-time using matplotlib and a camera-like snapshot tool.\n",
        "\n",
        "    Args:\n",
        "        ax_obj (matplotlib axis): The axis to draw the animation on.\n",
        "        cam_obj (camera object): The camera used to capture frames (e.g., celluloid).\n",
        "        obs (list or np.ndarray): List of obstacle coordinates.\n",
        "        goal (list or np.ndarray): Goal coordinate.\n",
        "        bounds (list): Boundary coordinates.\n",
        "        grid_size (float): Size of each grid cell in the animation.\n",
        "        T (float): Time to animate a single move.\n",
        "        invert (bool): Whether to swap row/col in coordinate conversion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ax_obj, cam_obj, obs, goal, bounds, grid_size=1, T=1, invert=False):\n",
        "        self.move_time = T\n",
        "        self.grid_size = grid_size\n",
        "        self.ax = ax_obj\n",
        "        self.camera = cam_obj\n",
        "        self.invert = invert\n",
        "        self._legend_drawn = False\n",
        "\n",
        "        # Ensure obs and goal are numpy arrays\n",
        "        self.obs = np.array(obs) if not isinstance(obs, np.ndarray) else obs\n",
        "        self.goal = np.array(goal) if not isinstance(goal, np.ndarray) else goal\n",
        "        self.bounds = bounds\n",
        "\n",
        "\n",
        "    def right(self, x, y):\n",
        "        \"Animate a rightward move\"\n",
        "        for i in range(int(self.move_time * 10)):\n",
        "            x += self.grid_size / (10 * self.move_time)\n",
        "            self.ax.scatter(x, y, c='black', edgecolors='white', s=120, marker='o')\n",
        "            self.show_obs()\n",
        "            self.camera.snap()\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def left(self, x, y):\n",
        "        \"Animate a leftward move\"\n",
        "        for i in range(int(self.move_time * 10)):\n",
        "            x -= self.grid_size / (10 * self.move_time)\n",
        "            self.ax.scatter(x, y, c='black', edgecolors='white', s=120, marker='o')\n",
        "            self.show_obs()\n",
        "            self.camera.snap()\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def up(self, x, y):\n",
        "        \"Animate an upward move\"\n",
        "        for i in range(int(self.move_time * 10)):\n",
        "            y -= self.grid_size / (10 * self.move_time)\n",
        "            self.ax.scatter(x, y, c='black', edgecolors='white', s=120, marker='o')\n",
        "            self.show_obs()\n",
        "            self.camera.snap()\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def down(self, x, y):\n",
        "        \"Animate a downward move\"\n",
        "        for i in range(int(self.move_time * 10)):\n",
        "            y += self.grid_size / (10 * self.move_time)\n",
        "            self.ax.scatter(x, y, c='black', edgecolors='white', s=120, marker='o')\n",
        "            self.show_obs()\n",
        "            self.camera.snap()\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def show_obs(self):\n",
        "        \"Show all static objects: obstacles, boundaries, and goal\"\n",
        "        def adapt_coords(pos):\n",
        "            row, col = pos\n",
        "            return (col + 0.5, row + 0.5) if self.invert else (row + 0.5, col + 0.5)\n",
        "\n",
        "        # Draw obstacles (red x)\n",
        "        for pos in self.obs:\n",
        "            x, y = adapt_coords(pos)\n",
        "            self.ax.scatter(x, y, c='red', marker='x', s=100)\n",
        "\n",
        "        # Draw boundaries (black x)\n",
        "        for pos in self.bounds:\n",
        "            x, y = adapt_coords(pos)\n",
        "            self.ax.scatter(x, y, c='black', marker='x', s=100)\n",
        "\n",
        "        # Draw goal (green star)\n",
        "        gx, gy = adapt_coords(self.goal)\n",
        "        self.ax.scatter(gx, gy, c='green', marker='*', s=200)\n",
        "\n",
        "        # Draw legend once\n",
        "        if not self._legend_drawn:\n",
        "            self.ax.scatter([], [], c='red', marker='x', s=100, label='Obstacle')\n",
        "            self.ax.scatter([], [], c='black', marker='x', s=100, label='Boundary')\n",
        "            self.ax.scatter([], [], c='green', marker='*', s=200, label='Goal')\n",
        "            self.ax.scatter([], [], c='black', edgecolors='white', s=120, marker='o', label='Agent')\n",
        "            self._legend_drawn = True\n",
        "\n",
        "    # Execute and animate a full trajectory from (cur_x, cur_y)\n",
        "    def execute_traj(self, traj, cur_x, cur_y):\n",
        "        # Optionally swap row and col based on display preference\n",
        "        if self.invert:\n",
        "            cur_x, cur_y = cur_y, cur_x\n",
        "\n",
        "        # Offset to center agent in the middle of a grid cell\n",
        "        x = cur_x + 0.5\n",
        "        y = cur_y + 0.5\n",
        "\n",
        "        # Move the agent step-by-step based on the trajectory list\n",
        "        for move in traj:\n",
        "            if move == \"right\":\n",
        "                x, y = self.right(x, y)\n",
        "            elif move == \"left\":\n",
        "                x, y = self.left(x, y)\n",
        "            elif move == \"up\":\n",
        "                x, y = self.up(x, y)\n",
        "            elif move == \"down\":\n",
        "                x, y = self.down(x, y)\n",
        "            else:\n",
        "                # No move (could handle invalid move here)\n",
        "                x, y = x, y\n",
        "\n",
        "        # Show legend after the full trajectory is played\n",
        "        self.ax.legend(loc='upper right', fontsize=10)\n",
        "\n",
        "\n",
        "\n",
        "### Method for visualizing q-table with directions corresponding to optimal actions for each state ###\n",
        "\n",
        "def draw_q_grid(q_table, env, scale=1.5, actions=[\"stay\", \"up\", \"down\", \"left\", \"right\"], focus_center=None, focus_size=3):\n",
        "    \"\"\"\n",
        "    Visualizes the Q-values of a grid-based environment using directional arrows and color-coded heatmaps.\n",
        "\n",
        "    Args:\n",
        "        q_table (dict): A dictionary with keys as (state, action) pairs and values as Q-values.\n",
        "        env (GridWorld): The grid environment (used for size and boundary info).\n",
        "        scale (float): Controls the visual scaling of the plot.\n",
        "        actions (list): List of action names corresponding to Q-values.\n",
        "        focus_center (tuple): Optional (x, y) center to zoom into a subsection of the grid.\n",
        "        focus_size (int): Size of the subsection to show if using focus_center.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Determine region to visualize ===\n",
        "    if focus_center:\n",
        "        cx, cy = focus_center\n",
        "        half = focus_size // 2\n",
        "        row_range = range(max(0, cy - half), min(env.rows, cy + half + 1))\n",
        "        col_range = range(max(0, cx - half), min(env.cols, cx + half + 1))\n",
        "    else:\n",
        "        row_range = range(env.rows)\n",
        "        col_range = range(env.cols)\n",
        "\n",
        "    # Arrow offsets for directional visualization\n",
        "    dx, dy = 0.25, 0.25\n",
        "    arrow_dict = {\"U\": (0, -dy), \"D\": (0, dy), \"L\": (-dx, 0), \"R\": (dx, 0)}\n",
        "\n",
        "    # === Initialize plot ===\n",
        "    fig, ax = plt.subplots(figsize=(len(col_range) * scale, len(row_range) * scale))\n",
        "    ax.set_xlim(0, len(col_range))\n",
        "    ax.set_ylim(0, len(row_range))\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xticks(np.arange(0, len(col_range)+1, 1))\n",
        "    ax.set_yticks(np.arange(0, len(row_range)+1, 1))\n",
        "    ax.invert_yaxis()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # === Normalize Q-values for color mapping ===\n",
        "    all_q_vals = [v for (_, v) in q_table.items()]\n",
        "    min_q = min(all_q_vals) if all_q_vals else -1\n",
        "    max_q = max(all_q_vals) if all_q_vals else 1\n",
        "    if min_q < 0 and max_q > 0:\n",
        "        norm = TwoSlopeNorm(vmin=min_q, vcenter=0, vmax=max_q)\n",
        "    else:\n",
        "        norm = Normalize(vmin=min_q, vmax=max_q)\n",
        "    cmap = plt.cm.bwr  # Blue-White-Red colormap\n",
        "\n",
        "    # === Iterate over grid cells ===\n",
        "    for i, row in enumerate(row_range):\n",
        "        for j, col in enumerate(col_range):\n",
        "            state = (row, col)\n",
        "\n",
        "            # Get Q-values for each action at this state\n",
        "            q_stay  = q_table.get((state, \"stay\"), 0)\n",
        "            q_up    = q_table.get((state, \"up\"), 0)\n",
        "            q_down  = q_table.get((state, \"down\"), 0)\n",
        "            q_left  = q_table.get((state, \"left\"), 0)\n",
        "            q_right = q_table.get((state, \"right\"), 0)\n",
        "\n",
        "            # Cell center coordinates\n",
        "            x, y = j, i\n",
        "            cx, cy = x + 0.5, y + 0.5\n",
        "\n",
        "            # Identify boundaries\n",
        "            px, py = state\n",
        "            boundary = px == 0 or px == env.rows - 1 or py == 0 or py == env.cols - 1\n",
        "\n",
        "            # === Drawing helper functions ===\n",
        "            def draw_triangle(points, q_val):\n",
        "                color = 'black' if boundary else cmap(norm(q_val))\n",
        "                triangle = patches.Polygon(points, closed=True, facecolor=color, edgecolor='black', alpha=0.85)\n",
        "                ax.add_patch(triangle)\n",
        "\n",
        "            def draw_square(origin):\n",
        "                square = patches.Rectangle(origin, width=1, height=1, facecolor='black', edgecolor='black', alpha=1.0)\n",
        "                ax.add_patch(square)\n",
        "\n",
        "            def draw_stay_circle(center, q_val, radius=0.1):\n",
        "                color = 'black' if (0 in state) or (env.cols-1 in state) else cmap(norm(q_val))\n",
        "                circle = patches.Circle(center, radius, facecolor=color, edgecolor='black', alpha=0.9)\n",
        "                ax.add_patch(circle)\n",
        "\n",
        "            # === Render cell ===\n",
        "            if boundary:\n",
        "                draw_square((x, y))\n",
        "            else:\n",
        "                # Draw directional triangles for each action\n",
        "                draw_triangle([(x, y), (x+1, y), (cx, cy)], q_up)\n",
        "                draw_triangle([(x, y+1), (x+1, y+1), (cx, cy)], q_down)\n",
        "                draw_triangle([(x, y), (x, y+1), (cx, cy)], q_left)\n",
        "                draw_triangle([(x+1, y), (x+1, y+1), (cx, cy)], q_right)\n",
        "\n",
        "                # Draw circle for 'stay' action\n",
        "                draw_stay_circle((cx, cy), q_stay)\n",
        "\n",
        "                # Determine best action and annotate with direction\n",
        "                q_vals = [q_stay, q_up, q_down, q_left, q_right]\n",
        "                best_action = actions[np.argmax(q_vals)]\n",
        "                direction = best_action[0].upper()\n",
        "                ax.text(cx, cy, direction, ha='center', va='center', fontsize=10, color='black')\n",
        "\n",
        "                # Optional: draw directional arrow\n",
        "                if direction in arrow_dict:\n",
        "                    dx, dy = arrow_dict[direction]\n",
        "                    ax.arrow(cx, cy, dx, dy, width=0.006)\n",
        "\n",
        "    # === Add colorbar ===\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])  # Required for colorbar to work\n",
        "    cbar = plt.colorbar(sm, ax=ax)\n",
        "    cbar.set_label(\"Q-Value\")\n",
        "\n",
        "    # Final formatting\n",
        "    plt.title(\"Q-Value Heatmap\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9z08n06CipE"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "class Trajectory:\n",
        "  \"\"\"\n",
        "  This class provides functionality for extracting or rolling\n",
        "  out optimal trajectory from learned policy.\n",
        "\n",
        "  Args:\n",
        "      policy (dict): A dictionary with keys as state tuples and action strings as values.\n",
        "      action_step (dict): A dictionary with keys as action strings and values as step tuples\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,policy):\n",
        "    self.policy = policy\n",
        "    self.action_step = {\n",
        "        \"up\":(-1,0),\n",
        "        \"down\":(1,0),\n",
        "        \"right\":(0,1),\n",
        "        \"left\":(0,-1),\n",
        "        \"stay\":(0,0)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "  def step(self, start_pos, goal_pos):\n",
        "    \"Recieves starting postion and goal position returns optimal action sequence\"\n",
        "    position = start_pos\n",
        "    actions = []\n",
        "    while not (position == goal):\n",
        "      action = self.policy.get(position)\n",
        "      actions.append(action)\n",
        "      print(action)\n",
        "      step = self.action_step.get(action)\n",
        "      position = tuple(map(sum,zip(position, step)))\n",
        "    return actions\n",
        "\n",
        "#Setup MDP problem\n",
        "\n",
        "\n",
        "\n",
        "### === Environment: GridWorld === ###\n",
        "class GridWorld:\n",
        "    \"\"\"\n",
        "    A 2D grid environment for reinforcement learning.\n",
        "    Supports goal states, obstacles, boundaries, and rewards.\n",
        "    \"\"\"\n",
        "    def __init__(self, obs: dict, goal: dict, rows: int, cols: int,\n",
        "                 bound_cost: float = -1.0, episode_steps: int = 100):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.bound_cost = bound_cost\n",
        "        self.episode_steps = episode_steps\n",
        "\n",
        "        # Default penalty for moving into free cells\n",
        "        self.empty_cost = -0.01\n",
        "        self.obstacle_cost = -0.8\n",
        "        self.goal_reward = 1.0\n",
        "\n",
        "        # Initialize grid with step penalty\n",
        "        self.grid = np.full((rows, cols), self.empty_cost)\n",
        "        self.map_grid = np.full((rows, cols), 0)\n",
        "\n",
        "        # Place obstacles\n",
        "        for (r, c), val in obs.items():\n",
        "            self.grid[r, c] = self.obstacle_cost\n",
        "            self.map_grid[r, c] = -1\n",
        "\n",
        "        # Place goals\n",
        "        for (r, c), val in goal.items():\n",
        "            self.grid[r, c] = self.goal_reward\n",
        "            self.map_grid[r, c] = 1\n",
        "\n",
        "        # Set outer boundaries\n",
        "        self._set_boundaries()\n",
        "\n",
        "        # Cache positions\n",
        "        self._cache_positions()\n",
        "\n",
        "    def _set_boundaries(self):\n",
        "        self.grid[0, :] = self.bound_cost\n",
        "        self.grid[-1, :] = self.bound_cost\n",
        "        self.grid[:, 0] = self.bound_cost\n",
        "        self.grid[:, -1] = self.bound_cost\n",
        "\n",
        "        self.map_grid[0, :] = -1\n",
        "        self.map_grid[-1, :] = -1\n",
        "        self.map_grid[:, 0] = -1\n",
        "        self.map_grid[:, -1] = -1\n",
        "\n",
        "    def _cache_positions(self):\n",
        "        self.goal_positions = list(zip(*np.where(self.grid == self.goal_reward)))\n",
        "        self.obstacle_positions = list(zip(*np.where(self.grid == self.obstacle_cost)))\n",
        "        self.bound_positions = list(zip(*np.where(self.grid == self.bound_cost)))\n",
        "\n",
        "    def get_reward(self, position):\n",
        "        \"\"\"Return the reward value at a given (row, col) position.\"\"\"\n",
        "        row, col = position\n",
        "        return self.grid[row, col]\n",
        "\n",
        "    def reset_random(self, num_obs, goal_pos):\n",
        "        # Reset grid\n",
        "        self.grid = np.full((self.rows, self.cols), self.empty_cost)\n",
        "        self.map_grid = np.full((self.rows, self.cols), 0)\n",
        "\n",
        "        # Set boundaries\n",
        "        self._set_boundaries()\n",
        "\n",
        "        # Place random obstacles\n",
        "        obs_list = [[random.randint(1, self.rows - 2), random.randint(1, self.cols - 2)]\n",
        "                    for _ in range(num_obs)]\n",
        "        for r, c in obs_list:\n",
        "            self.grid[r, c] = self.obstacle_cost\n",
        "            self.map_grid[r, c] = -1\n",
        "\n",
        "        # Place goal\n",
        "        self.grid[goal_pos[0], goal_pos[1]] = self.goal_reward\n",
        "        self.map_grid[goal_pos[0], goal_pos[1]] = 1\n",
        "\n",
        "        # Update goal positions cache\n",
        "        self.goal_positions = [goal_pos]\n",
        "\n",
        "        self._cache_positions()\n",
        "\n",
        "    def is_terminal(self, position):\n",
        "        \"\"\"Check if a state is a terminal (goal) state.\"\"\"\n",
        "        return (position in self.goal_positions)\n",
        "\n",
        "\n",
        "\n",
        "### === Agent === ###\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Grid-based agent that can move in 4 directions or stay in place.\n",
        "    \"\"\"\n",
        "    def __init__(self, action_space=[\"stay\", \"up\", \"down\", \"left\", \"right\"]):\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def reset(self, start_pos):\n",
        "        \"\"\"Reset agent to a starting position.\"\"\"\n",
        "        self.position = start_pos\n",
        "\n",
        "    def move(self, action, env: GridWorld):\n",
        "        \"\"\"\n",
        "        Move the agent based on the chosen action, considering environment boundaries.\n",
        "        \"\"\"\n",
        "        row, col = self.position\n",
        "        if action == \"up\" and row > 0:\n",
        "            row -= 1\n",
        "        elif action == \"down\" and row < env.rows - 1:\n",
        "            row += 1\n",
        "        elif action == \"left\" and col > 0:\n",
        "            col -= 1\n",
        "        elif action == \"right\" and col < env.cols - 1:\n",
        "            col += 1\n",
        "        # \"stay\" does nothing\n",
        "        self.position = (row, col)\n",
        "        return self.position\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FDa9CXC5uZ"
      },
      "source": [
        "#Deep Q-Networks (DQN) in Gridworld\n",
        "In this notebook, we extend your understanding of Q-learning by applying it to more complex state representations using neural networks. Tabular Q-learning works well for small, discrete state spaces, but what if your state includes partial observability, local vision, or continuous values?\n",
        "\n",
        "That's where Deep Q-Networks (DQN) come in.\n",
        "\n",
        "ğŸ§© What You'll Build --> A neural network that estimates Q-values directly from features like:\n",
        "\n",
        "- A local grid patch around the agent (to simulate limited perception)\n",
        "\n",
        "- The normalized positions of the agent and the goal\n",
        "\n",
        "- A replay buffer to store past experiences and train the agent more stably\n",
        "\n",
        "- A target network to improve training stability and reduce overestimation\n",
        "\n",
        "- An epsilon-greedy strategy to balance exploration vs. exploitation\n",
        "\n",
        "ğŸ” Key Concepts Covered\n",
        "\n",
        "- State encoding: Convert your local surroundings and positions into a vector\n",
        "\n",
        "- Q-function approximation: Replace the Q-table with a fully connected neural network\n",
        "\n",
        "- Experience replay: Randomly sample past transitions to break correlations\n",
        "\n",
        "- Target networks: Use a separate network for stable target value estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0i-LhkNtXTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71835207-0c2c-4dcb-d028-2d222eee1235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cEFP9CoEgzG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "def encode_local_state(agent_pos, goal_pos, grid, obs_range=1):\n",
        "    rows, cols = grid.shape\n",
        "    r, c = agent_pos\n",
        "\n",
        "    r_start = max(0, r - obs_range)\n",
        "    r_end   = min(rows, r + obs_range + 1)\n",
        "    c_start = max(0, c - obs_range)\n",
        "    c_end   = min(cols, c + obs_range + 1)\n",
        "\n",
        "    local = grid[r_start:r_end, c_start:c_end].copy()\n",
        "\n",
        "    padded_local = np.full((2*obs_range + 1, 2*obs_range + 1), -1.0, dtype=np.float32)\n",
        "    p_r_start = obs_range - (r - r_start)\n",
        "    p_r_end   = p_r_start + (r_end - r_start)\n",
        "    p_c_start = obs_range - (c - c_start)\n",
        "    p_c_end   = p_c_start + (c_end - c_start)\n",
        "    padded_local[p_r_start:p_r_end, p_c_start:p_c_end] = local\n",
        "\n",
        "    local_flat = padded_local.flatten()\n",
        "\n",
        "    agent_norm = [r / rows, c / cols]\n",
        "    goal_r, goal_c = goal_pos\n",
        "    goal_norm = [goal_r / rows, goal_c / cols]\n",
        "\n",
        "    state_vector = np.concatenate([local_flat, agent_norm, goal_norm]).astype(np.float32)\n",
        "    return state_vector\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BATCH_SIZE   = 128\n",
        "GAMMA        = 0.99\n",
        "EPS_START    = 0.9\n",
        "EPS_END      = 0.1\n",
        "EPS_DECAY    = 7000          # step-based exponential decay denominator\n",
        "TAU          = 0.005         # soft target update rate\n",
        "LR           = 3e-4          # AdamW learning rate\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size: int):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, n_observations: int, n_actions: int):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(n_observations, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, n_actions),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "def select_action(state, policy_net, n_actions):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1.0 * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1).indices.view(1, 1)   # greedy\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "def optimize_model(policy_net, target_net, memory, optimizer):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return None\n",
        "\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # final states are stored as None\n",
        "    non_final_mask = torch.tensor(tuple(s is not None for s in batch.next_state),\n",
        "                                  device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None], dim=0)\n",
        "\n",
        "    state_batch  = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Q(s_t, a)\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # V(s_{t+1})\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
        "\n",
        "    # expected Q\n",
        "    expected_state_action_values = reward_batch + (GAMMA * next_state_values)\n",
        "    expected_state_action_values = expected_state_action_values.unsqueeze(1)\n",
        "\n",
        "    criterion = nn.SmoothL1Loss()  # Huber\n",
        "    loss = criterion(state_action_values, expected_state_action_values)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "\n",
        "def run_training(env, agent, obs_range=2, num_episodes=600, memory_capacity=1000):\n",
        "    \"\"\"\n",
        "    Training loop for DQN on GridWorld:\n",
        "    - Terminal state or hitting env.episode_steps ends an episode.\n",
        "    - Reward shaping with Manhattan distance bonus.\n",
        "    - Reward clipping to [-1, 1] for stable Q-learning.\n",
        "    \"\"\"\n",
        "    actions = agent.action_space\n",
        "    n_actions = len(actions)\n",
        "\n",
        "    # Observation size\n",
        "    start_pos = (random.randint(1, env.rows - 2), random.randint(1, env.cols - 2))\n",
        "    agent.reset(start_pos)\n",
        "    dummy_state = encode_local_state(agent.position, env.goal_positions[0], env.map_grid, obs_range)\n",
        "    n_observations = dummy_state.shape[0]\n",
        "\n",
        "    policy_net = DQN(n_observations, n_actions).to(device)\n",
        "    target_net = DQN(n_observations, n_actions).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "    memory = ReplayMemory(memory_capacity)\n",
        "\n",
        "    episode_returns, episode_losses = [], []\n",
        "\n",
        "    for i_episode in range(num_episodes):\n",
        "        # Reset environment\n",
        "        start_pos = (random.randint(1, env.rows - 2), random.randint(1, env.cols - 2))\n",
        "        env.reset_random(num_obs=6, goal_pos=env.goal_positions[0])\n",
        "        agent.reset(start_pos)\n",
        "\n",
        "        # Build initial state\n",
        "        s = encode_local_state(agent.position, env.goal_positions[0], env.map_grid, obs_range)\n",
        "        state = torch.from_numpy(s).float().unsqueeze(0).to(device)\n",
        "\n",
        "        ep_return, losses = 0.0, []\n",
        "        prev_dist = abs(agent.position[0] - env.goal_positions[0][0]) + abs(agent.position[1] - env.goal_positions[0][1])\n",
        "\n",
        "        # Episode loop\n",
        "        for t in range(env.episode_steps):\n",
        "            action_tensor = select_action(state, policy_net, n_actions)\n",
        "            a_idx = action_tensor.item()\n",
        "            a_str = actions[a_idx]\n",
        "\n",
        "            # Environment step\n",
        "            next_pos = agent.move(a_str, env)\n",
        "            reward_val = env.get_reward(next_pos)\n",
        "            done = env.is_terminal(next_pos)\n",
        "\n",
        "            # Reward shaping with Manhattan distance bonus\n",
        "            new_dist = abs(next_pos[0] - env.goal_positions[0][0]) + abs(next_pos[1] - env.goal_positions[0][1])\n",
        "            shaping_bonus = 0.25 * (prev_dist - new_dist)  # positive if moving closer\n",
        "            reward_val += shaping_bonus\n",
        "            prev_dist = new_dist\n",
        "\n",
        "            # Reward clipping\n",
        "            #reward_val = np.clip(reward_val, -1.0, 1.0) not needed since rewards are manageable\n",
        "            reward = torch.tensor([reward_val], device=device, dtype=torch.float32)\n",
        "\n",
        "            # Next state\n",
        "            if not done:\n",
        "                s_next = encode_local_state(agent.position, env.goal_positions[0], env.map_grid, obs_range)\n",
        "                next_state = torch.from_numpy(s_next).float().unsqueeze(0).to(device)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            # Store transition\n",
        "            memory.push(state, action_tensor, next_state, reward)\n",
        "            state = next_state\n",
        "            ep_return += reward_val\n",
        "\n",
        "            # Optimize model\n",
        "            loss_val = optimize_model(policy_net, target_net, memory, optimizer)\n",
        "            if loss_val is not None:\n",
        "                losses.append(loss_val)\n",
        "\n",
        "            # Soft update target network\n",
        "            with torch.no_grad():\n",
        "                for target_param, param in zip(target_net.parameters(), policy_net.parameters()):\n",
        "                    target_param.data.copy_(target_param.data * (1.0 - TAU) + param.data * TAU)\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        episode_returns.append(ep_return)\n",
        "        episode_losses.append(np.mean(losses) if losses else 0.0)\n",
        "\n",
        "        print(\n",
        "            f\"Episode {i_episode} | Return: {ep_return:.2f} | \"\n",
        "            f\"Eps(step={steps_done}): {EPS_END + (EPS_START - EPS_END) * math.exp(-1.0 * steps_done / EPS_DECAY):.3f} | \"\n",
        "            f\"AvgLoss: {episode_losses[-1]:.4f}\"\n",
        "        )\n",
        "\n",
        "    return policy_net.state_dict(), episode_returns, episode_losses\n",
        "\n"
      ],
      "metadata": {
        "id": "1ZWGPYLGUEj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biO0ahMZeBKO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training(rewards, losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Episode')\n",
        "    ax1.set_ylabel('Total Reward', color=color)\n",
        "    ax1.plot(rewards, color=color, label='Total Reward')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2 = ax1.twinx()  # Create a second y-axis that shares the same x-axis\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Avg Loss', color=color)\n",
        "    ax2.plot(losses, color=color, linestyle='--', label='Avg Loss')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    plt.title(\"DQN Training Progress: Reward vs. Loss per Episode\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gZ6aSDTFBFZb",
        "outputId": "0afe7e81-9c70-4fed-d45a-29f1ec4b835b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Episode 5001 | Return: 3.17 | Eps(step=300896): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5002 | Return: 2.93 | Eps(step=300904): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5003 | Return: 2.21 | Eps(step=300909): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5004 | Return: 3.17 | Eps(step=300918): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5005 | Return: 2.21 | Eps(step=300923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5006 | Return: 2.43 | Eps(step=300931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5007 | Return: 2.21 | Eps(step=300936): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5008 | Return: 2.91 | Eps(step=300946): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5009 | Return: 2.45 | Eps(step=300952): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5010 | Return: -8.35 | Eps(step=301564): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5011 | Return: 1.00 | Eps(step=301565): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5012 | Return: 0.44 | Eps(step=301773): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5013 | Return: 2.69 | Eps(step=301780): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5014 | Return: 2.29 | Eps(step=301798): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5015 | Return: 3.89 | Eps(step=301810): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5016 | Return: 2.44 | Eps(step=301817): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5017 | Return: 2.45 | Eps(step=301823): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5018 | Return: 2.34 | Eps(step=301840): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5019 | Return: 1.95 | Eps(step=301846): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5020 | Return: 1.79 | Eps(step=301914): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5021 | Return: 2.44 | Eps(step=301946): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5022 | Return: 2.19 | Eps(step=301979): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5023 | Return: 2.69 | Eps(step=301986): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5024 | Return: 0.17 | Eps(step=301992): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5025 | Return: 2.69 | Eps(step=301999): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5026 | Return: 1.10 | Eps(step=302011): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5027 | Return: 2.10 | Eps(step=302023): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5028 | Return: 2.83 | Eps(step=302037): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5029 | Return: 2.21 | Eps(step=302042): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5030 | Return: 1.73 | Eps(step=302045): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5031 | Return: 1.97 | Eps(step=302049): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5032 | Return: 2.21 | Eps(step=302054): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5033 | Return: 3.63 | Eps(step=302067): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5034 | Return: 1.49 | Eps(step=302069): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5035 | Return: 1.25 | Eps(step=302070): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5036 | Return: 1.49 | Eps(step=302072): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5037 | Return: 1.47 | Eps(step=302076): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5038 | Return: 3.17 | Eps(step=302085): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5039 | Return: 2.93 | Eps(step=302093): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5040 | Return: 1.73 | Eps(step=302096): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5041 | Return: 3.40 | Eps(step=302107): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5042 | Return: 0.96 | Eps(step=302113): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5043 | Return: 1.49 | Eps(step=302115): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5044 | Return: 2.43 | Eps(step=302123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5045 | Return: 2.13 | Eps(step=302136): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5046 | Return: 2.21 | Eps(step=302141): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5047 | Return: 1.73 | Eps(step=302144): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5048 | Return: 3.17 | Eps(step=302153): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5049 | Return: 2.43 | Eps(step=302161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5050 | Return: 1.25 | Eps(step=302162): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5051 | Return: 2.68 | Eps(step=302170): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5052 | Return: 3.35 | Eps(step=302186): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5053 | Return: 1.60 | Eps(step=302198): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5054 | Return: 2.69 | Eps(step=302205): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5055 | Return: 2.43 | Eps(step=302213): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5056 | Return: 2.69 | Eps(step=302220): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5057 | Return: 3.15 | Eps(step=302231): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5058 | Return: 2.93 | Eps(step=302239): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5059 | Return: 0.24 | Eps(step=302242): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5060 | Return: 1.00 | Eps(step=302243): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5061 | Return: 2.69 | Eps(step=302250): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5062 | Return: 1.61 | Eps(step=302261): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5063 | Return: 2.67 | Eps(step=302270): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5064 | Return: 2.45 | Eps(step=302276): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5065 | Return: 1.97 | Eps(step=302280): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5066 | Return: 2.32 | Eps(step=302295): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5067 | Return: 1.25 | Eps(step=302296): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5068 | Return: 1.00 | Eps(step=302297): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5069 | Return: 2.80 | Eps(step=302314): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5070 | Return: 2.43 | Eps(step=302322): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5071 | Return: 2.69 | Eps(step=302329): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5072 | Return: 1.97 | Eps(step=302333): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5073 | Return: 2.43 | Eps(step=302341): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5074 | Return: 2.45 | Eps(step=302368): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5075 | Return: 3.88 | Eps(step=302381): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5076 | Return: 3.38 | Eps(step=302394): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5077 | Return: 1.49 | Eps(step=302396): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5078 | Return: 2.69 | Eps(step=302403): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5079 | Return: 2.45 | Eps(step=302409): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5080 | Return: 3.88 | Eps(step=302422): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5081 | Return: 2.65 | Eps(step=302433): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5082 | Return: 2.66 | Eps(step=302443): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5083 | Return: 2.91 | Eps(step=302453): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5084 | Return: 0.76 | Eps(step=302480): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5085 | Return: 1.24 | Eps(step=302482): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5086 | Return: 1.49 | Eps(step=302484): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5087 | Return: 1.69 | Eps(step=302491): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5088 | Return: 2.21 | Eps(step=302496): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5089 | Return: 1.71 | Eps(step=302501): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5090 | Return: 2.91 | Eps(step=302511): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5091 | Return: 1.86 | Eps(step=302522): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5092 | Return: 2.21 | Eps(step=302527): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5093 | Return: 1.43 | Eps(step=302581): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5094 | Return: 2.87 | Eps(step=302595): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5095 | Return: 2.43 | Eps(step=302603): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5096 | Return: 3.14 | Eps(step=302640): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5097 | Return: 1.97 | Eps(step=302644): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5098 | Return: 2.69 | Eps(step=302651): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5099 | Return: 2.45 | Eps(step=302657): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5100 | Return: 2.91 | Eps(step=302667): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5101 | Return: 2.45 | Eps(step=302673): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5102 | Return: 1.49 | Eps(step=302675): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5103 | Return: 1.00 | Eps(step=302676): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5104 | Return: 2.91 | Eps(step=302686): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5105 | Return: 2.45 | Eps(step=302692): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5106 | Return: 0.64 | Eps(step=302731): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5107 | Return: 2.61 | Eps(step=302746): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5108 | Return: 1.97 | Eps(step=302750): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5109 | Return: 2.69 | Eps(step=302757): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5110 | Return: 1.73 | Eps(step=302760): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5111 | Return: 2.38 | Eps(step=302769): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5112 | Return: 1.97 | Eps(step=302773): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5113 | Return: 3.14 | Eps(step=302785): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5114 | Return: 2.19 | Eps(step=302792): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5115 | Return: 3.65 | Eps(step=302803): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5116 | Return: 1.73 | Eps(step=302806): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5117 | Return: 3.15 | Eps(step=302817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5118 | Return: 2.21 | Eps(step=302822): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5119 | Return: 2.69 | Eps(step=302829): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5120 | Return: 1.97 | Eps(step=302833): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5121 | Return: 2.93 | Eps(step=302841): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5122 | Return: 2.44 | Eps(step=302848): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5123 | Return: 1.73 | Eps(step=302851): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5124 | Return: 1.25 | Eps(step=302852): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5125 | Return: 2.21 | Eps(step=302857): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5126 | Return: 1.48 | Eps(step=302860): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5127 | Return: 3.15 | Eps(step=302871): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5128 | Return: 1.17 | Eps(step=303001): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5129 | Return: 1.25 | Eps(step=303002): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5130 | Return: 1.39 | Eps(step=303014): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5131 | Return: 2.17 | Eps(step=303023): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5132 | Return: 2.88 | Eps(step=303037): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5133 | Return: 3.39 | Eps(step=303049): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5134 | Return: 1.85 | Eps(step=303061): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5135 | Return: 1.11 | Eps(step=303072): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5136 | Return: 3.17 | Eps(step=303081): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5137 | Return: 3.41 | Eps(step=303091): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5138 | Return: 2.18 | Eps(step=303099): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5139 | Return: 2.19 | Eps(step=303106): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5140 | Return: 1.74 | Eps(step=303133): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5141 | Return: -1.77 | Eps(step=303185): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5142 | Return: 1.97 | Eps(step=303189): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5143 | Return: 3.17 | Eps(step=303198): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5144 | Return: 1.97 | Eps(step=303202): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5145 | Return: 1.73 | Eps(step=303205): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5146 | Return: 2.45 | Eps(step=303211): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5147 | Return: 1.32 | Eps(step=303230): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5148 | Return: 1.00 | Eps(step=303231): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5149 | Return: 2.21 | Eps(step=303236): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5150 | Return: 1.97 | Eps(step=303240): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5151 | Return: 2.93 | Eps(step=303248): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5152 | Return: 1.25 | Eps(step=303249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5153 | Return: 1.97 | Eps(step=303253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5154 | Return: 2.63 | Eps(step=303266): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5155 | Return: 2.43 | Eps(step=303274): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5156 | Return: 2.08 | Eps(step=303292): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5157 | Return: 1.97 | Eps(step=303296): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5158 | Return: 3.89 | Eps(step=303308): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5159 | Return: 1.97 | Eps(step=303312): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5160 | Return: 3.17 | Eps(step=303321): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5161 | Return: 1.49 | Eps(step=303323): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5162 | Return: 1.97 | Eps(step=303327): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5163 | Return: 2.42 | Eps(step=303336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5164 | Return: 2.93 | Eps(step=303344): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5165 | Return: 3.89 | Eps(step=303356): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5166 | Return: 2.92 | Eps(step=303365): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5167 | Return: 1.25 | Eps(step=303366): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5168 | Return: 2.43 | Eps(step=303374): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5169 | Return: 2.79 | Eps(step=303392): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5170 | Return: 1.97 | Eps(step=303396): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5171 | Return: 2.91 | Eps(step=303406): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5172 | Return: 1.48 | Eps(step=303409): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5173 | Return: 2.19 | Eps(step=303416): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5174 | Return: 3.87 | Eps(step=303430): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5175 | Return: 2.69 | Eps(step=303437): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5176 | Return: 1.97 | Eps(step=303441): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5177 | Return: 1.97 | Eps(step=303445): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5178 | Return: 1.97 | Eps(step=303449): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5179 | Return: 2.44 | Eps(step=303456): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5180 | Return: 1.25 | Eps(step=303457): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5181 | Return: 1.73 | Eps(step=303460): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5182 | Return: 2.65 | Eps(step=303471): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5183 | Return: 1.49 | Eps(step=303473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5184 | Return: 2.68 | Eps(step=303481): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5185 | Return: 3.39 | Eps(step=303493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5186 | Return: 2.45 | Eps(step=303499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5187 | Return: 2.45 | Eps(step=303505): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5188 | Return: 1.86 | Eps(step=303516): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5189 | Return: 2.37 | Eps(step=303555): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5190 | Return: 2.40 | Eps(step=303567): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5191 | Return: 1.73 | Eps(step=303570): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5192 | Return: 1.97 | Eps(step=303574): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5193 | Return: 2.69 | Eps(step=303581): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5194 | Return: 2.14 | Eps(step=303593): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5195 | Return: 3.17 | Eps(step=303602): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5196 | Return: 2.67 | Eps(step=303611): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5197 | Return: 2.41 | Eps(step=303621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5198 | Return: 2.21 | Eps(step=303626): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5199 | Return: 0.96 | Eps(step=303632): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5200 | Return: 2.12 | Eps(step=303647): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5201 | Return: 2.41 | Eps(step=303657): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5202 | Return: 2.87 | Eps(step=303671): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5203 | Return: 1.73 | Eps(step=303674): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5204 | Return: 2.21 | Eps(step=303679): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5205 | Return: 2.21 | Eps(step=303684): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5206 | Return: 1.71 | Eps(step=303689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5207 | Return: 1.73 | Eps(step=303692): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5208 | Return: 1.97 | Eps(step=303696): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5209 | Return: 2.69 | Eps(step=303703): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5210 | Return: 1.73 | Eps(step=303706): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5211 | Return: 1.73 | Eps(step=303709): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5212 | Return: 2.93 | Eps(step=303717): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5213 | Return: 2.45 | Eps(step=303723): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5214 | Return: 2.67 | Eps(step=303732): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5215 | Return: 2.19 | Eps(step=303739): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5216 | Return: 1.71 | Eps(step=303744): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5217 | Return: 2.21 | Eps(step=303749): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5218 | Return: 2.67 | Eps(step=303758): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5219 | Return: 3.65 | Eps(step=303769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5220 | Return: 2.75 | Eps(step=303791): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5221 | Return: 2.93 | Eps(step=303799): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5222 | Return: 2.93 | Eps(step=303807): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5223 | Return: 3.05 | Eps(step=303828): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5224 | Return: 3.89 | Eps(step=303840): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5225 | Return: 2.68 | Eps(step=303848): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5226 | Return: 1.23 | Eps(step=303851): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5227 | Return: 3.63 | Eps(step=303864): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5228 | Return: 2.69 | Eps(step=303871): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5229 | Return: 2.69 | Eps(step=303878): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5230 | Return: 1.68 | Eps(step=303887): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5231 | Return: 1.63 | Eps(step=303896): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5232 | Return: 2.67 | Eps(step=303905): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5233 | Return: 3.63 | Eps(step=303918): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5234 | Return: 1.69 | Eps(step=303925): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5235 | Return: 0.55 | Eps(step=303997): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5236 | Return: 2.21 | Eps(step=304002): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5237 | Return: 2.43 | Eps(step=304010): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5238 | Return: 2.19 | Eps(step=304017): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5239 | Return: 2.50 | Eps(step=304043): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5240 | Return: 3.17 | Eps(step=304052): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5241 | Return: 0.88 | Eps(step=304111): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5242 | Return: 1.97 | Eps(step=304115): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5243 | Return: 2.18 | Eps(step=304123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5244 | Return: 2.43 | Eps(step=304131): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5245 | Return: 2.21 | Eps(step=304136): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5246 | Return: 2.91 | Eps(step=304146): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5247 | Return: 2.21 | Eps(step=304151): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5248 | Return: 2.21 | Eps(step=304156): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5249 | Return: 3.65 | Eps(step=304167): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5250 | Return: 2.21 | Eps(step=304172): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5251 | Return: 2.45 | Eps(step=304178): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5252 | Return: 2.45 | Eps(step=304184): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5253 | Return: 3.39 | Eps(step=304196): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5254 | Return: 1.49 | Eps(step=304198): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5255 | Return: 2.45 | Eps(step=304204): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5256 | Return: 1.64 | Eps(step=304216): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5257 | Return: 2.77 | Eps(step=304241): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5258 | Return: 3.41 | Eps(step=304251): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5259 | Return: 0.99 | Eps(step=304253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5260 | Return: 1.95 | Eps(step=304259): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5261 | Return: 2.69 | Eps(step=304266): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5262 | Return: 0.27 | Eps(step=304287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5263 | Return: 1.73 | Eps(step=304290): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5264 | Return: 1.40 | Eps(step=304297): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5265 | Return: 2.92 | Eps(step=304306): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5266 | Return: 2.48 | Eps(step=304334): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5267 | Return: 2.19 | Eps(step=304341): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5268 | Return: 1.97 | Eps(step=304345): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5269 | Return: 1.20 | Eps(step=304352): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5270 | Return: 1.49 | Eps(step=304354): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5271 | Return: 2.69 | Eps(step=304361): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5272 | Return: 2.43 | Eps(step=304369): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5273 | Return: 1.87 | Eps(step=304383): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5274 | Return: 2.45 | Eps(step=304389): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5275 | Return: 1.25 | Eps(step=304390): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5276 | Return: 2.39 | Eps(step=304402): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5277 | Return: 1.66 | Eps(step=304413): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5278 | Return: 1.96 | Eps(step=304418): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5279 | Return: 3.65 | Eps(step=304429): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5280 | Return: 3.37 | Eps(step=304443): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5281 | Return: 1.97 | Eps(step=304447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5282 | Return: 0.98 | Eps(step=304450): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5283 | Return: 3.10 | Eps(step=304466): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5284 | Return: 0.47 | Eps(step=304471): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5285 | Return: 1.44 | Eps(step=304479): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5286 | Return: 1.97 | Eps(step=304483): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5287 | Return: 2.21 | Eps(step=304488): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5288 | Return: 1.73 | Eps(step=304491): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5289 | Return: 2.67 | Eps(step=304500): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5290 | Return: 1.97 | Eps(step=304504): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5291 | Return: 0.37 | Eps(step=304519): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5292 | Return: 1.25 | Eps(step=304520): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5293 | Return: 1.97 | Eps(step=304524): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5294 | Return: -1.72 | Eps(step=304551): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5295 | Return: 1.73 | Eps(step=304554): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5296 | Return: 3.41 | Eps(step=304564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5297 | Return: 2.45 | Eps(step=304570): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5298 | Return: 2.03 | Eps(step=304593): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5299 | Return: 2.43 | Eps(step=304601): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5300 | Return: 2.21 | Eps(step=304606): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5301 | Return: 2.21 | Eps(step=304611): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5302 | Return: 1.73 | Eps(step=304614): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5303 | Return: 2.21 | Eps(step=304619): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5304 | Return: 1.71 | Eps(step=304624): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5305 | Return: -0.09 | Eps(step=304658): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5306 | Return: 2.12 | Eps(step=304668): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5307 | Return: 2.43 | Eps(step=304676): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5308 | Return: 2.69 | Eps(step=304683): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5309 | Return: 1.96 | Eps(step=304688): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5310 | Return: 2.21 | Eps(step=304693): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5311 | Return: 1.90 | Eps(step=304705): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5312 | Return: 1.73 | Eps(step=304708): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5313 | Return: 2.45 | Eps(step=304714): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5314 | Return: 3.15 | Eps(step=304725): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5315 | Return: 3.34 | Eps(step=304742): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5316 | Return: 1.49 | Eps(step=304744): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5317 | Return: 3.17 | Eps(step=304753): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5318 | Return: 1.25 | Eps(step=304754): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5319 | Return: 3.87 | Eps(step=304768): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5320 | Return: 2.43 | Eps(step=304776): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5321 | Return: 1.09 | Eps(step=304785): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5322 | Return: 2.91 | Eps(step=304795): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5323 | Return: 1.97 | Eps(step=304799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5324 | Return: 2.69 | Eps(step=304806): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5325 | Return: 2.69 | Eps(step=304813): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5326 | Return: 2.06 | Eps(step=304829): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5327 | Return: 1.49 | Eps(step=304831): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5328 | Return: 3.15 | Eps(step=304842): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5329 | Return: 1.73 | Eps(step=304845): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5330 | Return: 3.17 | Eps(step=304854): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5331 | Return: 2.69 | Eps(step=304861): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5332 | Return: 3.16 | Eps(step=304871): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5333 | Return: 1.97 | Eps(step=304875): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5334 | Return: 3.17 | Eps(step=304884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5335 | Return: 2.82 | Eps(step=304928): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5336 | Return: 1.49 | Eps(step=304930): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5337 | Return: 2.45 | Eps(step=304936): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5338 | Return: 2.93 | Eps(step=304944): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5339 | Return: 0.25 | Eps(step=304991): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5340 | Return: 2.43 | Eps(step=304999): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5341 | Return: 2.21 | Eps(step=305004): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5342 | Return: 2.45 | Eps(step=305010): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5343 | Return: 1.95 | Eps(step=305016): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5344 | Return: 2.21 | Eps(step=305021): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5345 | Return: 3.41 | Eps(step=305031): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5346 | Return: 1.95 | Eps(step=305037): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5347 | Return: 3.16 | Eps(step=305047): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5348 | Return: 3.06 | Eps(step=305063): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5349 | Return: 2.93 | Eps(step=305071): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5350 | Return: 2.21 | Eps(step=305076): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5351 | Return: 3.41 | Eps(step=305086): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5352 | Return: 1.49 | Eps(step=305088): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5353 | Return: 2.45 | Eps(step=305094): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5354 | Return: 2.19 | Eps(step=305101): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5355 | Return: 2.45 | Eps(step=305107): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5356 | Return: 3.89 | Eps(step=305119): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5357 | Return: 2.69 | Eps(step=305126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5358 | Return: 2.42 | Eps(step=305135): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5359 | Return: 2.16 | Eps(step=305146): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5360 | Return: 2.87 | Eps(step=305160): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5361 | Return: 2.19 | Eps(step=305167): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5362 | Return: 0.65 | Eps(step=305175): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5363 | Return: 1.47 | Eps(step=305200): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5364 | Return: 1.46 | Eps(step=305205): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5365 | Return: 1.00 | Eps(step=305206): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5366 | Return: 2.44 | Eps(step=305213): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5367 | Return: 1.97 | Eps(step=305217): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5368 | Return: 1.25 | Eps(step=305218): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5369 | Return: 2.45 | Eps(step=305224): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5370 | Return: 1.25 | Eps(step=305225): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5371 | Return: 2.70 | Eps(step=305252): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5372 | Return: 3.39 | Eps(step=305264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5373 | Return: 3.69 | Eps(step=305296): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5374 | Return: 2.71 | Eps(step=305326): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5375 | Return: 1.25 | Eps(step=305327): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5376 | Return: 0.13 | Eps(step=305337): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5377 | Return: 2.21 | Eps(step=305342): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5378 | Return: 2.93 | Eps(step=305350): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5379 | Return: 2.84 | Eps(step=305367): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5380 | Return: 1.82 | Eps(step=305386): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5381 | Return: 2.93 | Eps(step=305394): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5382 | Return: 3.40 | Eps(step=305405): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5383 | Return: 2.44 | Eps(step=305412): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5384 | Return: 3.65 | Eps(step=305423): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5385 | Return: 2.68 | Eps(step=305431): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5386 | Return: 2.19 | Eps(step=305438): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5387 | Return: 3.17 | Eps(step=305447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5388 | Return: 1.00 | Eps(step=305448): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5389 | Return: 3.17 | Eps(step=305457): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5390 | Return: 3.40 | Eps(step=305468): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5391 | Return: 0.67 | Eps(step=305479): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5392 | Return: 2.69 | Eps(step=305486): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5393 | Return: 2.45 | Eps(step=305492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5394 | Return: 1.71 | Eps(step=305497): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5395 | Return: 1.49 | Eps(step=305499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5396 | Return: 2.21 | Eps(step=305504): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5397 | Return: 1.49 | Eps(step=305506): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5398 | Return: 2.19 | Eps(step=305513): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5399 | Return: 3.41 | Eps(step=305523): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5400 | Return: 3.41 | Eps(step=305533): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5401 | Return: 2.92 | Eps(step=305542): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5402 | Return: 2.93 | Eps(step=305550): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5403 | Return: 2.69 | Eps(step=305557): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5404 | Return: 2.93 | Eps(step=305565): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5405 | Return: 2.93 | Eps(step=305573): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5406 | Return: 1.97 | Eps(step=305577): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5407 | Return: 2.69 | Eps(step=305609): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5408 | Return: 2.45 | Eps(step=305615): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5409 | Return: 2.21 | Eps(step=305620): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5410 | Return: 1.14 | Eps(step=305628): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5411 | Return: 2.21 | Eps(step=305633): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5412 | Return: 2.69 | Eps(step=305640): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5413 | Return: 3.15 | Eps(step=305651): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5414 | Return: 2.93 | Eps(step=305659): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5415 | Return: 2.43 | Eps(step=305667): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5416 | Return: 1.49 | Eps(step=305669): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5417 | Return: 2.06 | Eps(step=305689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5418 | Return: 2.20 | Eps(step=305695): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5419 | Return: 1.97 | Eps(step=305699): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5420 | Return: 1.97 | Eps(step=305703): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5421 | Return: 2.45 | Eps(step=305709): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5422 | Return: 2.62 | Eps(step=305723): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5423 | Return: 3.86 | Eps(step=305738): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5424 | Return: 2.61 | Eps(step=305753): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5425 | Return: 2.43 | Eps(step=305761): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5426 | Return: 1.71 | Eps(step=305766): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5427 | Return: 2.88 | Eps(step=305779): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5428 | Return: 2.08 | Eps(step=305797): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5429 | Return: 1.97 | Eps(step=305801): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5430 | Return: -17.90 | Eps(step=306801): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5431 | Return: 1.05 | Eps(step=306822): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5432 | Return: 2.10 | Eps(step=306834): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5433 | Return: 0.81 | Eps(step=306881): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5434 | Return: 2.55 | Eps(step=306902): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5435 | Return: 3.17 | Eps(step=306911): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5436 | Return: 1.49 | Eps(step=306913): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5437 | Return: 1.49 | Eps(step=306915): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5438 | Return: 2.17 | Eps(step=306924): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5439 | Return: 1.92 | Eps(step=306934): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5440 | Return: 1.11 | Eps(step=306970): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5441 | Return: 2.45 | Eps(step=306976): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5442 | Return: 2.36 | Eps(step=306987): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5443 | Return: 2.21 | Eps(step=306992): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5444 | Return: 2.45 | Eps(step=306998): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5445 | Return: 2.91 | Eps(step=307008): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5446 | Return: 2.63 | Eps(step=307021): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5447 | Return: 2.52 | Eps(step=307041): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5448 | Return: 3.10 | Eps(step=307053): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5449 | Return: 1.80 | Eps(step=307070): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5450 | Return: 1.66 | Eps(step=307080): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5451 | Return: 2.47 | Eps(step=307109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5452 | Return: 1.97 | Eps(step=307113): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5453 | Return: 3.40 | Eps(step=307124): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5454 | Return: 1.94 | Eps(step=307131): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5455 | Return: 2.69 | Eps(step=307138): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5456 | Return: 1.97 | Eps(step=307142): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5457 | Return: 3.41 | Eps(step=307152): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5458 | Return: 2.19 | Eps(step=307159): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5459 | Return: 1.73 | Eps(step=307162): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5460 | Return: 2.21 | Eps(step=307167): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5461 | Return: 2.21 | Eps(step=307172): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5462 | Return: 2.93 | Eps(step=307180): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5463 | Return: 2.69 | Eps(step=307187): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5464 | Return: 2.67 | Eps(step=307196): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5465 | Return: 1.73 | Eps(step=307199): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5466 | Return: 2.69 | Eps(step=307206): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5467 | Return: 2.93 | Eps(step=307214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5468 | Return: 1.92 | Eps(step=307223): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5469 | Return: 2.93 | Eps(step=307231): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5470 | Return: 0.45 | Eps(step=307263): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5471 | Return: 3.39 | Eps(step=307275): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5472 | Return: 2.45 | Eps(step=307281): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5473 | Return: 2.21 | Eps(step=307286): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5474 | Return: 1.97 | Eps(step=307290): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5475 | Return: 1.97 | Eps(step=307294): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5476 | Return: 1.00 | Eps(step=307295): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5477 | Return: 3.15 | Eps(step=307306): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5478 | Return: 1.97 | Eps(step=307310): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5479 | Return: 2.87 | Eps(step=307324): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5480 | Return: 1.97 | Eps(step=307328): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5481 | Return: 2.21 | Eps(step=307333): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5482 | Return: 1.95 | Eps(step=307339): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5483 | Return: 3.10 | Eps(step=307355): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5484 | Return: 2.21 | Eps(step=307360): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5485 | Return: 3.63 | Eps(step=307373): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5486 | Return: 1.73 | Eps(step=307376): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5487 | Return: 3.41 | Eps(step=307386): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5488 | Return: 2.21 | Eps(step=307391): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5489 | Return: 1.19 | Eps(step=307444): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5490 | Return: 2.08 | Eps(step=307462): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5491 | Return: 0.89 | Eps(step=307470): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5492 | Return: 1.73 | Eps(step=307473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5493 | Return: 2.21 | Eps(step=307478): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5494 | Return: 1.71 | Eps(step=307483): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5495 | Return: 1.91 | Eps(step=307493): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5496 | Return: 2.39 | Eps(step=307505): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5497 | Return: 2.65 | Eps(step=307516): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5498 | Return: 2.11 | Eps(step=307531): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5499 | Return: 3.89 | Eps(step=307543): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5500 | Return: 2.93 | Eps(step=307551): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5501 | Return: 3.58 | Eps(step=307569): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5502 | Return: 3.89 | Eps(step=307581): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5503 | Return: 2.43 | Eps(step=307589): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5504 | Return: 3.17 | Eps(step=307598): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5505 | Return: 3.41 | Eps(step=307608): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5506 | Return: 3.15 | Eps(step=307619): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5507 | Return: 1.73 | Eps(step=307622): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5508 | Return: 3.41 | Eps(step=307632): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5509 | Return: 3.39 | Eps(step=307644): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5510 | Return: 1.96 | Eps(step=307649): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5511 | Return: 2.93 | Eps(step=307657): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5512 | Return: 1.73 | Eps(step=307660): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5513 | Return: 3.80 | Eps(step=307681): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5514 | Return: 1.00 | Eps(step=307682): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5515 | Return: 2.19 | Eps(step=307689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5516 | Return: 2.85 | Eps(step=307701): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5517 | Return: 3.60 | Eps(step=307717): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5518 | Return: 1.60 | Eps(step=307729): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5519 | Return: 2.66 | Eps(step=307739): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5520 | Return: 3.17 | Eps(step=307748): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5521 | Return: 2.21 | Eps(step=307753): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5522 | Return: 2.44 | Eps(step=307760): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5523 | Return: 2.67 | Eps(step=307769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5524 | Return: 3.39 | Eps(step=307781): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5525 | Return: 2.69 | Eps(step=307788): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5526 | Return: 2.20 | Eps(step=307794): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5527 | Return: 2.21 | Eps(step=307799): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5528 | Return: 1.02 | Eps(step=307865): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5529 | Return: 1.97 | Eps(step=307869): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5530 | Return: 2.19 | Eps(step=307876): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5531 | Return: 2.21 | Eps(step=307881): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5532 | Return: 1.97 | Eps(step=307885): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5533 | Return: 2.45 | Eps(step=307891): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5534 | Return: 1.73 | Eps(step=307894): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5535 | Return: 2.20 | Eps(step=307900): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5536 | Return: 2.93 | Eps(step=307908): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5537 | Return: 2.69 | Eps(step=307915): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5538 | Return: 2.91 | Eps(step=307925): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5539 | Return: 3.41 | Eps(step=307935): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5540 | Return: 1.49 | Eps(step=307937): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5541 | Return: 1.62 | Eps(step=307968): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5542 | Return: 2.19 | Eps(step=307975): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5543 | Return: 2.68 | Eps(step=307983): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5544 | Return: 2.93 | Eps(step=307991): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5545 | Return: 1.95 | Eps(step=307997): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5546 | Return: 1.60 | Eps(step=308035): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5547 | Return: 2.21 | Eps(step=308040): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5548 | Return: 3.17 | Eps(step=308049): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5549 | Return: 1.25 | Eps(step=308050): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5550 | Return: 1.49 | Eps(step=308052): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5551 | Return: 2.11 | Eps(step=308067): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5552 | Return: 1.97 | Eps(step=308071): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5553 | Return: 2.93 | Eps(step=308079): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5554 | Return: 2.69 | Eps(step=308086): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5555 | Return: 2.67 | Eps(step=308095): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5556 | Return: 2.42 | Eps(step=308129): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5557 | Return: 2.13 | Eps(step=308142): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5558 | Return: 2.62 | Eps(step=308156): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5559 | Return: 2.45 | Eps(step=308162): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5560 | Return: 1.90 | Eps(step=308169): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5561 | Return: 2.68 | Eps(step=308177): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5562 | Return: 2.89 | Eps(step=308189): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5563 | Return: 0.45 | Eps(step=308197): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5564 | Return: 2.93 | Eps(step=308205): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5565 | Return: 3.17 | Eps(step=308214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5566 | Return: 1.97 | Eps(step=308218): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5567 | Return: 1.61 | Eps(step=308259): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5568 | Return: 2.93 | Eps(step=308267): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5569 | Return: 1.97 | Eps(step=308271): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5570 | Return: 2.43 | Eps(step=308279): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5571 | Return: 0.24 | Eps(step=308403): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5572 | Return: 1.92 | Eps(step=308412): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5573 | Return: 0.38 | Eps(step=308422): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5574 | Return: 2.90 | Eps(step=308433): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5575 | Return: 1.73 | Eps(step=308436): 0.100 | AvgLoss: 0.0008\n",
            "Episode 5576 | Return: 1.00 | Eps(step=308437): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5577 | Return: 2.93 | Eps(step=308445): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5578 | Return: 1.40 | Eps(step=308452): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5579 | Return: 2.27 | Eps(step=308476): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5580 | Return: 2.19 | Eps(step=308483): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5581 | Return: 2.93 | Eps(step=308491): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5582 | Return: 2.78 | Eps(step=308514): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5583 | Return: 2.67 | Eps(step=308523): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5584 | Return: 1.97 | Eps(step=308527): 0.100 | AvgLoss: 0.0006\n",
            "Episode 5585 | Return: 2.45 | Eps(step=308533): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5586 | Return: 2.21 | Eps(step=308538): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5587 | Return: 2.38 | Eps(step=308547): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5588 | Return: 3.15 | Eps(step=308558): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5589 | Return: 1.97 | Eps(step=308562): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5590 | Return: 1.25 | Eps(step=308563): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5591 | Return: 2.67 | Eps(step=308572): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5592 | Return: 1.92 | Eps(step=308582): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5593 | Return: 2.91 | Eps(step=308592): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5594 | Return: -1.10 | Eps(step=308656): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5595 | Return: 2.21 | Eps(step=308661): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5596 | Return: 2.21 | Eps(step=308666): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5597 | Return: -0.23 | Eps(step=308688): 0.100 | AvgLoss: 0.0006\n",
            "Episode 5598 | Return: 2.69 | Eps(step=308695): 0.100 | AvgLoss: 0.0009\n",
            "Episode 5599 | Return: -0.80 | Eps(step=308798): 0.100 | AvgLoss: 0.0007\n",
            "Episode 5600 | Return: 1.25 | Eps(step=308799): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5601 | Return: 1.49 | Eps(step=308801): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5602 | Return: 1.95 | Eps(step=308832): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5603 | Return: 2.69 | Eps(step=308839): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5604 | Return: 1.72 | Eps(step=308843): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5605 | Return: 3.65 | Eps(step=308854): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5606 | Return: 2.24 | Eps(step=308877): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5607 | Return: 2.43 | Eps(step=308885): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5608 | Return: -0.04 | Eps(step=308967): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5609 | Return: 3.17 | Eps(step=308976): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5610 | Return: 2.51 | Eps(step=309001): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5611 | Return: 1.49 | Eps(step=309003): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5612 | Return: 1.36 | Eps(step=309019): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5613 | Return: 2.20 | Eps(step=309025): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5614 | Return: 2.02 | Eps(step=309045): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5615 | Return: 1.93 | Eps(step=309053): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5616 | Return: 2.66 | Eps(step=309113): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5617 | Return: 1.95 | Eps(step=309119): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5618 | Return: 2.67 | Eps(step=309128): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5619 | Return: 2.19 | Eps(step=309135): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5620 | Return: 2.67 | Eps(step=309144): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5621 | Return: 3.17 | Eps(step=309178): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5622 | Return: 2.93 | Eps(step=309186): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5623 | Return: 3.41 | Eps(step=309196): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5624 | Return: 2.93 | Eps(step=309204): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5625 | Return: 2.50 | Eps(step=309230): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5626 | Return: 2.45 | Eps(step=309236): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5627 | Return: 1.94 | Eps(step=309243): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5628 | Return: 0.24 | Eps(step=309246): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5629 | Return: 2.62 | Eps(step=309256): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5630 | Return: 1.00 | Eps(step=309257): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5631 | Return: 3.41 | Eps(step=309267): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5632 | Return: 2.91 | Eps(step=309277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5633 | Return: 2.19 | Eps(step=309284): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5634 | Return: 2.45 | Eps(step=309290): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5635 | Return: 2.45 | Eps(step=309296): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5636 | Return: 1.49 | Eps(step=309298): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5637 | Return: 1.25 | Eps(step=309299): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5638 | Return: 2.21 | Eps(step=309304): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5639 | Return: 2.21 | Eps(step=309309): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5640 | Return: 2.19 | Eps(step=309316): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5641 | Return: 2.34 | Eps(step=309358): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5642 | Return: 3.41 | Eps(step=309368): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5643 | Return: 1.49 | Eps(step=309370): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5644 | Return: 1.49 | Eps(step=309372): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5645 | Return: 2.68 | Eps(step=309380): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5646 | Return: 2.45 | Eps(step=309386): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5647 | Return: 1.72 | Eps(step=309390): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5648 | Return: 3.17 | Eps(step=309399): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5649 | Return: -19.44 | Eps(step=310158): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5650 | Return: 2.07 | Eps(step=310177): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5651 | Return: 1.34 | Eps(step=310194): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5652 | Return: 2.20 | Eps(step=310200): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5653 | Return: 0.90 | Eps(step=310233): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5654 | Return: 0.48 | Eps(step=310237): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5655 | Return: 2.59 | Eps(step=310254): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5656 | Return: 2.82 | Eps(step=310269): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5657 | Return: 0.11 | Eps(step=310306): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5658 | Return: 2.67 | Eps(step=310315): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5659 | Return: 2.45 | Eps(step=310321): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5660 | Return: 0.68 | Eps(step=310325): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5661 | Return: 1.71 | Eps(step=310330): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5662 | Return: 2.21 | Eps(step=310335): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5663 | Return: 2.44 | Eps(step=310342): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5664 | Return: 1.66 | Eps(step=310353): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5665 | Return: 0.48 | Eps(step=310357): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5666 | Return: 1.49 | Eps(step=310359): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5667 | Return: 2.90 | Eps(step=310370): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5668 | Return: 1.73 | Eps(step=310373): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5669 | Return: 1.49 | Eps(step=310375): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5670 | Return: 2.17 | Eps(step=310434): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5671 | Return: 1.95 | Eps(step=310440): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5672 | Return: 1.25 | Eps(step=310441): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5673 | Return: 2.45 | Eps(step=310447): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5674 | Return: 3.13 | Eps(step=310460): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5675 | Return: 2.56 | Eps(step=310476): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5676 | Return: 1.25 | Eps(step=310477): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5677 | Return: 3.59 | Eps(step=310494): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5678 | Return: 2.45 | Eps(step=310500): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5679 | Return: 2.43 | Eps(step=310508): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5680 | Return: 1.73 | Eps(step=310511): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5681 | Return: 1.93 | Eps(step=310519): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5682 | Return: -0.56 | Eps(step=310593): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5683 | Return: 2.60 | Eps(step=310605): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5684 | Return: 1.37 | Eps(step=310620): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5685 | Return: 1.00 | Eps(step=310621): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5686 | Return: 2.86 | Eps(step=310636): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5687 | Return: 1.73 | Eps(step=310639): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5688 | Return: 1.25 | Eps(step=310640): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5689 | Return: 1.49 | Eps(step=310642): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5690 | Return: 1.47 | Eps(step=310646): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5691 | Return: 2.01 | Eps(step=310692): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5692 | Return: 2.63 | Eps(step=310705): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5693 | Return: 2.93 | Eps(step=310713): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5694 | Return: 1.68 | Eps(step=310722): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5695 | Return: 1.25 | Eps(step=310723): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5696 | Return: 3.16 | Eps(step=310733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5697 | Return: 1.25 | Eps(step=310734): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5698 | Return: 2.20 | Eps(step=310740): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5699 | Return: -1.98 | Eps(step=310888): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5700 | Return: 2.92 | Eps(step=310897): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5701 | Return: 1.73 | Eps(step=310900): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5702 | Return: 1.25 | Eps(step=310901): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5703 | Return: 1.42 | Eps(step=310906): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5704 | Return: 1.73 | Eps(step=310909): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5705 | Return: 3.63 | Eps(step=310922): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5706 | Return: 2.16 | Eps(step=310933): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5707 | Return: 1.97 | Eps(step=310937): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5708 | Return: 1.73 | Eps(step=310940): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5709 | Return: 2.89 | Eps(step=310952): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5710 | Return: 1.73 | Eps(step=310955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5711 | Return: 1.95 | Eps(step=310961): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5712 | Return: 3.17 | Eps(step=310970): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5713 | Return: 1.97 | Eps(step=310974): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5714 | Return: 2.67 | Eps(step=310983): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5715 | Return: 2.69 | Eps(step=310990): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5716 | Return: -5.06 | Eps(step=311298): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5717 | Return: 1.25 | Eps(step=311299): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5718 | Return: 1.47 | Eps(step=311303): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5719 | Return: 1.73 | Eps(step=311306): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5720 | Return: 1.72 | Eps(step=311335): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5721 | Return: 1.50 | Eps(step=311357): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5722 | Return: 2.94 | Eps(step=311389): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5723 | Return: 2.01 | Eps(step=311439): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5724 | Return: 2.21 | Eps(step=311444): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5725 | Return: 2.87 | Eps(step=311458): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5726 | Return: 1.97 | Eps(step=311462): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5727 | Return: 2.67 | Eps(step=311471): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5728 | Return: 2.91 | Eps(step=311481): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5729 | Return: 3.40 | Eps(step=311492): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5730 | Return: 2.45 | Eps(step=311498): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5731 | Return: 1.49 | Eps(step=311500): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5732 | Return: 1.73 | Eps(step=311503): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5733 | Return: 2.45 | Eps(step=311509): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5734 | Return: 3.35 | Eps(step=311525): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5735 | Return: 2.45 | Eps(step=311531): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5736 | Return: 1.49 | Eps(step=311533): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5737 | Return: 2.67 | Eps(step=311542): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5738 | Return: 2.16 | Eps(step=311552): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5739 | Return: 2.45 | Eps(step=311558): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5740 | Return: 2.21 | Eps(step=311563): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5741 | Return: 2.64 | Eps(step=311575): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5742 | Return: 2.30 | Eps(step=311588): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5743 | Return: 1.97 | Eps(step=311592): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5744 | Return: 2.19 | Eps(step=311599): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5745 | Return: 1.40 | Eps(step=311606): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5746 | Return: 1.73 | Eps(step=311609): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5747 | Return: 1.73 | Eps(step=311612): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5748 | Return: 1.95 | Eps(step=311618): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5749 | Return: 2.38 | Eps(step=311631): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5750 | Return: 2.34 | Eps(step=311644): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5751 | Return: 2.69 | Eps(step=311651): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5752 | Return: 3.39 | Eps(step=311663): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5753 | Return: 1.93 | Eps(step=311671): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5754 | Return: 1.00 | Eps(step=311672): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5755 | Return: 1.49 | Eps(step=311674): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5756 | Return: 2.69 | Eps(step=311681): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5757 | Return: 2.21 | Eps(step=311686): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5758 | Return: 3.63 | Eps(step=311699): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5759 | Return: 3.86 | Eps(step=311714): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5760 | Return: 1.25 | Eps(step=311715): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5761 | Return: 2.45 | Eps(step=311721): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5762 | Return: 2.45 | Eps(step=311727): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5763 | Return: 1.95 | Eps(step=311733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5764 | Return: 2.19 | Eps(step=311740): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5765 | Return: 3.41 | Eps(step=311750): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5766 | Return: 1.97 | Eps(step=311754): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5767 | Return: 2.40 | Eps(step=311765): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5768 | Return: 1.97 | Eps(step=311769): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5769 | Return: 1.71 | Eps(step=311774): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5770 | Return: 3.17 | Eps(step=311783): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5771 | Return: 1.45 | Eps(step=311789): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5772 | Return: 2.21 | Eps(step=311794): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5773 | Return: 2.45 | Eps(step=311800): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5774 | Return: 2.45 | Eps(step=311806): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5775 | Return: 1.71 | Eps(step=311811): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5776 | Return: 2.21 | Eps(step=311816): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5777 | Return: 2.67 | Eps(step=311825): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5778 | Return: 2.66 | Eps(step=311835): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5779 | Return: 1.97 | Eps(step=311839): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5780 | Return: 2.44 | Eps(step=311846): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5781 | Return: 1.89 | Eps(step=311858): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5782 | Return: 1.69 | Eps(step=311890): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5783 | Return: 1.49 | Eps(step=311892): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5784 | Return: 2.19 | Eps(step=311899): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5785 | Return: 1.49 | Eps(step=311901): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5786 | Return: 2.69 | Eps(step=311908): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5787 | Return: 1.47 | Eps(step=311912): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5788 | Return: 2.52 | Eps(step=311936): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5789 | Return: 3.13 | Eps(step=311949): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5790 | Return: 2.45 | Eps(step=311955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5791 | Return: 1.25 | Eps(step=311956): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5792 | Return: 2.21 | Eps(step=311961): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5793 | Return: 2.67 | Eps(step=311970): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5794 | Return: 1.95 | Eps(step=311976): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5795 | Return: 2.21 | Eps(step=311981): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5796 | Return: 2.10 | Eps(step=311997): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5797 | Return: 2.69 | Eps(step=312004): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5798 | Return: 2.39 | Eps(step=312016): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5799 | Return: 2.68 | Eps(step=312024): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5800 | Return: 2.41 | Eps(step=312034): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5801 | Return: 3.39 | Eps(step=312046): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5802 | Return: 1.73 | Eps(step=312049): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5803 | Return: 2.65 | Eps(step=312060): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5804 | Return: 1.73 | Eps(step=312063): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5805 | Return: 2.90 | Eps(step=312074): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5806 | Return: 2.58 | Eps(step=312088): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5807 | Return: 2.21 | Eps(step=312093): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5808 | Return: 1.97 | Eps(step=312097): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5809 | Return: 2.94 | Eps(step=312129): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5810 | Return: 1.97 | Eps(step=312133): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5811 | Return: 2.15 | Eps(step=312145): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5812 | Return: 2.45 | Eps(step=312151): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5813 | Return: 3.07 | Eps(step=312170): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5814 | Return: 3.15 | Eps(step=312181): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5815 | Return: 1.92 | Eps(step=312191): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5816 | Return: 2.04 | Eps(step=312213): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5817 | Return: 2.41 | Eps(step=312223): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5818 | Return: 3.16 | Eps(step=312233): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5819 | Return: 2.69 | Eps(step=312240): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5820 | Return: 2.67 | Eps(step=312249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5821 | Return: 2.45 | Eps(step=312255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5822 | Return: 1.25 | Eps(step=312256): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5823 | Return: 2.21 | Eps(step=312261): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5824 | Return: 2.14 | Eps(step=312273): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5825 | Return: 2.89 | Eps(step=312285): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5826 | Return: 2.44 | Eps(step=312292): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5827 | Return: 1.00 | Eps(step=312293): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5828 | Return: 1.73 | Eps(step=312296): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5829 | Return: 1.25 | Eps(step=312297): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5830 | Return: 2.19 | Eps(step=312304): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5831 | Return: 2.89 | Eps(step=312316): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5832 | Return: 1.39 | Eps(step=312353): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5833 | Return: 2.41 | Eps(step=312363): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5834 | Return: 1.25 | Eps(step=312364): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5835 | Return: 1.44 | Eps(step=312372): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5836 | Return: 1.97 | Eps(step=312376): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5837 | Return: 1.97 | Eps(step=312380): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5838 | Return: 3.65 | Eps(step=312391): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5839 | Return: 2.67 | Eps(step=312400): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5840 | Return: -21.96 | Eps(step=313400): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5841 | Return: 3.17 | Eps(step=313409): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5842 | Return: 1.67 | Eps(step=313418): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5843 | Return: 2.93 | Eps(step=313426): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5844 | Return: 1.25 | Eps(step=313427): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5845 | Return: -0.31 | Eps(step=313456): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5846 | Return: 1.49 | Eps(step=313458): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5847 | Return: 2.69 | Eps(step=313465): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5848 | Return: 2.43 | Eps(step=313473): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5849 | Return: 2.21 | Eps(step=313478): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5850 | Return: 1.00 | Eps(step=313479): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5851 | Return: 2.93 | Eps(step=313487): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5852 | Return: 2.67 | Eps(step=313496): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5853 | Return: 2.18 | Eps(step=313504): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5854 | Return: 1.73 | Eps(step=313507): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5855 | Return: 2.75 | Eps(step=313554): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5856 | Return: 2.91 | Eps(step=313564): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5857 | Return: 1.73 | Eps(step=313567): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5858 | Return: 1.49 | Eps(step=313569): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5859 | Return: 3.15 | Eps(step=313580): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5860 | Return: 1.73 | Eps(step=313583): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5861 | Return: 2.21 | Eps(step=313588): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5862 | Return: 0.04 | Eps(step=313648): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5863 | Return: 2.45 | Eps(step=313654): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5864 | Return: 1.97 | Eps(step=313658): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5865 | Return: 2.93 | Eps(step=313666): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5866 | Return: 2.69 | Eps(step=313673): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5867 | Return: 3.17 | Eps(step=313682): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5868 | Return: 1.92 | Eps(step=313692): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5869 | Return: 2.45 | Eps(step=313698): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5870 | Return: 1.73 | Eps(step=313701): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5871 | Return: 1.90 | Eps(step=313708): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5872 | Return: 2.38 | Eps(step=313722): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5873 | Return: 3.65 | Eps(step=313733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5874 | Return: 1.73 | Eps(step=313736): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5875 | Return: 2.21 | Eps(step=313741): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5876 | Return: 1.25 | Eps(step=313742): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5877 | Return: 2.43 | Eps(step=313750): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5878 | Return: 2.93 | Eps(step=313758): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5879 | Return: 1.37 | Eps(step=313769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5880 | Return: 1.96 | Eps(step=313774): 0.100 | AvgLoss: 0.0005\n",
            "Episode 5881 | Return: 1.95 | Eps(step=313780): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5882 | Return: 2.13 | Eps(step=313794): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5883 | Return: 2.21 | Eps(step=313799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5884 | Return: 3.41 | Eps(step=313809): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5885 | Return: 2.93 | Eps(step=313817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5886 | Return: 3.15 | Eps(step=313828): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5887 | Return: 3.17 | Eps(step=313837): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5888 | Return: 1.97 | Eps(step=313841): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5889 | Return: 2.69 | Eps(step=313848): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5890 | Return: 2.87 | Eps(step=313887): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5891 | Return: 2.37 | Eps(step=313897): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5892 | Return: 1.97 | Eps(step=313901): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5893 | Return: 2.69 | Eps(step=313908): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5894 | Return: -1.08 | Eps(step=314040): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5895 | Return: 1.71 | Eps(step=314045): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5896 | Return: 2.93 | Eps(step=314053): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5897 | Return: 0.20 | Eps(step=314073): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5898 | Return: 2.93 | Eps(step=314081): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5899 | Return: 1.73 | Eps(step=314084): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5900 | Return: 2.91 | Eps(step=314094): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5901 | Return: 1.93 | Eps(step=314102): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5902 | Return: 2.93 | Eps(step=314110): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5903 | Return: 2.45 | Eps(step=314116): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5904 | Return: 1.00 | Eps(step=314117): 0.100 | AvgLoss: 0.0004\n",
            "Episode 5905 | Return: 3.17 | Eps(step=314126): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5906 | Return: 1.00 | Eps(step=314127): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5907 | Return: 1.97 | Eps(step=314131): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5908 | Return: 1.97 | Eps(step=314135): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5909 | Return: 1.73 | Eps(step=314138): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5910 | Return: 2.12 | Eps(step=314148): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5911 | Return: 2.13 | Eps(step=314161): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5912 | Return: 2.93 | Eps(step=314169): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5913 | Return: 1.25 | Eps(step=314170): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5914 | Return: 1.67 | Eps(step=314180): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5915 | Return: 3.17 | Eps(step=314189): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5916 | Return: 2.93 | Eps(step=314197): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5917 | Return: 1.73 | Eps(step=314200): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5918 | Return: 2.68 | Eps(step=314208): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5919 | Return: 1.85 | Eps(step=314224): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5920 | Return: 2.69 | Eps(step=314231): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5921 | Return: 3.41 | Eps(step=314241): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5922 | Return: 3.41 | Eps(step=314251): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5923 | Return: 1.49 | Eps(step=314253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5924 | Return: 2.32 | Eps(step=314293): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5925 | Return: 2.69 | Eps(step=314300): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5926 | Return: -0.24 | Eps(step=314348): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5927 | Return: 2.42 | Eps(step=314357): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5928 | Return: 2.67 | Eps(step=314366): 0.100 | AvgLoss: 0.0003\n",
            "Episode 5929 | Return: 3.05 | Eps(step=314387): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5930 | Return: 3.15 | Eps(step=314398): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5931 | Return: 1.69 | Eps(step=314405): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5932 | Return: 1.42 | Eps(step=314415): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5933 | Return: 1.47 | Eps(step=314419): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5934 | Return: 2.42 | Eps(step=314428): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5935 | Return: 3.17 | Eps(step=314437): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5936 | Return: 2.08 | Eps(step=314451): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5937 | Return: 2.17 | Eps(step=314460): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5938 | Return: 2.45 | Eps(step=314466): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5939 | Return: 2.45 | Eps(step=314472): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5940 | Return: -4.80 | Eps(step=314674): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5941 | Return: 2.03 | Eps(step=314689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5942 | Return: 1.17 | Eps(step=314699): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5943 | Return: -26.73 | Eps(step=315699): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5944 | Return: 2.12 | Eps(step=315734): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5945 | Return: 2.69 | Eps(step=315741): 0.100 | AvgLoss: 0.0000\n",
            "Episode 5946 | Return: 0.78 | Eps(step=315790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5947 | Return: 1.69 | Eps(step=315797): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5948 | Return: 1.25 | Eps(step=315798): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5949 | Return: 3.15 | Eps(step=315809): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5950 | Return: 1.49 | Eps(step=315811): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5951 | Return: -1.52 | Eps(step=315863): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5952 | Return: 1.73 | Eps(step=315866): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5953 | Return: 2.45 | Eps(step=315872): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5954 | Return: 1.71 | Eps(step=315877): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5955 | Return: 1.73 | Eps(step=315880): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5956 | Return: 2.24 | Eps(step=315908): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5957 | Return: 2.69 | Eps(step=315915): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5958 | Return: 1.97 | Eps(step=315919): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5959 | Return: 2.43 | Eps(step=315927): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5960 | Return: 1.96 | Eps(step=315932): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5961 | Return: 2.87 | Eps(step=315946): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5962 | Return: 3.85 | Eps(step=315962): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5963 | Return: 2.45 | Eps(step=315968): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5964 | Return: 2.91 | Eps(step=315978): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5965 | Return: 1.64 | Eps(step=315986): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5966 | Return: 2.19 | Eps(step=315993): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5967 | Return: 1.47 | Eps(step=315997): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5968 | Return: 3.15 | Eps(step=316008): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5969 | Return: 3.89 | Eps(step=316020): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5970 | Return: 2.15 | Eps(step=316031): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5971 | Return: 2.41 | Eps(step=316041): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5972 | Return: 1.25 | Eps(step=316042): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5973 | Return: 1.47 | Eps(step=316046): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5974 | Return: 2.45 | Eps(step=316052): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5975 | Return: 1.00 | Eps(step=316053): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5976 | Return: 2.07 | Eps(step=316097): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5977 | Return: 1.00 | Eps(step=316098): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5978 | Return: 1.96 | Eps(step=316103): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5979 | Return: 0.18 | Eps(step=316113): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5980 | Return: 2.84 | Eps(step=316126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5981 | Return: 3.17 | Eps(step=316135): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5982 | Return: 2.19 | Eps(step=316142): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5983 | Return: 3.65 | Eps(step=316153): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5984 | Return: 1.20 | Eps(step=316160): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5985 | Return: 2.91 | Eps(step=316170): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5986 | Return: 1.16 | Eps(step=316176): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5987 | Return: 3.65 | Eps(step=316187): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5988 | Return: 2.15 | Eps(step=316198): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5989 | Return: 2.63 | Eps(step=316211): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5990 | Return: 1.49 | Eps(step=316213): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5991 | Return: 1.97 | Eps(step=316217): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5992 | Return: 2.44 | Eps(step=316224): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5993 | Return: 2.21 | Eps(step=316229): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5994 | Return: 2.65 | Eps(step=316240): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5995 | Return: 2.43 | Eps(step=316248): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5996 | Return: 2.21 | Eps(step=316253): 0.100 | AvgLoss: 0.0001\n",
            "Episode 5997 | Return: 2.68 | Eps(step=316261): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5998 | Return: 2.93 | Eps(step=316269): 0.100 | AvgLoss: 0.0002\n",
            "Episode 5999 | Return: 2.91 | Eps(step=316279): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6000 | Return: 3.30 | Eps(step=316300): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6001 | Return: 1.71 | Eps(step=316305): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6002 | Return: 2.19 | Eps(step=316312): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6003 | Return: 2.69 | Eps(step=316319): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6004 | Return: 1.72 | Eps(step=316323): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6005 | Return: 3.17 | Eps(step=316332): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6006 | Return: 2.65 | Eps(step=316343): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6007 | Return: 1.49 | Eps(step=316345): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6008 | Return: 2.45 | Eps(step=316351): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6009 | Return: 2.69 | Eps(step=316358): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6010 | Return: 1.91 | Eps(step=316368): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6011 | Return: 1.89 | Eps(step=316380): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6012 | Return: 1.25 | Eps(step=316381): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6013 | Return: 2.65 | Eps(step=316392): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6014 | Return: 2.21 | Eps(step=316397): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6015 | Return: 1.89 | Eps(step=316409): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6016 | Return: 1.25 | Eps(step=316410): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6017 | Return: 2.45 | Eps(step=316416): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6018 | Return: 1.49 | Eps(step=316418): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6019 | Return: 1.73 | Eps(step=316421): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6020 | Return: 3.16 | Eps(step=316431): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6021 | Return: 2.67 | Eps(step=316440): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6022 | Return: 3.17 | Eps(step=316449): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6023 | Return: 2.45 | Eps(step=316455): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6024 | Return: 1.25 | Eps(step=316456): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6025 | Return: 3.41 | Eps(step=316466): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6026 | Return: 3.41 | Eps(step=316476): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6027 | Return: 1.63 | Eps(step=316490): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6028 | Return: 3.61 | Eps(step=316505): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6029 | Return: 3.17 | Eps(step=316514): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6030 | Return: 2.21 | Eps(step=316519): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6031 | Return: 2.53 | Eps(step=316543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6032 | Return: 2.69 | Eps(step=316550): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6033 | Return: 3.17 | Eps(step=316559): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6034 | Return: 2.21 | Eps(step=316564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6035 | Return: 2.69 | Eps(step=316571): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6036 | Return: 2.69 | Eps(step=316578): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6037 | Return: 3.87 | Eps(step=316592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6038 | Return: 2.43 | Eps(step=316600): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6039 | Return: 2.45 | Eps(step=316606): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6040 | Return: 2.67 | Eps(step=316615): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6041 | Return: 1.95 | Eps(step=316621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6042 | Return: 3.41 | Eps(step=316631): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6043 | Return: 2.21 | Eps(step=316636): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6044 | Return: 2.69 | Eps(step=316643): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6045 | Return: 1.97 | Eps(step=316647): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6046 | Return: 1.25 | Eps(step=316648): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6047 | Return: 1.97 | Eps(step=316652): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6048 | Return: 1.00 | Eps(step=316653): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6049 | Return: 2.61 | Eps(step=316668): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6050 | Return: 1.49 | Eps(step=316670): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6051 | Return: 3.39 | Eps(step=316682): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6052 | Return: 1.73 | Eps(step=316685): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6053 | Return: 3.17 | Eps(step=316694): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6054 | Return: 2.93 | Eps(step=316702): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6055 | Return: 1.49 | Eps(step=316704): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6056 | Return: 2.21 | Eps(step=316709): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6057 | Return: 1.49 | Eps(step=316711): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6058 | Return: 1.32 | Eps(step=316722): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6059 | Return: 2.17 | Eps(step=316731): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6060 | Return: 1.97 | Eps(step=316735): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6061 | Return: 1.73 | Eps(step=316738): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6062 | Return: 2.69 | Eps(step=316745): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6063 | Return: 2.19 | Eps(step=316752): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6064 | Return: 2.21 | Eps(step=316757): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6065 | Return: 3.63 | Eps(step=316770): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6066 | Return: 1.71 | Eps(step=316775): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6067 | Return: 2.92 | Eps(step=316784): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6068 | Return: 0.72 | Eps(step=316789): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6069 | Return: 1.62 | Eps(step=316799): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6070 | Return: 2.44 | Eps(step=316806): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6071 | Return: 2.69 | Eps(step=316813): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6072 | Return: 3.41 | Eps(step=316848): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6073 | Return: 2.69 | Eps(step=316855): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6074 | Return: 2.49 | Eps(step=316882): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6075 | Return: 1.73 | Eps(step=316885): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6076 | Return: 1.25 | Eps(step=316886): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6077 | Return: 2.02 | Eps(step=316906): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6078 | Return: 1.73 | Eps(step=316909): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6079 | Return: 1.73 | Eps(step=316912): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6080 | Return: 2.69 | Eps(step=316919): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6081 | Return: 1.25 | Eps(step=316920): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6082 | Return: 2.31 | Eps(step=316940): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6083 | Return: 2.93 | Eps(step=316948): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6084 | Return: 2.21 | Eps(step=316953): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6085 | Return: 2.93 | Eps(step=316961): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6086 | Return: 2.21 | Eps(step=316966): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6087 | Return: 0.70 | Eps(step=316968): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6088 | Return: 1.97 | Eps(step=316972): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6089 | Return: 3.62 | Eps(step=316986): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6090 | Return: 1.97 | Eps(step=316990): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6091 | Return: 2.16 | Eps(step=317001): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6092 | Return: 1.99 | Eps(step=317020): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6093 | Return: 1.71 | Eps(step=317025): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6094 | Return: 2.64 | Eps(step=317038): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6095 | Return: 3.41 | Eps(step=317048): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6096 | Return: 2.16 | Eps(step=317058): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6097 | Return: 1.73 | Eps(step=317061): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6098 | Return: 1.97 | Eps(step=317065): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6099 | Return: 1.49 | Eps(step=317067): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6100 | Return: 2.91 | Eps(step=317077): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6101 | Return: 1.49 | Eps(step=317079): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6102 | Return: 1.00 | Eps(step=317080): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6103 | Return: 2.43 | Eps(step=317088): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6104 | Return: 2.45 | Eps(step=317094): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6105 | Return: 2.47 | Eps(step=317123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6106 | Return: 1.97 | Eps(step=317127): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6107 | Return: 3.63 | Eps(step=317140): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6108 | Return: 1.73 | Eps(step=317143): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6109 | Return: 1.97 | Eps(step=317147): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6110 | Return: 2.93 | Eps(step=317155): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6111 | Return: 1.97 | Eps(step=317159): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6112 | Return: 3.63 | Eps(step=317172): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6113 | Return: 1.25 | Eps(step=317173): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6114 | Return: 2.69 | Eps(step=317180): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6115 | Return: 1.73 | Eps(step=317183): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6116 | Return: 1.49 | Eps(step=317185): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6117 | Return: 3.41 | Eps(step=317195): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6118 | Return: 1.00 | Eps(step=317196): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6119 | Return: 2.59 | Eps(step=317213): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6120 | Return: 1.97 | Eps(step=317217): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6121 | Return: 2.12 | Eps(step=317232): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6122 | Return: 1.25 | Eps(step=317233): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6123 | Return: 2.38 | Eps(step=317242): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6124 | Return: 1.73 | Eps(step=317245): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6125 | Return: 1.97 | Eps(step=317249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6126 | Return: 3.17 | Eps(step=317258): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6127 | Return: 3.10 | Eps(step=317274): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6128 | Return: 1.18 | Eps(step=317278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6129 | Return: 1.97 | Eps(step=317282): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6130 | Return: 1.94 | Eps(step=317289): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6131 | Return: 3.17 | Eps(step=317298): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6132 | Return: 1.25 | Eps(step=317299): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6133 | Return: 2.93 | Eps(step=317307): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6134 | Return: 2.91 | Eps(step=317317): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6135 | Return: 1.97 | Eps(step=317321): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6136 | Return: 1.97 | Eps(step=317325): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6137 | Return: 1.97 | Eps(step=317329): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6138 | Return: 2.69 | Eps(step=317336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6139 | Return: 1.25 | Eps(step=317337): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6140 | Return: 2.21 | Eps(step=317342): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6141 | Return: 2.69 | Eps(step=317349): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6142 | Return: 1.73 | Eps(step=317352): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6143 | Return: 1.97 | Eps(step=317356): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6144 | Return: 2.15 | Eps(step=317367): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6145 | Return: 1.47 | Eps(step=317371): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6146 | Return: 3.39 | Eps(step=317383): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6147 | Return: 2.17 | Eps(step=317392): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6148 | Return: 2.63 | Eps(step=317405): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6149 | Return: 3.89 | Eps(step=317417): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6150 | Return: 2.21 | Eps(step=317422): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6151 | Return: 1.72 | Eps(step=317426): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6152 | Return: 2.69 | Eps(step=317433): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6153 | Return: 2.21 | Eps(step=317438): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6154 | Return: 3.39 | Eps(step=317450): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6155 | Return: 2.98 | Eps(step=317478): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6156 | Return: 2.67 | Eps(step=317487): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6157 | Return: 2.87 | Eps(step=317501): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6158 | Return: 3.17 | Eps(step=317510): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6159 | Return: 0.72 | Eps(step=317515): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6160 | Return: 3.14 | Eps(step=317527): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6161 | Return: 3.65 | Eps(step=317538): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6162 | Return: 2.91 | Eps(step=317548): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6163 | Return: 1.49 | Eps(step=317550): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6164 | Return: 2.24 | Eps(step=317578): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6165 | Return: 2.69 | Eps(step=317585): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6166 | Return: 2.21 | Eps(step=317590): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6167 | Return: 2.20 | Eps(step=317596): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6168 | Return: 2.20 | Eps(step=317602): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6169 | Return: 1.25 | Eps(step=317603): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6170 | Return: 1.88 | Eps(step=317612): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6171 | Return: 2.01 | Eps(step=317637): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6172 | Return: 2.45 | Eps(step=317643): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6173 | Return: 1.49 | Eps(step=317645): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6174 | Return: 2.21 | Eps(step=317650): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6175 | Return: 1.21 | Eps(step=317706): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6176 | Return: 3.17 | Eps(step=317715): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6177 | Return: 1.49 | Eps(step=317717): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6178 | Return: 2.19 | Eps(step=317724): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6179 | Return: 2.73 | Eps(step=317752): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6180 | Return: 2.27 | Eps(step=317776): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6181 | Return: 2.69 | Eps(step=317783): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6182 | Return: 2.69 | Eps(step=317790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6183 | Return: 2.84 | Eps(step=317803): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6184 | Return: 2.93 | Eps(step=317811): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6185 | Return: 2.38 | Eps(step=317820): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6186 | Return: 2.90 | Eps(step=317831): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6187 | Return: 3.39 | Eps(step=317843): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6188 | Return: 3.17 | Eps(step=317852): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6189 | Return: 2.69 | Eps(step=317859): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6190 | Return: 1.00 | Eps(step=317860): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6191 | Return: 3.17 | Eps(step=317869): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6192 | Return: 2.18 | Eps(step=317877): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6193 | Return: 2.69 | Eps(step=317884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6194 | Return: 1.73 | Eps(step=317887): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6195 | Return: 3.17 | Eps(step=317896): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6196 | Return: 2.21 | Eps(step=317901): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6197 | Return: 2.75 | Eps(step=317923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6198 | Return: 3.89 | Eps(step=317935): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6199 | Return: 2.21 | Eps(step=317940): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6200 | Return: 1.25 | Eps(step=317941): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6201 | Return: 2.93 | Eps(step=317949): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6202 | Return: 3.15 | Eps(step=317960): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6203 | Return: 1.73 | Eps(step=317963): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6204 | Return: 1.97 | Eps(step=317967): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6205 | Return: 2.69 | Eps(step=317974): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6206 | Return: 1.97 | Eps(step=317978): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6207 | Return: 1.73 | Eps(step=317981): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6208 | Return: 2.21 | Eps(step=317986): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6209 | Return: 2.40 | Eps(step=318022): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6210 | Return: 0.17 | Eps(step=318033): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6211 | Return: 1.97 | Eps(step=318037): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6212 | Return: 2.69 | Eps(step=318044): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6213 | Return: 2.91 | Eps(step=318054): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6214 | Return: 3.65 | Eps(step=318065): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6215 | Return: 2.21 | Eps(step=318070): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6216 | Return: 1.23 | Eps(step=318073): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6217 | Return: 1.97 | Eps(step=318077): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6218 | Return: -20.28 | Eps(step=319077): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6219 | Return: 2.25 | Eps(step=319103): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6220 | Return: 1.73 | Eps(step=319106): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6221 | Return: 1.64 | Eps(step=319243): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6222 | Return: 1.73 | Eps(step=319246): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6223 | Return: 1.25 | Eps(step=319247): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6224 | Return: 2.63 | Eps(step=319260): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6225 | Return: 1.00 | Eps(step=319261): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6226 | Return: 2.21 | Eps(step=319266): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6227 | Return: 1.00 | Eps(step=319267): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6228 | Return: 0.40 | Eps(step=319453): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6229 | Return: 1.97 | Eps(step=319457): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6230 | Return: 3.65 | Eps(step=319468): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6231 | Return: 1.64 | Eps(step=319476): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6232 | Return: 3.15 | Eps(step=319487): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6233 | Return: 1.97 | Eps(step=319491): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6234 | Return: 2.21 | Eps(step=319496): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6235 | Return: 2.87 | Eps(step=319510): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6236 | Return: 1.25 | Eps(step=319511): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6237 | Return: 1.97 | Eps(step=319515): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6238 | Return: 2.45 | Eps(step=319521): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6239 | Return: 1.97 | Eps(step=319525): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6240 | Return: 2.69 | Eps(step=319532): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6241 | Return: 2.21 | Eps(step=319537): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6242 | Return: 3.17 | Eps(step=319546): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6243 | Return: 2.91 | Eps(step=319556): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6244 | Return: 1.73 | Eps(step=319559): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6245 | Return: 2.21 | Eps(step=319564): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6246 | Return: 2.66 | Eps(step=319574): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6247 | Return: 2.44 | Eps(step=319581): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6248 | Return: 2.45 | Eps(step=319587): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6249 | Return: 3.17 | Eps(step=319596): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6250 | Return: 2.69 | Eps(step=319603): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6251 | Return: 3.17 | Eps(step=319612): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6252 | Return: 3.41 | Eps(step=319622): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6253 | Return: 2.43 | Eps(step=319630): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6254 | Return: 1.93 | Eps(step=319638): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6255 | Return: 2.19 | Eps(step=319645): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6256 | Return: 2.93 | Eps(step=319653): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6257 | Return: 2.67 | Eps(step=319662): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6258 | Return: 0.46 | Eps(step=319668): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6259 | Return: 1.62 | Eps(step=319678): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6260 | Return: 3.17 | Eps(step=319687): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6261 | Return: 2.45 | Eps(step=319693): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6262 | Return: 2.65 | Eps(step=319704): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6263 | Return: 1.73 | Eps(step=319707): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6264 | Return: 3.63 | Eps(step=319720): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6265 | Return: 1.25 | Eps(step=319721): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6266 | Return: 2.69 | Eps(step=319728): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6267 | Return: 1.73 | Eps(step=319731): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6268 | Return: 2.93 | Eps(step=319739): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6269 | Return: -11.70 | Eps(step=320219): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6270 | Return: 2.93 | Eps(step=320227): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6271 | Return: 3.33 | Eps(step=320245): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6272 | Return: 0.92 | Eps(step=320250): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6273 | Return: -0.06 | Eps(step=320305): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6274 | Return: 2.08 | Eps(step=320323): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6275 | Return: 1.49 | Eps(step=320325): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6276 | Return: 2.44 | Eps(step=320332): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6277 | Return: 2.93 | Eps(step=320340): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6278 | Return: 2.69 | Eps(step=320347): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6279 | Return: 1.73 | Eps(step=320350): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6280 | Return: 2.69 | Eps(step=320357): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6281 | Return: 2.62 | Eps(step=320367): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6282 | Return: 3.02 | Eps(step=320466): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6283 | Return: 2.11 | Eps(step=320481): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6284 | Return: 1.49 | Eps(step=320483): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6285 | Return: 2.11 | Eps(step=320498): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6286 | Return: -0.37 | Eps(step=320558): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6287 | Return: 3.41 | Eps(step=320568): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6288 | Return: 2.45 | Eps(step=320574): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6289 | Return: 2.81 | Eps(step=320594): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6290 | Return: 3.41 | Eps(step=320604): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6291 | Return: 1.97 | Eps(step=320608): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6292 | Return: 3.41 | Eps(step=320618): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6293 | Return: 0.44 | Eps(step=320621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6294 | Return: 1.97 | Eps(step=320625): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6295 | Return: 3.23 | Eps(step=320678): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6296 | Return: 3.17 | Eps(step=320687): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6297 | Return: 2.86 | Eps(step=320702): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6298 | Return: 2.43 | Eps(step=320710): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6299 | Return: 2.45 | Eps(step=320716): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6300 | Return: 1.49 | Eps(step=320718): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6301 | Return: 2.95 | Eps(step=320749): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6302 | Return: 1.49 | Eps(step=320751): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6303 | Return: 2.69 | Eps(step=320758): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6304 | Return: 1.95 | Eps(step=320764): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6305 | Return: 2.21 | Eps(step=320769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6306 | Return: 0.20 | Eps(step=320777): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6307 | Return: 2.69 | Eps(step=320784): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6308 | Return: 2.93 | Eps(step=320792): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6309 | Return: -2.86 | Eps(step=321028): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6310 | Return: 0.60 | Eps(step=321070): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6311 | Return: 1.67 | Eps(step=321079): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6312 | Return: 2.21 | Eps(step=321084): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6313 | Return: 0.74 | Eps(step=321104): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6314 | Return: 2.20 | Eps(step=321135): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6315 | Return: 1.25 | Eps(step=321136): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6316 | Return: 2.21 | Eps(step=321141): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6317 | Return: 1.49 | Eps(step=321143): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6318 | Return: 0.69 | Eps(step=321146): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6319 | Return: 2.81 | Eps(step=321166): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6320 | Return: 1.25 | Eps(step=321167): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6321 | Return: 1.00 | Eps(step=321168): 0.100 | AvgLoss: 0.0007\n",
            "Episode 6322 | Return: 2.21 | Eps(step=321173): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6323 | Return: 2.69 | Eps(step=321180): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6324 | Return: 1.20 | Eps(step=321187): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6325 | Return: 1.97 | Eps(step=321191): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6326 | Return: 2.91 | Eps(step=321201): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6327 | Return: 1.93 | Eps(step=321209): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6328 | Return: 1.73 | Eps(step=321212): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6329 | Return: 2.11 | Eps(step=321227): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6330 | Return: 2.40 | Eps(step=321259): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6331 | Return: 1.95 | Eps(step=321265): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6332 | Return: 1.92 | Eps(step=321291): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6333 | Return: 2.12 | Eps(step=321330): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6334 | Return: 1.97 | Eps(step=321334): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6335 | Return: 1.16 | Eps(step=321340): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6336 | Return: 2.69 | Eps(step=321347): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6337 | Return: 1.16 | Eps(step=321353): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6338 | Return: 1.66 | Eps(step=321359): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6339 | Return: 1.00 | Eps(step=321360): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6340 | Return: 2.69 | Eps(step=321367): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6341 | Return: 2.69 | Eps(step=321374): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6342 | Return: 2.21 | Eps(step=321379): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6343 | Return: 2.76 | Eps(step=321404): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6344 | Return: 1.83 | Eps(step=321422): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6345 | Return: 3.87 | Eps(step=321436): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6346 | Return: 2.61 | Eps(step=321451): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6347 | Return: 1.73 | Eps(step=321454): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6348 | Return: 3.15 | Eps(step=321465): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6349 | Return: 2.93 | Eps(step=321473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6350 | Return: 2.45 | Eps(step=321479): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6351 | Return: 1.95 | Eps(step=321485): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6352 | Return: 2.45 | Eps(step=321491): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6353 | Return: 2.91 | Eps(step=321501): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6354 | Return: 0.94 | Eps(step=321504): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6355 | Return: 1.05 | Eps(step=321546): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6356 | Return: -0.33 | Eps(step=321557): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6357 | Return: 1.90 | Eps(step=321569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6358 | Return: 2.75 | Eps(step=321595): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6359 | Return: 1.95 | Eps(step=321601): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6360 | Return: 3.40 | Eps(step=321612): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6361 | Return: 1.49 | Eps(step=321614): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6362 | Return: 1.25 | Eps(step=321615): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6363 | Return: 2.12 | Eps(step=321625): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6364 | Return: 1.97 | Eps(step=321629): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6365 | Return: 2.45 | Eps(step=321635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6366 | Return: 2.69 | Eps(step=321642): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6367 | Return: 1.44 | Eps(step=321650): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6368 | Return: 3.41 | Eps(step=321660): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6369 | Return: 2.21 | Eps(step=321665): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6370 | Return: 2.93 | Eps(step=321673): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6371 | Return: 2.43 | Eps(step=321681): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6372 | Return: 2.69 | Eps(step=321688): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6373 | Return: 1.00 | Eps(step=321689): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6374 | Return: 3.89 | Eps(step=321701): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6375 | Return: 1.97 | Eps(step=321705): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6376 | Return: 3.36 | Eps(step=321720): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6377 | Return: 1.97 | Eps(step=321724): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6378 | Return: 2.21 | Eps(step=321729): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6379 | Return: 1.56 | Eps(step=321746): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6380 | Return: 0.40 | Eps(step=321759): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6381 | Return: 2.02 | Eps(step=321779): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6382 | Return: 1.97 | Eps(step=321783): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6383 | Return: 1.49 | Eps(step=321785): 0.100 | AvgLoss: 0.0007\n",
            "Episode 6384 | Return: 2.67 | Eps(step=321794): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6385 | Return: 1.03 | Eps(step=321817): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6386 | Return: 2.69 | Eps(step=321824): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6387 | Return: 2.21 | Eps(step=321829): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6388 | Return: 2.45 | Eps(step=321835): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6389 | Return: 1.25 | Eps(step=321836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6390 | Return: 2.93 | Eps(step=321844): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6391 | Return: 2.17 | Eps(step=321853): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6392 | Return: 1.71 | Eps(step=321858): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6393 | Return: 1.16 | Eps(step=321869): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6394 | Return: 2.20 | Eps(step=321875): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6395 | Return: 1.25 | Eps(step=321876): 0.100 | AvgLoss: 0.0008\n",
            "Episode 6396 | Return: 2.67 | Eps(step=321885): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6397 | Return: 1.97 | Eps(step=321889): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6398 | Return: 2.92 | Eps(step=321898): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6399 | Return: 3.17 | Eps(step=321907): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6400 | Return: -0.30 | Eps(step=321915): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6401 | Return: 2.19 | Eps(step=321922): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6402 | Return: 1.16 | Eps(step=321928): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6403 | Return: 3.41 | Eps(step=321938): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6404 | Return: 2.45 | Eps(step=321944): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6405 | Return: 3.41 | Eps(step=321954): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6406 | Return: 3.37 | Eps(step=321968): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6407 | Return: 1.66 | Eps(step=321974): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6408 | Return: 2.21 | Eps(step=321979): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6409 | Return: 1.25 | Eps(step=321980): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6410 | Return: 3.30 | Eps(step=322026): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6411 | Return: 2.41 | Eps(step=322057): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6412 | Return: 2.16 | Eps(step=322068): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6413 | Return: 1.73 | Eps(step=322071): 0.100 | AvgLoss: 0.0004\n",
            "Episode 6414 | Return: 0.71 | Eps(step=322077): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6415 | Return: 1.67 | Eps(step=322086): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6416 | Return: 1.25 | Eps(step=322087): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6417 | Return: 1.97 | Eps(step=322091): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6418 | Return: 0.20 | Eps(step=322099): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6419 | Return: 1.48 | Eps(step=322102): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6420 | Return: 2.43 | Eps(step=322110): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6421 | Return: 2.21 | Eps(step=322115): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6422 | Return: 1.25 | Eps(step=322116): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6423 | Return: 3.65 | Eps(step=322127): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6424 | Return: 3.41 | Eps(step=322137): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6425 | Return: 2.45 | Eps(step=322143): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6426 | Return: 2.67 | Eps(step=322152): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6427 | Return: 2.67 | Eps(step=322161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6428 | Return: 2.19 | Eps(step=322168): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6429 | Return: 2.93 | Eps(step=322176): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6430 | Return: 2.45 | Eps(step=322182): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6431 | Return: 2.21 | Eps(step=322187): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6432 | Return: 3.17 | Eps(step=322196): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6433 | Return: 3.65 | Eps(step=322207): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6434 | Return: 1.62 | Eps(step=322217): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6435 | Return: 1.84 | Eps(step=322235): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6436 | Return: 2.41 | Eps(step=322245): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6437 | Return: 2.93 | Eps(step=322253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6438 | Return: 2.67 | Eps(step=322262): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6439 | Return: 1.49 | Eps(step=322264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6440 | Return: 1.73 | Eps(step=322267): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6441 | Return: 2.91 | Eps(step=322277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6442 | Return: 3.87 | Eps(step=322291): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6443 | Return: 2.43 | Eps(step=322299): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6444 | Return: 1.72 | Eps(step=322303): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6445 | Return: 1.97 | Eps(step=322307): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6446 | Return: 2.67 | Eps(step=322316): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6447 | Return: 1.95 | Eps(step=322322): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6448 | Return: 3.17 | Eps(step=322331): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6449 | Return: 3.41 | Eps(step=322341): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6450 | Return: 2.93 | Eps(step=322349): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6451 | Return: 3.39 | Eps(step=322361): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6452 | Return: 2.43 | Eps(step=322369): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6453 | Return: 1.97 | Eps(step=322373): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6454 | Return: 1.00 | Eps(step=322374): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6455 | Return: 2.92 | Eps(step=322383): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6456 | Return: 2.61 | Eps(step=322398): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6457 | Return: 3.14 | Eps(step=322410): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6458 | Return: 1.95 | Eps(step=322416): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6459 | Return: 2.43 | Eps(step=322424): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6460 | Return: 2.45 | Eps(step=322430): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6461 | Return: 2.69 | Eps(step=322437): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6462 | Return: 1.97 | Eps(step=322441): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6463 | Return: 1.97 | Eps(step=322445): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6464 | Return: 2.14 | Eps(step=322453): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6465 | Return: 2.69 | Eps(step=322460): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6466 | Return: 2.68 | Eps(step=322468): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6467 | Return: 1.97 | Eps(step=322472): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6468 | Return: 3.14 | Eps(step=322484): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6469 | Return: 3.11 | Eps(step=322499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6470 | Return: 1.25 | Eps(step=322500): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6471 | Return: 1.73 | Eps(step=322503): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6472 | Return: 2.69 | Eps(step=322510): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6473 | Return: 3.39 | Eps(step=322522): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6474 | Return: 1.25 | Eps(step=322523): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6475 | Return: 2.69 | Eps(step=322530): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6476 | Return: 2.21 | Eps(step=322535): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6477 | Return: 1.42 | Eps(step=322545): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6478 | Return: 2.93 | Eps(step=322553): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6479 | Return: 3.15 | Eps(step=322564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6480 | Return: 3.15 | Eps(step=322575): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6481 | Return: -3.07 | Eps(step=322871): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6482 | Return: 2.43 | Eps(step=322879): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6483 | Return: 3.15 | Eps(step=322890): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6484 | Return: 1.49 | Eps(step=322892): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6485 | Return: 2.67 | Eps(step=322901): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6486 | Return: 3.65 | Eps(step=322912): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6487 | Return: 3.13 | Eps(step=322925): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6488 | Return: 2.89 | Eps(step=322937): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6489 | Return: 3.65 | Eps(step=322948): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6490 | Return: 3.17 | Eps(step=322957): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6491 | Return: 2.36 | Eps(step=322968): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6492 | Return: 1.97 | Eps(step=322972): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6493 | Return: 2.93 | Eps(step=322980): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6494 | Return: 2.47 | Eps(step=323009): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6495 | Return: 3.65 | Eps(step=323020): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6496 | Return: 3.17 | Eps(step=323029): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6497 | Return: 2.91 | Eps(step=323039): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6498 | Return: 2.93 | Eps(step=323047): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6499 | Return: 1.25 | Eps(step=323048): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6500 | Return: 1.97 | Eps(step=323052): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6501 | Return: 3.14 | Eps(step=323064): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6502 | Return: 3.41 | Eps(step=323074): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6503 | Return: 2.69 | Eps(step=323081): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6504 | Return: 2.34 | Eps(step=323098): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6505 | Return: 2.29 | Eps(step=323120): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6506 | Return: 2.11 | Eps(step=323135): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6507 | Return: 2.91 | Eps(step=323145): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6508 | Return: 2.45 | Eps(step=323151): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6509 | Return: 1.97 | Eps(step=323155): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6510 | Return: 2.67 | Eps(step=323164): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6511 | Return: 3.88 | Eps(step=323177): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6512 | Return: 2.44 | Eps(step=323184): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6513 | Return: 3.10 | Eps(step=323225): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6514 | Return: 3.07 | Eps(step=323244): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6515 | Return: 1.71 | Eps(step=323249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6516 | Return: 1.64 | Eps(step=323257): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6517 | Return: 3.39 | Eps(step=323269): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6518 | Return: 3.49 | Eps(step=323296): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6519 | Return: 2.07 | Eps(step=323316): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6520 | Return: 2.21 | Eps(step=323321): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6521 | Return: 2.67 | Eps(step=323330): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6522 | Return: 2.19 | Eps(step=323337): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6523 | Return: 1.71 | Eps(step=323342): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6524 | Return: 3.65 | Eps(step=323353): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6525 | Return: 2.41 | Eps(step=323363): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6526 | Return: 0.70 | Eps(step=323370): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6527 | Return: 2.93 | Eps(step=323378): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6528 | Return: 3.41 | Eps(step=323388): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6529 | Return: 2.45 | Eps(step=323394): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6530 | Return: 3.41 | Eps(step=323404): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6531 | Return: 3.17 | Eps(step=323413): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6532 | Return: 2.43 | Eps(step=323421): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6533 | Return: 2.93 | Eps(step=323429): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6534 | Return: 3.65 | Eps(step=323440): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6535 | Return: 2.68 | Eps(step=323448): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6536 | Return: 3.41 | Eps(step=323458): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6537 | Return: 2.58 | Eps(step=323472): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6538 | Return: 2.36 | Eps(step=323483): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6539 | Return: 2.44 | Eps(step=323490): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6540 | Return: 2.21 | Eps(step=323495): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6541 | Return: 1.97 | Eps(step=323499): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6542 | Return: 2.58 | Eps(step=323513): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6543 | Return: 1.47 | Eps(step=323517): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6544 | Return: 3.41 | Eps(step=323527): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6545 | Return: 1.00 | Eps(step=323528): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6546 | Return: 1.97 | Eps(step=323532): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6547 | Return: 1.81 | Eps(step=323549): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6548 | Return: 2.21 | Eps(step=323554): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6549 | Return: 2.45 | Eps(step=323560): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6550 | Return: 2.19 | Eps(step=323567): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6551 | Return: 2.90 | Eps(step=323578): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6552 | Return: 1.73 | Eps(step=323581): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6553 | Return: 2.45 | Eps(step=323587): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6554 | Return: 3.41 | Eps(step=323597): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6555 | Return: 3.17 | Eps(step=323606): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6556 | Return: 1.00 | Eps(step=323607): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6557 | Return: 2.67 | Eps(step=323616): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6558 | Return: 2.20 | Eps(step=323622): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6559 | Return: 2.45 | Eps(step=323628): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6560 | Return: 2.69 | Eps(step=323635): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6561 | Return: 1.73 | Eps(step=323638): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6562 | Return: 2.19 | Eps(step=323645): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6563 | Return: 3.17 | Eps(step=323654): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6564 | Return: 3.88 | Eps(step=323667): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6565 | Return: 1.05 | Eps(step=323681): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6566 | Return: 3.17 | Eps(step=323690): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6567 | Return: 2.93 | Eps(step=323698): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6568 | Return: 3.13 | Eps(step=323711): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6569 | Return: 1.47 | Eps(step=323715): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6570 | Return: 1.97 | Eps(step=323719): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6571 | Return: 2.43 | Eps(step=323727): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6572 | Return: 2.93 | Eps(step=323735): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6573 | Return: 2.45 | Eps(step=323741): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6574 | Return: 2.19 | Eps(step=323748): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6575 | Return: 1.73 | Eps(step=323751): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6576 | Return: 1.49 | Eps(step=323753): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6577 | Return: 2.93 | Eps(step=323761): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6578 | Return: 2.18 | Eps(step=323769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6579 | Return: 3.17 | Eps(step=323778): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6580 | Return: 2.45 | Eps(step=323784): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6581 | Return: 1.73 | Eps(step=323787): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6582 | Return: 1.61 | Eps(step=323798): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6583 | Return: 2.69 | Eps(step=323805): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6584 | Return: 2.89 | Eps(step=323817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6585 | Return: 2.21 | Eps(step=323822): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6586 | Return: 1.47 | Eps(step=323826): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6587 | Return: 2.93 | Eps(step=323834): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6588 | Return: 1.95 | Eps(step=323840): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6589 | Return: 2.69 | Eps(step=323847): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6590 | Return: 2.38 | Eps(step=323856): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6591 | Return: 1.49 | Eps(step=323858): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6592 | Return: 1.13 | Eps(step=323888): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6593 | Return: 1.97 | Eps(step=323892): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6594 | Return: 1.02 | Eps(step=323912): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6595 | Return: 3.65 | Eps(step=323923): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6596 | Return: 0.94 | Eps(step=323931): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6597 | Return: 2.93 | Eps(step=323939): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6598 | Return: 1.25 | Eps(step=323940): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6599 | Return: 2.12 | Eps(step=323954): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6600 | Return: 2.63 | Eps(step=323967): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6601 | Return: 1.25 | Eps(step=323968): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6602 | Return: 0.59 | Eps(step=324106): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6603 | Return: 2.21 | Eps(step=324111): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6604 | Return: 1.49 | Eps(step=324113): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6605 | Return: 1.47 | Eps(step=324117): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6606 | Return: 3.16 | Eps(step=324127): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6607 | Return: 3.41 | Eps(step=324137): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6608 | Return: 2.43 | Eps(step=324145): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6609 | Return: 1.73 | Eps(step=324148): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6610 | Return: 1.67 | Eps(step=324182): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6611 | Return: 2.21 | Eps(step=324187): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6612 | Return: 3.15 | Eps(step=324198): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6613 | Return: 1.49 | Eps(step=324200): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6614 | Return: 2.21 | Eps(step=324205): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6615 | Return: 2.93 | Eps(step=324213): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6616 | Return: 2.21 | Eps(step=324218): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6617 | Return: 1.66 | Eps(step=324224): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6618 | Return: 2.66 | Eps(step=324234): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6619 | Return: 0.36 | Eps(step=324241): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6620 | Return: 2.92 | Eps(step=324250): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6621 | Return: 1.49 | Eps(step=324252): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6622 | Return: 1.25 | Eps(step=324253): 0.100 | AvgLoss: 0.0003\n",
            "Episode 6623 | Return: 1.25 | Eps(step=324254): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6624 | Return: 2.91 | Eps(step=324264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6625 | Return: 2.69 | Eps(step=324271): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6626 | Return: 2.69 | Eps(step=324278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6627 | Return: -12.19 | Eps(step=324782): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6628 | Return: 1.83 | Eps(step=324800): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6629 | Return: 2.21 | Eps(step=324805): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6630 | Return: 1.84 | Eps(step=324823): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6631 | Return: 2.93 | Eps(step=324831): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6632 | Return: 1.00 | Eps(step=324832): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6633 | Return: 0.40 | Eps(step=324870): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6634 | Return: 2.65 | Eps(step=324881): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6635 | Return: 3.41 | Eps(step=324891): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6636 | Return: 0.32 | Eps(step=324932): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6637 | Return: 3.41 | Eps(step=324942): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6638 | Return: 2.67 | Eps(step=324976): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6639 | Return: 1.73 | Eps(step=324979): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6640 | Return: 3.38 | Eps(step=324992): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6641 | Return: 1.95 | Eps(step=324998): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6642 | Return: 1.71 | Eps(step=325003): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6643 | Return: 3.17 | Eps(step=325012): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6644 | Return: 1.44 | Eps(step=325020): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6645 | Return: 1.93 | Eps(step=325028): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6646 | Return: 0.92 | Eps(step=325033): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6647 | Return: 2.45 | Eps(step=325039): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6648 | Return: 1.73 | Eps(step=325042): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6649 | Return: 2.90 | Eps(step=325053): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6650 | Return: 1.31 | Eps(step=325094): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6651 | Return: 2.15 | Eps(step=325105): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6652 | Return: 1.47 | Eps(step=325109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6653 | Return: 2.21 | Eps(step=325114): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6654 | Return: 1.42 | Eps(step=325119): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6655 | Return: 2.21 | Eps(step=325124): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6656 | Return: 2.03 | Eps(step=325147): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6657 | Return: 1.25 | Eps(step=325148): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6658 | Return: 2.19 | Eps(step=325155): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6659 | Return: 1.71 | Eps(step=325160): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6660 | Return: 3.85 | Eps(step=325176): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6661 | Return: 2.93 | Eps(step=325184): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6662 | Return: 2.69 | Eps(step=325191): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6663 | Return: 2.12 | Eps(step=325201): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6664 | Return: 2.85 | Eps(step=325238): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6665 | Return: 2.69 | Eps(step=325245): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6666 | Return: 0.93 | Eps(step=325249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6667 | Return: 2.69 | Eps(step=325256): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6668 | Return: 2.21 | Eps(step=325261): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6669 | Return: 2.45 | Eps(step=325267): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6670 | Return: 2.93 | Eps(step=325275): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6671 | Return: 2.92 | Eps(step=325284): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6672 | Return: 2.43 | Eps(step=325292): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6673 | Return: 2.45 | Eps(step=325298): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6674 | Return: 2.80 | Eps(step=325319): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6675 | Return: 3.87 | Eps(step=325333): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6676 | Return: 2.40 | Eps(step=325344): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6677 | Return: 2.93 | Eps(step=325352): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6678 | Return: 1.92 | Eps(step=325361): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6679 | Return: 3.62 | Eps(step=325375): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6680 | Return: 0.96 | Eps(step=325381): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6681 | Return: 3.16 | Eps(step=325391): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6682 | Return: 3.51 | Eps(step=325416): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6683 | Return: 2.45 | Eps(step=325422): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6684 | Return: 3.41 | Eps(step=325432): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6685 | Return: 2.91 | Eps(step=325442): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6686 | Return: 1.72 | Eps(step=325446): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6687 | Return: 1.97 | Eps(step=325450): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6688 | Return: 2.21 | Eps(step=325455): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6689 | Return: 2.21 | Eps(step=325460): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6690 | Return: 1.89 | Eps(step=325472): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6691 | Return: 2.63 | Eps(step=325485): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6692 | Return: 2.43 | Eps(step=325493): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6693 | Return: 3.40 | Eps(step=325504): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6694 | Return: 2.43 | Eps(step=325512): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6695 | Return: 1.00 | Eps(step=325513): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6696 | Return: 1.25 | Eps(step=325514): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6697 | Return: 2.33 | Eps(step=325532): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6698 | Return: 1.63 | Eps(step=325545): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6699 | Return: 1.36 | Eps(step=325556): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6700 | Return: 1.71 | Eps(step=325561): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6701 | Return: 1.49 | Eps(step=325563): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6702 | Return: 3.65 | Eps(step=325574): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6703 | Return: 2.69 | Eps(step=325581): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6704 | Return: 2.45 | Eps(step=325587): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6705 | Return: 1.00 | Eps(step=325588): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6706 | Return: 2.93 | Eps(step=325596): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6707 | Return: 1.25 | Eps(step=325597): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6708 | Return: 2.21 | Eps(step=325602): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6709 | Return: 1.49 | Eps(step=325604): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6710 | Return: 1.73 | Eps(step=325607): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6711 | Return: 3.16 | Eps(step=325617): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6712 | Return: 3.65 | Eps(step=325628): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6713 | Return: 1.69 | Eps(step=325635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6714 | Return: 2.43 | Eps(step=325643): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6715 | Return: 2.93 | Eps(step=325651): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6716 | Return: 3.17 | Eps(step=325660): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6717 | Return: 2.93 | Eps(step=325668): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6718 | Return: 2.21 | Eps(step=325673): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6719 | Return: 3.15 | Eps(step=325684): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6720 | Return: 3.65 | Eps(step=325695): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6721 | Return: 2.61 | Eps(step=325706): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6722 | Return: 1.95 | Eps(step=325712): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6723 | Return: 2.43 | Eps(step=325720): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6724 | Return: 2.20 | Eps(step=325751): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6725 | Return: 2.69 | Eps(step=325758): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6726 | Return: 1.71 | Eps(step=325763): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6727 | Return: -0.75 | Eps(step=325831): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6728 | Return: 1.25 | Eps(step=325832): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6729 | Return: 0.48 | Eps(step=325836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6730 | Return: 3.17 | Eps(step=325845): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6731 | Return: 1.97 | Eps(step=325849): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6732 | Return: 3.17 | Eps(step=325858): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6733 | Return: 2.20 | Eps(step=325864): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6734 | Return: 1.73 | Eps(step=325867): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6735 | Return: 3.89 | Eps(step=325879): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6736 | Return: 2.65 | Eps(step=325890): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6737 | Return: 1.49 | Eps(step=325892): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6738 | Return: 2.21 | Eps(step=325897): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6739 | Return: 3.17 | Eps(step=325906): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6740 | Return: 1.91 | Eps(step=325916): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6741 | Return: 2.21 | Eps(step=325921): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6742 | Return: 3.65 | Eps(step=325932): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6743 | Return: 1.49 | Eps(step=325934): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6744 | Return: 2.21 | Eps(step=325939): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6745 | Return: 2.93 | Eps(step=325947): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6746 | Return: 2.43 | Eps(step=325955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6747 | Return: 2.21 | Eps(step=325960): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6748 | Return: 1.96 | Eps(step=325965): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6749 | Return: 3.89 | Eps(step=325977): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6750 | Return: 3.17 | Eps(step=325986): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6751 | Return: 2.93 | Eps(step=325994): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6752 | Return: 2.21 | Eps(step=325999): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6753 | Return: 3.17 | Eps(step=326008): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6754 | Return: 1.66 | Eps(step=326019): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6755 | Return: 1.17 | Eps(step=326029): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6756 | Return: 1.98 | Eps(step=326082): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6757 | Return: 2.21 | Eps(step=326087): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6758 | Return: 1.97 | Eps(step=326091): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6759 | Return: 2.45 | Eps(step=326097): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6760 | Return: 1.23 | Eps(step=326100): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6761 | Return: 2.80 | Eps(step=326122): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6762 | Return: 1.71 | Eps(step=326127): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6763 | Return: 2.67 | Eps(step=326136): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6764 | Return: 1.73 | Eps(step=326139): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6765 | Return: 1.97 | Eps(step=326143): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6766 | Return: 2.19 | Eps(step=326150): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6767 | Return: 2.21 | Eps(step=326155): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6768 | Return: 2.39 | Eps(step=326168): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6769 | Return: 2.45 | Eps(step=326174): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6770 | Return: 3.17 | Eps(step=326183): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6771 | Return: 2.21 | Eps(step=326188): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6772 | Return: 2.45 | Eps(step=326194): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6773 | Return: 1.00 | Eps(step=326195): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6774 | Return: 2.69 | Eps(step=326202): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6775 | Return: 3.00 | Eps(step=326228): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6776 | Return: 1.73 | Eps(step=326231): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6777 | Return: 1.71 | Eps(step=326236): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6778 | Return: 3.17 | Eps(step=326245): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6779 | Return: 1.93 | Eps(step=326253): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6780 | Return: 2.42 | Eps(step=326262): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6781 | Return: 0.38 | Eps(step=326277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6782 | Return: 2.91 | Eps(step=326287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6783 | Return: 2.19 | Eps(step=326294): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6784 | Return: 2.11 | Eps(step=326305): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6785 | Return: 3.17 | Eps(step=326314): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6786 | Return: 2.88 | Eps(step=326328): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6787 | Return: 1.93 | Eps(step=326336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6788 | Return: 1.95 | Eps(step=326342): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6789 | Return: 2.93 | Eps(step=326350): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6790 | Return: 1.55 | Eps(step=326371): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6791 | Return: 2.21 | Eps(step=326376): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6792 | Return: 0.72 | Eps(step=326381): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6793 | Return: 3.17 | Eps(step=326390): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6794 | Return: 3.63 | Eps(step=326403): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6795 | Return: 2.40 | Eps(step=326415): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6796 | Return: 1.49 | Eps(step=326417): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6797 | Return: 1.49 | Eps(step=326419): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6798 | Return: 2.68 | Eps(step=326427): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6799 | Return: 3.00 | Eps(step=326453): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6800 | Return: 1.25 | Eps(step=326454): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6801 | Return: 1.67 | Eps(step=326464): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6802 | Return: 2.69 | Eps(step=326471): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6803 | Return: 1.97 | Eps(step=326475): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6804 | Return: 1.73 | Eps(step=326478): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6805 | Return: 2.45 | Eps(step=326484): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6806 | Return: 1.25 | Eps(step=326485): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6807 | Return: 3.64 | Eps(step=326497): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6808 | Return: 1.21 | Eps(step=326544): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6809 | Return: 2.67 | Eps(step=326553): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6810 | Return: 2.03 | Eps(step=326572): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6811 | Return: 3.65 | Eps(step=326583): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6812 | Return: 2.67 | Eps(step=326592): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6813 | Return: 3.40 | Eps(step=326603): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6814 | Return: 1.25 | Eps(step=326604): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6815 | Return: 2.16 | Eps(step=326615): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6816 | Return: 1.25 | Eps(step=326616): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6817 | Return: 3.15 | Eps(step=326627): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6818 | Return: 1.71 | Eps(step=326632): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6819 | Return: 1.49 | Eps(step=326634): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6820 | Return: 2.45 | Eps(step=326640): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6821 | Return: 1.44 | Eps(step=326648): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6822 | Return: 1.20 | Eps(step=326655): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6823 | Return: 1.73 | Eps(step=326658): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6824 | Return: 2.17 | Eps(step=326667): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6825 | Return: 3.63 | Eps(step=326680): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6826 | Return: 3.17 | Eps(step=326689): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6827 | Return: 2.93 | Eps(step=326697): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6828 | Return: 1.54 | Eps(step=326719): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6829 | Return: 3.60 | Eps(step=326735): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6830 | Return: 2.18 | Eps(step=326743): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6831 | Return: 3.13 | Eps(step=326756): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6832 | Return: 2.95 | Eps(step=326787): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6833 | Return: 1.73 | Eps(step=326790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6834 | Return: 3.17 | Eps(step=326799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6835 | Return: 3.65 | Eps(step=326810): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6836 | Return: 2.45 | Eps(step=326816): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6837 | Return: 3.17 | Eps(step=326825): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6838 | Return: 1.94 | Eps(step=326832): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6839 | Return: 2.21 | Eps(step=326837): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6840 | Return: 1.97 | Eps(step=326841): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6841 | Return: 1.73 | Eps(step=326844): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6842 | Return: 2.91 | Eps(step=326854): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6843 | Return: 1.40 | Eps(step=326861): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6844 | Return: 2.21 | Eps(step=326866): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6845 | Return: 1.71 | Eps(step=326871): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6846 | Return: 1.97 | Eps(step=326875): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6847 | Return: 1.68 | Eps(step=326884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6848 | Return: 1.49 | Eps(step=326886): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6849 | Return: 1.25 | Eps(step=326887): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6850 | Return: 3.07 | Eps(step=326906): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6851 | Return: 1.25 | Eps(step=326907): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6852 | Return: 2.45 | Eps(step=326913): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6853 | Return: 2.39 | Eps(step=326925): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6854 | Return: 2.45 | Eps(step=326931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6855 | Return: 2.21 | Eps(step=326936): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6856 | Return: -5.62 | Eps(step=327467): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6857 | Return: 1.73 | Eps(step=327470): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6858 | Return: 2.55 | Eps(step=327516): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6859 | Return: 1.73 | Eps(step=327519): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6860 | Return: 1.49 | Eps(step=327521): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6861 | Return: 2.45 | Eps(step=327527): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6862 | Return: 2.66 | Eps(step=327537): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6863 | Return: -9.14 | Eps(step=327851): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6864 | Return: 2.21 | Eps(step=327856): 0.100 | AvgLoss: 0.0000\n",
            "Episode 6865 | Return: 1.44 | Eps(step=327884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6866 | Return: 2.17 | Eps(step=327893): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6867 | Return: 2.38 | Eps(step=327906): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6868 | Return: 2.93 | Eps(step=327914): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6869 | Return: 1.49 | Eps(step=327916): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6870 | Return: 2.21 | Eps(step=327921): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6871 | Return: 2.19 | Eps(step=327928): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6872 | Return: 2.61 | Eps(step=327968): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6873 | Return: 1.73 | Eps(step=327971): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6874 | Return: -0.71 | Eps(step=328095): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6875 | Return: 2.43 | Eps(step=328103): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6876 | Return: 3.08 | Eps(step=328121): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6877 | Return: 2.45 | Eps(step=328127): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6878 | Return: 1.14 | Eps(step=328165): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6879 | Return: 2.87 | Eps(step=328179): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6880 | Return: 3.40 | Eps(step=328190): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6881 | Return: 1.49 | Eps(step=328192): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6882 | Return: 1.49 | Eps(step=328194): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6883 | Return: 3.17 | Eps(step=328203): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6884 | Return: 1.73 | Eps(step=328206): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6885 | Return: 2.91 | Eps(step=328216): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6886 | Return: 1.97 | Eps(step=328220): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6887 | Return: 3.40 | Eps(step=328231): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6888 | Return: 2.68 | Eps(step=328239): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6889 | Return: 1.88 | Eps(step=328248): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6890 | Return: 2.69 | Eps(step=328255): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6891 | Return: 2.28 | Eps(step=328278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6892 | Return: 3.17 | Eps(step=328287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6893 | Return: 2.43 | Eps(step=328295): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6894 | Return: 1.42 | Eps(step=328305): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6895 | Return: 1.95 | Eps(step=328311): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6896 | Return: 1.73 | Eps(step=328314): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6897 | Return: 2.21 | Eps(step=328319): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6898 | Return: 2.45 | Eps(step=328325): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6899 | Return: 3.65 | Eps(step=328336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6900 | Return: 2.93 | Eps(step=328344): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6901 | Return: 1.73 | Eps(step=328347): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6902 | Return: 2.93 | Eps(step=328355): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6903 | Return: 3.15 | Eps(step=328366): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6904 | Return: 2.19 | Eps(step=328373): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6905 | Return: 3.39 | Eps(step=328385): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6906 | Return: 2.43 | Eps(step=328393): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6907 | Return: 2.43 | Eps(step=328401): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6908 | Return: 1.73 | Eps(step=328404): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6909 | Return: 1.57 | Eps(step=328419): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6910 | Return: 3.16 | Eps(step=328429): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6911 | Return: 1.49 | Eps(step=328431): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6912 | Return: 2.20 | Eps(step=328437): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6913 | Return: 1.67 | Eps(step=328446): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6914 | Return: 2.21 | Eps(step=328451): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6915 | Return: 1.64 | Eps(step=328459): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6916 | Return: 2.69 | Eps(step=328466): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6917 | Return: 1.97 | Eps(step=328470): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6918 | Return: 2.19 | Eps(step=328477): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6919 | Return: 2.45 | Eps(step=328483): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6920 | Return: 3.15 | Eps(step=328494): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6921 | Return: 3.63 | Eps(step=328507): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6922 | Return: 1.74 | Eps(step=328585): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6923 | Return: 3.39 | Eps(step=328597): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6924 | Return: 1.71 | Eps(step=328602): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6925 | Return: 2.69 | Eps(step=328609): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6926 | Return: 2.92 | Eps(step=328618): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6927 | Return: 1.73 | Eps(step=328621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6928 | Return: 2.21 | Eps(step=328626): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6929 | Return: 2.91 | Eps(step=328636): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6930 | Return: 2.43 | Eps(step=328644): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6931 | Return: 1.79 | Eps(step=328658): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6932 | Return: 2.21 | Eps(step=328663): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6933 | Return: 2.21 | Eps(step=328668): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6934 | Return: 2.69 | Eps(step=328675): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6935 | Return: 2.45 | Eps(step=328681): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6936 | Return: 2.41 | Eps(step=328717): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6937 | Return: 2.21 | Eps(step=328722): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6938 | Return: 2.91 | Eps(step=328732): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6939 | Return: 1.66 | Eps(step=328738): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6940 | Return: 2.69 | Eps(step=328745): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6941 | Return: 1.95 | Eps(step=328751): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6942 | Return: 3.63 | Eps(step=328764): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6943 | Return: 2.45 | Eps(step=328770): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6944 | Return: 1.97 | Eps(step=328774): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6945 | Return: 1.95 | Eps(step=328780): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6946 | Return: 1.71 | Eps(step=328785): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6947 | Return: 1.49 | Eps(step=328787): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6948 | Return: 2.45 | Eps(step=328793): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6949 | Return: 3.63 | Eps(step=328806): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6950 | Return: 1.71 | Eps(step=328811): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6951 | Return: 1.48 | Eps(step=328814): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6952 | Return: 1.95 | Eps(step=328820): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6953 | Return: 3.15 | Eps(step=328831): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6954 | Return: 2.68 | Eps(step=328839): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6955 | Return: 3.86 | Eps(step=328854): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6956 | Return: 1.25 | Eps(step=328855): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6957 | Return: 2.43 | Eps(step=328863): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6958 | Return: -1.21 | Eps(step=328908): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6959 | Return: 2.41 | Eps(step=328918): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6960 | Return: 3.17 | Eps(step=328927): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6961 | Return: 1.97 | Eps(step=328931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6962 | Return: 2.15 | Eps(step=328942): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6963 | Return: 2.69 | Eps(step=328949): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6964 | Return: 0.96 | Eps(step=328955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6965 | Return: 2.69 | Eps(step=328962): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6966 | Return: 2.19 | Eps(step=328969): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6967 | Return: 2.68 | Eps(step=328977): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6968 | Return: 3.41 | Eps(step=328987): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6969 | Return: 0.94 | Eps(step=328990): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6970 | Return: 2.38 | Eps(step=329004): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6971 | Return: 1.45 | Eps(step=329010): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6972 | Return: 1.95 | Eps(step=329016): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6973 | Return: 1.97 | Eps(step=329020): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6974 | Return: 1.65 | Eps(step=329052): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6975 | Return: 1.97 | Eps(step=329056): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6976 | Return: 2.81 | Eps(step=329072): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6977 | Return: 2.69 | Eps(step=329079): 0.100 | AvgLoss: 0.0002\n",
            "Episode 6978 | Return: 3.41 | Eps(step=329089): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6979 | Return: 3.39 | Eps(step=329101): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6980 | Return: 2.93 | Eps(step=329109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6981 | Return: 2.93 | Eps(step=329117): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6982 | Return: -1.83 | Eps(step=329422): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6983 | Return: 1.49 | Eps(step=329424): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6984 | Return: 3.17 | Eps(step=329433): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6985 | Return: 2.44 | Eps(step=329440): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6986 | Return: 2.91 | Eps(step=329450): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6987 | Return: 2.17 | Eps(step=329459): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6988 | Return: 1.71 | Eps(step=329464): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6989 | Return: 1.42 | Eps(step=329469): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6990 | Return: 2.38 | Eps(step=329478): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6991 | Return: 1.49 | Eps(step=329480): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6992 | Return: 3.65 | Eps(step=329491): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6993 | Return: 1.49 | Eps(step=329493): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6994 | Return: 1.73 | Eps(step=329496): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6995 | Return: 1.25 | Eps(step=329497): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6996 | Return: 2.21 | Eps(step=329502): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6997 | Return: 2.43 | Eps(step=329510): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6998 | Return: 1.20 | Eps(step=329517): 0.100 | AvgLoss: 0.0001\n",
            "Episode 6999 | Return: 3.41 | Eps(step=329527): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7000 | Return: 1.97 | Eps(step=329531): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7001 | Return: 3.41 | Eps(step=329541): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7002 | Return: 2.84 | Eps(step=329554): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7003 | Return: 3.37 | Eps(step=329568): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7004 | Return: 2.19 | Eps(step=329575): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7005 | Return: 3.41 | Eps(step=329585): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7006 | Return: 3.65 | Eps(step=329596): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7007 | Return: 1.73 | Eps(step=329599): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7008 | Return: 3.65 | Eps(step=329610): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7009 | Return: 2.45 | Eps(step=329616): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7010 | Return: 1.47 | Eps(step=329620): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7011 | Return: 2.44 | Eps(step=329627): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7012 | Return: 1.25 | Eps(step=329628): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7013 | Return: 2.69 | Eps(step=329635): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7014 | Return: 1.95 | Eps(step=329641): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7015 | Return: 1.49 | Eps(step=329643): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7016 | Return: 3.41 | Eps(step=329653): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7017 | Return: 1.71 | Eps(step=329658): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7018 | Return: 2.69 | Eps(step=329665): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7019 | Return: 1.71 | Eps(step=329670): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7020 | Return: 2.41 | Eps(step=329680): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7021 | Return: 2.45 | Eps(step=329686): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7022 | Return: 2.45 | Eps(step=329692): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7023 | Return: 2.21 | Eps(step=329697): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7024 | Return: 1.97 | Eps(step=329701): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7025 | Return: 2.38 | Eps(step=329710): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7026 | Return: 1.73 | Eps(step=329713): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7027 | Return: 2.45 | Eps(step=329719): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7028 | Return: 2.91 | Eps(step=329729): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7029 | Return: 2.41 | Eps(step=329739): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7030 | Return: 1.00 | Eps(step=329740): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7031 | Return: 2.19 | Eps(step=329747): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7032 | Return: 0.72 | Eps(step=329752): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7033 | Return: 1.90 | Eps(step=329763): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7034 | Return: 1.49 | Eps(step=329765): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7035 | Return: 1.73 | Eps(step=329768): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7036 | Return: 1.73 | Eps(step=329771): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7037 | Return: 2.93 | Eps(step=329779): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7038 | Return: 3.41 | Eps(step=329789): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7039 | Return: 1.49 | Eps(step=329791): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7040 | Return: 1.49 | Eps(step=329793): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7041 | Return: 2.19 | Eps(step=329800): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7042 | Return: 3.39 | Eps(step=329812): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7043 | Return: 2.21 | Eps(step=329817): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7044 | Return: 1.97 | Eps(step=329821): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7045 | Return: 0.64 | Eps(step=329836): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7046 | Return: 2.43 | Eps(step=329844): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7047 | Return: 0.72 | Eps(step=329849): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7048 | Return: 1.60 | Eps(step=329861): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7049 | Return: 3.41 | Eps(step=329871): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7050 | Return: 1.25 | Eps(step=329872): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7051 | Return: 2.45 | Eps(step=329878): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7052 | Return: 2.45 | Eps(step=329884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7053 | Return: 2.45 | Eps(step=329890): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7054 | Return: 2.68 | Eps(step=329898): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7055 | Return: 3.16 | Eps(step=329908): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7056 | Return: 3.12 | Eps(step=329922): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7057 | Return: 1.25 | Eps(step=329923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7058 | Return: 1.93 | Eps(step=329931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7059 | Return: 2.69 | Eps(step=329938): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7060 | Return: 1.44 | Eps(step=329945): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7061 | Return: 2.91 | Eps(step=329955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7062 | Return: 1.25 | Eps(step=329956): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7063 | Return: 3.41 | Eps(step=329966): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7064 | Return: 3.64 | Eps(step=329978): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7065 | Return: 2.19 | Eps(step=329985): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7066 | Return: 2.21 | Eps(step=329990): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7067 | Return: 3.39 | Eps(step=330002): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7068 | Return: 1.90 | Eps(step=330009): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7069 | Return: 1.49 | Eps(step=330011): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7070 | Return: 3.65 | Eps(step=330022): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7071 | Return: 2.21 | Eps(step=330027): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7072 | Return: 2.60 | Eps(step=330068): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7073 | Return: 1.49 | Eps(step=330070): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7074 | Return: 3.11 | Eps(step=330085): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7075 | Return: 2.42 | Eps(step=330094): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7076 | Return: 2.45 | Eps(step=330100): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7077 | Return: 2.92 | Eps(step=330109): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7078 | Return: 3.17 | Eps(step=330118): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7079 | Return: 2.41 | Eps(step=330128): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7080 | Return: 2.43 | Eps(step=330136): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7081 | Return: 0.72 | Eps(step=330141): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7082 | Return: 1.00 | Eps(step=330142): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7083 | Return: 2.21 | Eps(step=330147): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7084 | Return: -23.94 | Eps(step=331147): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7085 | Return: 1.49 | Eps(step=331149): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7086 | Return: 1.47 | Eps(step=331153): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7087 | Return: 2.43 | Eps(step=331161): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7088 | Return: 2.59 | Eps(step=331174): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7089 | Return: 3.17 | Eps(step=331183): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7090 | Return: 1.95 | Eps(step=331189): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7091 | Return: 2.12 | Eps(step=331204): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7092 | Return: 2.67 | Eps(step=331213): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7093 | Return: 0.95 | Eps(step=331246): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7094 | Return: 2.19 | Eps(step=331253): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7095 | Return: 2.18 | Eps(step=331261): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7096 | Return: 1.25 | Eps(step=331262): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7097 | Return: 3.64 | Eps(step=331274): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7098 | Return: -1.43 | Eps(step=331347): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7099 | Return: 1.49 | Eps(step=331349): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7100 | Return: 3.17 | Eps(step=331358): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7101 | Return: 3.59 | Eps(step=331375): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7102 | Return: 1.97 | Eps(step=331379): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7103 | Return: 1.68 | Eps(step=331388): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7104 | Return: 0.58 | Eps(step=331407): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7105 | Return: 2.21 | Eps(step=331412): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7106 | Return: 2.43 | Eps(step=331420): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7107 | Return: 2.41 | Eps(step=331430): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7108 | Return: 3.06 | Eps(step=331450): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7109 | Return: 1.62 | Eps(step=331460): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7110 | Return: 1.66 | Eps(step=331466): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7111 | Return: 1.25 | Eps(step=331467): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7112 | Return: 2.36 | Eps(step=331478): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7113 | Return: 2.21 | Eps(step=331483): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7114 | Return: 1.19 | Eps(step=331540): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7115 | Return: 2.93 | Eps(step=331548): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7116 | Return: 3.17 | Eps(step=331557): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7117 | Return: 2.69 | Eps(step=331564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7118 | Return: 1.49 | Eps(step=331566): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7119 | Return: 2.62 | Eps(step=331580): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7120 | Return: 2.45 | Eps(step=331586): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7121 | Return: 1.73 | Eps(step=331589): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7122 | Return: 2.89 | Eps(step=331601): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7123 | Return: 3.37 | Eps(step=331615): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7124 | Return: 0.12 | Eps(step=331631): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7125 | Return: 2.85 | Eps(step=331647): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7126 | Return: 2.93 | Eps(step=331655): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7127 | Return: 2.69 | Eps(step=331662): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7128 | Return: 1.73 | Eps(step=331665): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7129 | Return: 1.97 | Eps(step=331669): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7130 | Return: 1.70 | Eps(step=331675): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7131 | Return: 2.21 | Eps(step=331680): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7132 | Return: 1.97 | Eps(step=331684): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7133 | Return: 2.45 | Eps(step=331690): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7134 | Return: 0.24 | Eps(step=331693): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7135 | Return: 1.97 | Eps(step=331697): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7136 | Return: 2.43 | Eps(step=331705): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7137 | Return: 2.45 | Eps(step=331711): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7138 | Return: 2.69 | Eps(step=331718): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7139 | Return: 2.45 | Eps(step=331724): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7140 | Return: 1.49 | Eps(step=331726): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7141 | Return: 3.39 | Eps(step=331738): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7142 | Return: 3.63 | Eps(step=331751): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7143 | Return: -9.54 | Eps(step=332106): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7144 | Return: 3.39 | Eps(step=332118): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7145 | Return: 3.08 | Eps(step=332136): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7146 | Return: 3.89 | Eps(step=332148): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7147 | Return: 1.97 | Eps(step=332152): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7148 | Return: 2.45 | Eps(step=332158): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7149 | Return: 2.69 | Eps(step=332165): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7150 | Return: 0.91 | Eps(step=332221): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7151 | Return: 3.63 | Eps(step=332234): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7152 | Return: 2.45 | Eps(step=332240): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7153 | Return: 2.93 | Eps(step=332248): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7154 | Return: 2.45 | Eps(step=332254): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7155 | Return: 1.25 | Eps(step=332255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7156 | Return: 1.73 | Eps(step=332258): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7157 | Return: 1.97 | Eps(step=332262): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7158 | Return: 2.90 | Eps(step=332273): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7159 | Return: 2.93 | Eps(step=332281): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7160 | Return: 2.45 | Eps(step=332287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7161 | Return: 1.71 | Eps(step=332292): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7162 | Return: 2.45 | Eps(step=332298): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7163 | Return: 2.93 | Eps(step=332306): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7164 | Return: 2.45 | Eps(step=332312): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7165 | Return: 2.68 | Eps(step=332320): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7166 | Return: 3.41 | Eps(step=332330): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7167 | Return: 1.73 | Eps(step=332333): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7168 | Return: 1.64 | Eps(step=332341): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7169 | Return: 2.14 | Eps(step=332353): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7170 | Return: 2.69 | Eps(step=332360): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7171 | Return: 1.42 | Eps(step=332365): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7172 | Return: 2.87 | Eps(step=332379): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7173 | Return: 2.21 | Eps(step=332384): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7174 | Return: 3.15 | Eps(step=332395): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7175 | Return: 1.25 | Eps(step=332396): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7176 | Return: 2.91 | Eps(step=332406): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7177 | Return: 1.90 | Eps(step=332417): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7178 | Return: 2.19 | Eps(step=332424): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7179 | Return: 2.61 | Eps(step=332440): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7180 | Return: 1.95 | Eps(step=332446): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7181 | Return: 1.49 | Eps(step=332448): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7182 | Return: 2.68 | Eps(step=332456): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7183 | Return: 1.88 | Eps(step=332469): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7184 | Return: 2.21 | Eps(step=332474): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7185 | Return: 1.49 | Eps(step=332476): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7186 | Return: 1.71 | Eps(step=332481): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7187 | Return: 2.14 | Eps(step=332493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7188 | Return: 2.45 | Eps(step=332499): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7189 | Return: 2.46 | Eps(step=332525): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7190 | Return: 2.21 | Eps(step=332530): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7191 | Return: 1.00 | Eps(step=332531): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7192 | Return: 1.66 | Eps(step=332542): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7193 | Return: 1.72 | Eps(step=332546): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7194 | Return: 2.91 | Eps(step=332556): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7195 | Return: 1.49 | Eps(step=332558): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7196 | Return: 2.43 | Eps(step=332566): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7197 | Return: 2.21 | Eps(step=332571): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7198 | Return: 2.45 | Eps(step=332577): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7199 | Return: 2.18 | Eps(step=332635): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7200 | Return: 1.47 | Eps(step=332639): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7201 | Return: 1.25 | Eps(step=332640): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7202 | Return: 2.45 | Eps(step=332646): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7203 | Return: 2.45 | Eps(step=332652): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7204 | Return: -2.10 | Eps(step=332910): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7205 | Return: 0.68 | Eps(step=332940): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7206 | Return: 2.45 | Eps(step=332946): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7207 | Return: 2.24 | Eps(step=332974): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7208 | Return: 2.91 | Eps(step=332984): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7209 | Return: 2.69 | Eps(step=332991): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7210 | Return: 2.69 | Eps(step=332998): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7211 | Return: 3.38 | Eps(step=333011): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7212 | Return: 1.73 | Eps(step=333014): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7213 | Return: 3.65 | Eps(step=333025): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7214 | Return: 3.16 | Eps(step=333035): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7215 | Return: 1.49 | Eps(step=333037): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7216 | Return: -1.02 | Eps(step=333063): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7217 | Return: 1.73 | Eps(step=333066): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7218 | Return: 3.87 | Eps(step=333080): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7219 | Return: 1.68 | Eps(step=333089): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7220 | Return: 1.25 | Eps(step=333090): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7221 | Return: 2.43 | Eps(step=333098): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7222 | Return: 2.93 | Eps(step=333106): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7223 | Return: 3.17 | Eps(step=333115): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7224 | Return: 1.92 | Eps(step=333125): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7225 | Return: 1.00 | Eps(step=333126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7226 | Return: 1.40 | Eps(step=333133): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7227 | Return: 1.25 | Eps(step=333134): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7228 | Return: 1.00 | Eps(step=333135): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7229 | Return: 0.68 | Eps(step=333139): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7230 | Return: 1.93 | Eps(step=333147): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7231 | Return: 1.39 | Eps(step=333161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7232 | Return: 1.49 | Eps(step=333163): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7233 | Return: 1.95 | Eps(step=333169): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7234 | Return: 1.00 | Eps(step=333170): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7235 | Return: 2.88 | Eps(step=333233): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7236 | Return: 2.45 | Eps(step=333239): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7237 | Return: 2.93 | Eps(step=333247): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7238 | Return: 2.43 | Eps(step=333255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7239 | Return: 2.21 | Eps(step=333260): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7240 | Return: 2.67 | Eps(step=333269): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7241 | Return: 1.97 | Eps(step=333273): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7242 | Return: 1.00 | Eps(step=333274): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7243 | Return: -0.14 | Eps(step=333365): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7244 | Return: 2.91 | Eps(step=333375): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7245 | Return: 1.62 | Eps(step=333414): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7246 | Return: 2.61 | Eps(step=333429): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7247 | Return: 3.41 | Eps(step=333439): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7248 | Return: 2.42 | Eps(step=333448): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7249 | Return: 2.45 | Eps(step=333454): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7250 | Return: 1.68 | Eps(step=333462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7251 | Return: 1.44 | Eps(step=333470): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7252 | Return: 2.58 | Eps(step=333488): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7253 | Return: 1.96 | Eps(step=333493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7254 | Return: 1.97 | Eps(step=333497): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7255 | Return: 1.49 | Eps(step=333499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7256 | Return: 2.21 | Eps(step=333504): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7257 | Return: 3.37 | Eps(step=333518): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7258 | Return: 3.41 | Eps(step=333528): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7259 | Return: 2.45 | Eps(step=333534): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7260 | Return: 2.69 | Eps(step=333541): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7261 | Return: 1.73 | Eps(step=333544): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7262 | Return: 1.97 | Eps(step=333548): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7263 | Return: 1.25 | Eps(step=333549): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7264 | Return: 2.33 | Eps(step=333563): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7265 | Return: 3.05 | Eps(step=333584): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7266 | Return: 2.43 | Eps(step=333592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7267 | Return: 1.25 | Eps(step=333593): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7268 | Return: 2.21 | Eps(step=333598): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7269 | Return: 3.65 | Eps(step=333609): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7270 | Return: 3.11 | Eps(step=333624): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7271 | Return: 1.97 | Eps(step=333628): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7272 | Return: 2.43 | Eps(step=333636): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7273 | Return: 3.17 | Eps(step=333645): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7274 | Return: 2.21 | Eps(step=333650): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7275 | Return: 1.00 | Eps(step=333651): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7276 | Return: 1.89 | Eps(step=333659): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7277 | Return: 2.88 | Eps(step=333672): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7278 | Return: 3.15 | Eps(step=333683): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7279 | Return: 2.68 | Eps(step=333691): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7280 | Return: 2.43 | Eps(step=333699): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7281 | Return: 2.34 | Eps(step=333712): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7282 | Return: 2.12 | Eps(step=333722): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7283 | Return: 1.49 | Eps(step=333724): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7284 | Return: 1.61 | Eps(step=333756): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7285 | Return: 1.73 | Eps(step=333759): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7286 | Return: 0.72 | Eps(step=333764): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7287 | Return: 2.91 | Eps(step=333774): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7288 | Return: 3.17 | Eps(step=333783): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7289 | Return: 2.66 | Eps(step=333793): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7290 | Return: 1.49 | Eps(step=333795): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7291 | Return: 3.39 | Eps(step=333807): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7292 | Return: 1.67 | Eps(step=333817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7293 | Return: 1.95 | Eps(step=333823): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7294 | Return: 2.39 | Eps(step=333835): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7295 | Return: 3.00 | Eps(step=333861): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7296 | Return: 2.69 | Eps(step=333868): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7297 | Return: 2.87 | Eps(step=333932): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7298 | Return: -3.02 | Eps(step=334303): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7299 | Return: 2.21 | Eps(step=334308): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7300 | Return: 2.93 | Eps(step=334316): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7301 | Return: 2.69 | Eps(step=334323): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7302 | Return: 1.25 | Eps(step=334324): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7303 | Return: 3.41 | Eps(step=334334): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7304 | Return: 3.05 | Eps(step=334351): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7305 | Return: 2.43 | Eps(step=334359): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7306 | Return: 3.17 | Eps(step=334368): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7307 | Return: 1.49 | Eps(step=334370): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7308 | Return: 1.49 | Eps(step=334372): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7309 | Return: 1.73 | Eps(step=334375): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7310 | Return: 2.45 | Eps(step=334381): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7311 | Return: 1.41 | Eps(step=334392): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7312 | Return: 2.69 | Eps(step=334399): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7313 | Return: 1.25 | Eps(step=334400): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7314 | Return: 2.93 | Eps(step=334408): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7315 | Return: 2.64 | Eps(step=334420): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7316 | Return: 3.89 | Eps(step=334432): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7317 | Return: 2.38 | Eps(step=334446): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7318 | Return: 1.25 | Eps(step=334447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7319 | Return: 2.93 | Eps(step=334455): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7320 | Return: 2.58 | Eps(step=334469): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7321 | Return: 1.97 | Eps(step=334473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7322 | Return: 2.45 | Eps(step=334479): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7323 | Return: 2.64 | Eps(step=334492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7324 | Return: 3.41 | Eps(step=334502): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7325 | Return: 2.91 | Eps(step=334512): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7326 | Return: 2.58 | Eps(step=334526): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7327 | Return: 3.84 | Eps(step=334543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7328 | Return: 2.40 | Eps(step=334554): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7329 | Return: 1.97 | Eps(step=334558): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7330 | Return: -1.23 | Eps(step=334585): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7331 | Return: 2.44 | Eps(step=334592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7332 | Return: 3.14 | Eps(step=334604): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7333 | Return: 3.65 | Eps(step=334615): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7334 | Return: 2.45 | Eps(step=334621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7335 | Return: 2.69 | Eps(step=334628): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7336 | Return: 2.67 | Eps(step=334637): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7337 | Return: 1.43 | Eps(step=334645): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7338 | Return: 2.93 | Eps(step=334653): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7339 | Return: 1.25 | Eps(step=334654): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7340 | Return: 1.73 | Eps(step=334657): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7341 | Return: 3.07 | Eps(step=334676): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7342 | Return: 1.49 | Eps(step=334678): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7343 | Return: 3.12 | Eps(step=334692): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7344 | Return: 3.17 | Eps(step=334701): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7345 | Return: 1.49 | Eps(step=334703): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7346 | Return: 2.68 | Eps(step=334711): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7347 | Return: 2.93 | Eps(step=334719): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7348 | Return: 1.49 | Eps(step=334721): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7349 | Return: 2.65 | Eps(step=334732): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7350 | Return: 3.41 | Eps(step=334742): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7351 | Return: 0.64 | Eps(step=334755): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7352 | Return: 3.37 | Eps(step=334769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7353 | Return: 1.49 | Eps(step=334771): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7354 | Return: 1.98 | Eps(step=334795): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7355 | Return: 2.68 | Eps(step=334803): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7356 | Return: 0.11 | Eps(step=334860): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7357 | Return: 2.93 | Eps(step=334868): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7358 | Return: 3.19 | Eps(step=334900): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7359 | Return: 2.69 | Eps(step=334907): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7360 | Return: 3.16 | Eps(step=334917): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7361 | Return: -0.21 | Eps(step=334966): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7362 | Return: 3.15 | Eps(step=334977): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7363 | Return: 3.40 | Eps(step=334988): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7364 | Return: 1.20 | Eps(step=334995): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7365 | Return: 2.93 | Eps(step=335003): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7366 | Return: -7.65 | Eps(step=335301): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7367 | Return: 2.68 | Eps(step=335309): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7368 | Return: 2.37 | Eps(step=335323): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7369 | Return: 1.93 | Eps(step=335331): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7370 | Return: 1.71 | Eps(step=335336): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7371 | Return: 2.42 | Eps(step=335345): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7372 | Return: 2.21 | Eps(step=335350): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7373 | Return: 1.49 | Eps(step=335352): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7374 | Return: 2.93 | Eps(step=335360): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7375 | Return: 2.68 | Eps(step=335368): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7376 | Return: 3.11 | Eps(step=335383): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7377 | Return: 1.97 | Eps(step=335387): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7378 | Return: 2.69 | Eps(step=335394): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7379 | Return: 1.70 | Eps(step=335400): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7380 | Return: 2.58 | Eps(step=335418): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7381 | Return: 1.97 | Eps(step=335422): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7382 | Return: 0.96 | Eps(step=335428): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7383 | Return: -0.50 | Eps(step=335476): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7384 | Return: 2.69 | Eps(step=335483): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7385 | Return: 1.03 | Eps(step=335527): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7386 | Return: 0.37 | Eps(step=335543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7387 | Return: 2.92 | Eps(step=335552): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7388 | Return: 1.48 | Eps(step=335555): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7389 | Return: 2.45 | Eps(step=335561): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7390 | Return: 1.21 | Eps(step=335587): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7391 | Return: 3.64 | Eps(step=335599): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7392 | Return: 1.38 | Eps(step=335639): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7393 | Return: 2.45 | Eps(step=335645): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7394 | Return: 2.83 | Eps(step=335663): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7395 | Return: 0.96 | Eps(step=335714): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7396 | Return: 1.97 | Eps(step=335718): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7397 | Return: 1.84 | Eps(step=335731): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7398 | Return: 1.49 | Eps(step=335733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7399 | Return: 1.49 | Eps(step=335735): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7400 | Return: 1.97 | Eps(step=335739): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7401 | Return: 1.63 | Eps(step=335753): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7402 | Return: 2.39 | Eps(step=335766): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7403 | Return: 1.49 | Eps(step=335768): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7404 | Return: 1.73 | Eps(step=335771): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7405 | Return: 3.14 | Eps(step=335783): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7406 | Return: 1.25 | Eps(step=335784): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7407 | Return: 1.36 | Eps(step=335795): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7408 | Return: 1.18 | Eps(step=335799): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7409 | Return: 2.21 | Eps(step=335804): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7410 | Return: 2.86 | Eps(step=335819): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7411 | Return: 2.68 | Eps(step=335827): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7412 | Return: 1.73 | Eps(step=335830): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7413 | Return: 1.66 | Eps(step=335836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7414 | Return: 1.97 | Eps(step=335840): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7415 | Return: 1.86 | Eps(step=335856): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7416 | Return: 1.85 | Eps(step=335922): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7417 | Return: 0.73 | Eps(step=335952): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7418 | Return: 1.25 | Eps(step=335953): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7419 | Return: 1.96 | Eps(step=335958): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7420 | Return: 3.01 | Eps(step=335983): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7421 | Return: 2.76 | Eps(step=336058): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7422 | Return: 3.39 | Eps(step=336070): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7423 | Return: 2.45 | Eps(step=336076): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7424 | Return: 3.17 | Eps(step=336085): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7425 | Return: 2.21 | Eps(step=336090): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7426 | Return: 2.92 | Eps(step=336099): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7427 | Return: 3.41 | Eps(step=336109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7428 | Return: 2.19 | Eps(step=336116): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7429 | Return: 2.43 | Eps(step=336124): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7430 | Return: 2.59 | Eps(step=336141): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7431 | Return: 3.41 | Eps(step=336151): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7432 | Return: 2.91 | Eps(step=336161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7433 | Return: 2.54 | Eps(step=336208): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7434 | Return: 3.11 | Eps(step=336223): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7435 | Return: 1.45 | Eps(step=336250): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7436 | Return: 2.60 | Eps(step=336262): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7437 | Return: 2.39 | Eps(step=336274): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7438 | Return: 2.41 | Eps(step=336284): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7439 | Return: 2.21 | Eps(step=336289): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7440 | Return: 2.15 | Eps(step=336300): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7441 | Return: 3.64 | Eps(step=336312): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7442 | Return: 1.49 | Eps(step=336314): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7443 | Return: 1.95 | Eps(step=336320): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7444 | Return: 2.21 | Eps(step=336325): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7445 | Return: 2.01 | Eps(step=336346): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7446 | Return: 3.41 | Eps(step=336356): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7447 | Return: 1.97 | Eps(step=336360): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7448 | Return: 1.25 | Eps(step=336361): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7449 | Return: 3.41 | Eps(step=336371): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7450 | Return: 2.69 | Eps(step=336403): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7451 | Return: 1.97 | Eps(step=336407): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7452 | Return: 1.00 | Eps(step=336408): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7453 | Return: 3.41 | Eps(step=336418): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7454 | Return: 1.25 | Eps(step=336419): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7455 | Return: 2.90 | Eps(step=336430): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7456 | Return: 3.89 | Eps(step=336442): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7457 | Return: 2.21 | Eps(step=336447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7458 | Return: 1.18 | Eps(step=336456): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7459 | Return: 1.25 | Eps(step=336457): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7460 | Return: 1.71 | Eps(step=336462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7461 | Return: 2.69 | Eps(step=336469): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7462 | Return: 1.73 | Eps(step=336472): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7463 | Return: 1.73 | Eps(step=336475): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7464 | Return: 2.92 | Eps(step=336484): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7465 | Return: 2.45 | Eps(step=336490): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7466 | Return: 1.00 | Eps(step=336491): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7467 | Return: 2.93 | Eps(step=336499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7468 | Return: 1.25 | Eps(step=336500): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7469 | Return: 1.63 | Eps(step=336513): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7470 | Return: 2.21 | Eps(step=336518): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7471 | Return: 1.48 | Eps(step=336521): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7472 | Return: 1.49 | Eps(step=336523): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7473 | Return: 2.43 | Eps(step=336531): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7474 | Return: 1.72 | Eps(step=336535): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7475 | Return: 1.64 | Eps(step=336547): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7476 | Return: 1.25 | Eps(step=336548): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7477 | Return: 1.25 | Eps(step=336549): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7478 | Return: 2.20 | Eps(step=336555): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7479 | Return: 1.64 | Eps(step=336563): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7480 | Return: 2.45 | Eps(step=336569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7481 | Return: -0.95 | Eps(step=336588): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7482 | Return: 2.21 | Eps(step=336593): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7483 | Return: 2.21 | Eps(step=336598): 0.100 | AvgLoss: 0.0006\n",
            "Episode 7484 | Return: 2.93 | Eps(step=336606): 0.100 | AvgLoss: 0.0007\n",
            "Episode 7485 | Return: 2.21 | Eps(step=336611): 0.100 | AvgLoss: 0.0005\n",
            "Episode 7486 | Return: 2.37 | Eps(step=336625): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7487 | Return: -15.18 | Eps(step=337499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7488 | Return: 1.88 | Eps(step=337508): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7489 | Return: 1.73 | Eps(step=337511): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7490 | Return: 2.91 | Eps(step=337521): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7491 | Return: 3.37 | Eps(step=337535): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7492 | Return: 2.93 | Eps(step=337543): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7493 | Return: 2.30 | Eps(step=337560): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7494 | Return: 2.93 | Eps(step=337568): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7495 | Return: 3.37 | Eps(step=337632): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7496 | Return: 2.21 | Eps(step=337637): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7497 | Return: 2.21 | Eps(step=337642): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7498 | Return: 2.43 | Eps(step=337650): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7499 | Return: 2.21 | Eps(step=337655): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7500 | Return: 2.12 | Eps(step=337665): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7501 | Return: 1.97 | Eps(step=337669): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7502 | Return: 1.25 | Eps(step=337670): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7503 | Return: 0.02 | Eps(step=337796): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7504 | Return: 2.21 | Eps(step=337801): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7505 | Return: 2.42 | Eps(step=337810): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7506 | Return: -7.07 | Eps(step=338589): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7507 | Return: 1.49 | Eps(step=338591): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7508 | Return: 0.81 | Eps(step=338662): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7509 | Return: 1.71 | Eps(step=338667): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7510 | Return: 1.95 | Eps(step=338673): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7511 | Return: -0.62 | Eps(step=338689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7512 | Return: 2.19 | Eps(step=338696): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7513 | Return: 3.63 | Eps(step=338709): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7514 | Return: 2.65 | Eps(step=338720): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7515 | Return: 2.69 | Eps(step=338727): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7516 | Return: 1.73 | Eps(step=338730): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7517 | Return: 3.17 | Eps(step=338739): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7518 | Return: 1.39 | Eps(step=338772): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7519 | Return: 2.40 | Eps(step=338783): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7520 | Return: 2.45 | Eps(step=338789): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7521 | Return: 2.99 | Eps(step=338816): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7522 | Return: 2.00 | Eps(step=338843): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7523 | Return: 2.42 | Eps(step=338852): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7524 | Return: 3.17 | Eps(step=338861): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7525 | Return: 2.20 | Eps(step=338867): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7526 | Return: 2.19 | Eps(step=338874): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7527 | Return: 1.49 | Eps(step=338876): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7528 | Return: 1.23 | Eps(step=338905): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7529 | Return: 1.47 | Eps(step=338909): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7530 | Return: 3.14 | Eps(step=338921): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7531 | Return: 2.69 | Eps(step=338928): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7532 | Return: 2.43 | Eps(step=338936): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7533 | Return: 2.14 | Eps(step=338944): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7534 | Return: 2.21 | Eps(step=338949): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7535 | Return: 2.85 | Eps(step=338965): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7536 | Return: 2.45 | Eps(step=338971): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7537 | Return: 1.73 | Eps(step=338974): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7538 | Return: -33.37 | Eps(step=339974): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7539 | Return: -15.87 | Eps(step=340974): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7540 | Return: 0.91 | Eps(step=341051): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7541 | Return: 1.63 | Eps(step=341089): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7542 | Return: 1.97 | Eps(step=341093): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7543 | Return: 1.88 | Eps(step=341127): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7544 | Return: 2.68 | Eps(step=341135): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7545 | Return: 1.95 | Eps(step=341141): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7546 | Return: 2.69 | Eps(step=341148): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7547 | Return: 1.71 | Eps(step=341153): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7548 | Return: 1.73 | Eps(step=341156): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7549 | Return: 1.97 | Eps(step=341160): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7550 | Return: 2.68 | Eps(step=341193): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7551 | Return: 2.10 | Eps(step=341210): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7552 | Return: 1.97 | Eps(step=341214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7553 | Return: 3.17 | Eps(step=341223): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7554 | Return: 2.45 | Eps(step=341229): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7555 | Return: 2.21 | Eps(step=341234): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7556 | Return: 2.93 | Eps(step=341242): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7557 | Return: 1.44 | Eps(step=341250): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7558 | Return: 2.62 | Eps(step=341264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7559 | Return: 3.17 | Eps(step=341273): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7560 | Return: 2.36 | Eps(step=341284): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7561 | Return: 3.17 | Eps(step=341293): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7562 | Return: 1.73 | Eps(step=341296): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7563 | Return: 2.93 | Eps(step=341304): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7564 | Return: 1.71 | Eps(step=341309): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7565 | Return: -1.39 | Eps(step=341343): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7566 | Return: 2.64 | Eps(step=341355): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7567 | Return: 2.19 | Eps(step=341362): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7568 | Return: 2.45 | Eps(step=341368): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7569 | Return: 0.24 | Eps(step=341371): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7570 | Return: 2.12 | Eps(step=341381): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7571 | Return: 2.95 | Eps(step=341462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7572 | Return: 2.67 | Eps(step=341471): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7573 | Return: 1.95 | Eps(step=341477): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7574 | Return: 0.94 | Eps(step=341485): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7575 | Return: 2.45 | Eps(step=341491): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7576 | Return: 2.91 | Eps(step=341501): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7577 | Return: 1.18 | Eps(step=341510): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7578 | Return: 2.43 | Eps(step=341518): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7579 | Return: 1.44 | Eps(step=341526): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7580 | Return: 2.19 | Eps(step=341533): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7581 | Return: 1.49 | Eps(step=341535): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7582 | Return: 2.41 | Eps(step=341545): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7583 | Return: 1.97 | Eps(step=341549): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7584 | Return: 2.19 | Eps(step=341556): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7585 | Return: 1.13 | Eps(step=341590): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7586 | Return: 1.00 | Eps(step=341591): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7587 | Return: 2.19 | Eps(step=341598): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7588 | Return: 2.45 | Eps(step=341604): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7589 | Return: 1.00 | Eps(step=341605): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7590 | Return: 2.88 | Eps(step=341618): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7591 | Return: 2.69 | Eps(step=341625): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7592 | Return: 2.21 | Eps(step=341630): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7593 | Return: 1.97 | Eps(step=341634): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7594 | Return: 1.73 | Eps(step=341637): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7595 | Return: 3.00 | Eps(step=341663): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7596 | Return: 2.69 | Eps(step=341670): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7597 | Return: 1.00 | Eps(step=341671): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7598 | Return: 2.69 | Eps(step=341678): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7599 | Return: 1.00 | Eps(step=341679): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7600 | Return: 2.20 | Eps(step=341685): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7601 | Return: 1.72 | Eps(step=341689): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7602 | Return: 2.67 | Eps(step=341698): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7603 | Return: 3.17 | Eps(step=341707): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7604 | Return: 2.21 | Eps(step=341712): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7605 | Return: 2.93 | Eps(step=341720): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7606 | Return: 1.49 | Eps(step=341722): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7607 | Return: 1.97 | Eps(step=341726): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7608 | Return: 2.21 | Eps(step=341731): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7609 | Return: 1.25 | Eps(step=341732): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7610 | Return: 0.96 | Eps(step=341738): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7611 | Return: 1.97 | Eps(step=341742): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7612 | Return: 3.40 | Eps(step=341753): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7613 | Return: 2.45 | Eps(step=341759): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7614 | Return: 3.17 | Eps(step=341768): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7615 | Return: 3.13 | Eps(step=341781): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7616 | Return: 2.12 | Eps(step=341791): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7617 | Return: 1.68 | Eps(step=341800): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7618 | Return: 1.97 | Eps(step=341804): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7619 | Return: 3.38 | Eps(step=341817): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7620 | Return: 2.17 | Eps(step=341826): 0.100 | AvgLoss: 0.0005\n",
            "Episode 7621 | Return: 1.71 | Eps(step=341831): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7622 | Return: 3.39 | Eps(step=341843): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7623 | Return: 2.68 | Eps(step=341851): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7624 | Return: 2.45 | Eps(step=341857): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7625 | Return: 1.72 | Eps(step=341936): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7626 | Return: 1.72 | Eps(step=341940): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7627 | Return: 1.49 | Eps(step=341942): 0.100 | AvgLoss: 0.0005\n",
            "Episode 7628 | Return: 1.97 | Eps(step=341946): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7629 | Return: 2.45 | Eps(step=341952): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7630 | Return: 1.25 | Eps(step=341953): 0.100 | AvgLoss: 0.0005\n",
            "Episode 7631 | Return: 3.40 | Eps(step=341964): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7632 | Return: 1.73 | Eps(step=341967): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7633 | Return: 2.62 | Eps(step=341977): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7634 | Return: 0.80 | Eps(step=341994): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7635 | Return: 2.92 | Eps(step=342003): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7636 | Return: 2.21 | Eps(step=342008): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7637 | Return: 3.40 | Eps(step=342019): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7638 | Return: 1.49 | Eps(step=342021): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7639 | Return: 3.17 | Eps(step=342030): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7640 | Return: 2.69 | Eps(step=342037): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7641 | Return: 3.17 | Eps(step=342046): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7642 | Return: 2.69 | Eps(step=342053): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7643 | Return: 0.48 | Eps(step=342057): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7644 | Return: -0.57 | Eps(step=342133): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7645 | Return: 2.90 | Eps(step=342144): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7646 | Return: 3.17 | Eps(step=342153): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7647 | Return: 2.45 | Eps(step=342159): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7648 | Return: 2.93 | Eps(step=342167): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7649 | Return: 0.94 | Eps(step=342175): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7650 | Return: 1.89 | Eps(step=342183): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7651 | Return: 2.93 | Eps(step=342191): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7652 | Return: 2.45 | Eps(step=342197): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7653 | Return: 3.15 | Eps(step=342208): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7654 | Return: 3.37 | Eps(step=342222): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7655 | Return: 2.21 | Eps(step=342227): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7656 | Return: 2.45 | Eps(step=342233): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7657 | Return: 2.89 | Eps(step=342245): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7658 | Return: 2.45 | Eps(step=342251): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7659 | Return: 2.02 | Eps(step=342275): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7660 | Return: 2.69 | Eps(step=342282): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7661 | Return: 1.97 | Eps(step=342286): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7662 | Return: 3.07 | Eps(step=342305): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7663 | Return: 1.69 | Eps(step=342312): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7664 | Return: 3.87 | Eps(step=342326): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7665 | Return: 3.35 | Eps(step=342342): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7666 | Return: 2.69 | Eps(step=342349): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7667 | Return: 2.21 | Eps(step=342354): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7668 | Return: 2.93 | Eps(step=342362): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7669 | Return: 1.68 | Eps(step=342371): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7670 | Return: 2.93 | Eps(step=342379): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7671 | Return: 1.10 | Eps(step=342391): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7672 | Return: 2.84 | Eps(step=342404): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7673 | Return: 2.21 | Eps(step=342409): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7674 | Return: 3.41 | Eps(step=342419): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7675 | Return: 3.65 | Eps(step=342430): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7676 | Return: 2.44 | Eps(step=342437): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7677 | Return: 2.41 | Eps(step=342447): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7678 | Return: 3.17 | Eps(step=342456): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7679 | Return: 3.39 | Eps(step=342468): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7680 | Return: 1.61 | Eps(step=342479): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7681 | Return: 1.00 | Eps(step=342480): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7682 | Return: 1.95 | Eps(step=342486): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7683 | Return: 2.15 | Eps(step=342497): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7684 | Return: 1.49 | Eps(step=342499): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7685 | Return: 1.93 | Eps(step=342507): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7686 | Return: 1.70 | Eps(step=342538): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7687 | Return: 3.65 | Eps(step=342549): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7688 | Return: 1.95 | Eps(step=342555): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7689 | Return: 1.97 | Eps(step=342559): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7690 | Return: 2.19 | Eps(step=342566): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7691 | Return: 3.41 | Eps(step=342576): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7692 | Return: 2.45 | Eps(step=342582): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7693 | Return: 2.93 | Eps(step=342590): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7694 | Return: 0.20 | Eps(step=342623): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7695 | Return: 2.44 | Eps(step=342630): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7696 | Return: 1.91 | Eps(step=342640): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7697 | Return: 3.41 | Eps(step=342650): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7698 | Return: 2.21 | Eps(step=342655): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7699 | Return: 3.65 | Eps(step=342666): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7700 | Return: 2.69 | Eps(step=342673): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7701 | Return: 1.44 | Eps(step=342681): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7702 | Return: 0.00 | Eps(step=342683): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7703 | Return: 1.49 | Eps(step=342685): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7704 | Return: 2.21 | Eps(step=342690): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7705 | Return: 1.97 | Eps(step=342694): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7706 | Return: 2.66 | Eps(step=342704): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7707 | Return: 1.97 | Eps(step=342708): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7708 | Return: 2.21 | Eps(step=342713): 0.100 | AvgLoss: 0.0005\n",
            "Episode 7709 | Return: 2.45 | Eps(step=342719): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7710 | Return: 2.16 | Eps(step=342729): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7711 | Return: 1.96 | Eps(step=342734): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7712 | Return: 1.97 | Eps(step=342738): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7713 | Return: 3.17 | Eps(step=342747): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7714 | Return: 2.68 | Eps(step=342755): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7715 | Return: 1.49 | Eps(step=342757): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7716 | Return: 3.65 | Eps(step=342768): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7717 | Return: 1.97 | Eps(step=342772): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7718 | Return: 2.44 | Eps(step=342779): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7719 | Return: 2.69 | Eps(step=342786): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7720 | Return: 3.16 | Eps(step=342796): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7721 | Return: 2.69 | Eps(step=342803): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7722 | Return: 2.45 | Eps(step=342809): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7723 | Return: 1.97 | Eps(step=342813): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7724 | Return: 1.97 | Eps(step=342817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7725 | Return: 2.21 | Eps(step=342822): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7726 | Return: 2.57 | Eps(step=342841): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7727 | Return: 3.17 | Eps(step=342850): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7728 | Return: 2.93 | Eps(step=342858): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7729 | Return: 1.97 | Eps(step=342862): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7730 | Return: 2.93 | Eps(step=342870): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7731 | Return: 1.55 | Eps(step=342891): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7732 | Return: 2.21 | Eps(step=342896): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7733 | Return: 1.97 | Eps(step=342900): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7734 | Return: 2.93 | Eps(step=342908): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7735 | Return: 2.69 | Eps(step=342915): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7736 | Return: -3.50 | Eps(step=343097): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7737 | Return: 1.49 | Eps(step=343099): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7738 | Return: 1.71 | Eps(step=343104): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7739 | Return: -21.02 | Eps(step=344104): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7740 | Return: -1.25 | Eps(step=344184): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7741 | Return: 1.25 | Eps(step=344185): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7742 | Return: 1.91 | Eps(step=344221): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7743 | Return: 1.73 | Eps(step=344224): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7744 | Return: 1.49 | Eps(step=344226): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7745 | Return: 1.68 | Eps(step=344235): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7746 | Return: 0.72 | Eps(step=344240): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7747 | Return: 2.68 | Eps(step=344248): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7748 | Return: 1.82 | Eps(step=344267): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7749 | Return: 2.45 | Eps(step=344273): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7750 | Return: 1.71 | Eps(step=344278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7751 | Return: 1.96 | Eps(step=344283): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7752 | Return: 2.05 | Eps(step=344304): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7753 | Return: 2.92 | Eps(step=344313): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7754 | Return: 1.00 | Eps(step=344314): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7755 | Return: 1.73 | Eps(step=344317): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7756 | Return: 2.92 | Eps(step=344326): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7757 | Return: -32.96 | Eps(step=345153): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7758 | Return: 2.69 | Eps(step=345160): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7759 | Return: 2.21 | Eps(step=345165): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7760 | Return: -3.62 | Eps(step=345234): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7761 | Return: 2.45 | Eps(step=345240): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7762 | Return: 1.97 | Eps(step=345244): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7763 | Return: 2.20 | Eps(step=345250): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7764 | Return: 2.21 | Eps(step=345255): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7765 | Return: 3.12 | Eps(step=345269): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7766 | Return: 1.49 | Eps(step=345271): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7767 | Return: 1.49 | Eps(step=345273): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7768 | Return: 2.19 | Eps(step=345280): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7769 | Return: 2.90 | Eps(step=345291): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7770 | Return: 1.64 | Eps(step=345349): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7771 | Return: 1.97 | Eps(step=345353): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7772 | Return: 0.94 | Eps(step=345361): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7773 | Return: 1.84 | Eps(step=345374): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7774 | Return: 2.45 | Eps(step=345380): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7775 | Return: 1.47 | Eps(step=345384): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7776 | Return: 2.00 | Eps(step=345481): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7777 | Return: 2.44 | Eps(step=345488): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7778 | Return: 3.17 | Eps(step=345497): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7779 | Return: 1.58 | Eps(step=345511): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7780 | Return: 1.73 | Eps(step=345514): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7781 | Return: -1.69 | Eps(step=345652): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7782 | Return: 2.93 | Eps(step=345660): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7783 | Return: 1.09 | Eps(step=345677): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7784 | Return: 2.75 | Eps(step=345728): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7785 | Return: 2.93 | Eps(step=345736): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7786 | Return: 1.40 | Eps(step=345768): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7787 | Return: 2.45 | Eps(step=345774): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7788 | Return: 0.94 | Eps(step=345782): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7789 | Return: 2.93 | Eps(step=345790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7790 | Return: 1.49 | Eps(step=345792): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7791 | Return: 2.21 | Eps(step=345797): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7792 | Return: 2.20 | Eps(step=345803): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7793 | Return: 1.49 | Eps(step=345805): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7794 | Return: 1.97 | Eps(step=345809): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7795 | Return: 3.08 | Eps(step=345823): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7796 | Return: 2.21 | Eps(step=345828): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7797 | Return: 2.45 | Eps(step=345834): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7798 | Return: 2.40 | Eps(step=345846): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7799 | Return: 2.13 | Eps(step=345860): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7800 | Return: 3.40 | Eps(step=345871): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7801 | Return: 1.97 | Eps(step=345875): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7802 | Return: 2.21 | Eps(step=345880): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7803 | Return: 3.17 | Eps(step=345889): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7804 | Return: 2.21 | Eps(step=345894): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7805 | Return: 1.93 | Eps(step=345902): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7806 | Return: 2.19 | Eps(step=345909): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7807 | Return: 2.45 | Eps(step=345915): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7808 | Return: 1.44 | Eps(step=345923): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7809 | Return: 2.92 | Eps(step=345932): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7810 | Return: 2.82 | Eps(step=345951): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7811 | Return: 2.89 | Eps(step=345963): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7812 | Return: 2.45 | Eps(step=345969): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7813 | Return: 2.69 | Eps(step=345976): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7814 | Return: 1.48 | Eps(step=345979): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7815 | Return: 2.45 | Eps(step=345985): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7816 | Return: 1.97 | Eps(step=345989): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7817 | Return: 2.20 | Eps(step=345995): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7818 | Return: 3.41 | Eps(step=346005): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7819 | Return: 1.88 | Eps(step=346014): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7820 | Return: 1.97 | Eps(step=346018): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7821 | Return: 3.16 | Eps(step=346028): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7822 | Return: 2.64 | Eps(step=346041): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7823 | Return: 2.69 | Eps(step=346048): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7824 | Return: 1.49 | Eps(step=346050): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7825 | Return: 3.08 | Eps(step=346064): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7826 | Return: 3.17 | Eps(step=346073): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7827 | Return: 2.43 | Eps(step=346081): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7828 | Return: 1.96 | Eps(step=346086): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7829 | Return: 2.45 | Eps(step=346092): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7830 | Return: 1.49 | Eps(step=346094): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7831 | Return: 2.41 | Eps(step=346104): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7832 | Return: 3.63 | Eps(step=346117): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7833 | Return: 1.95 | Eps(step=346123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7834 | Return: 2.67 | Eps(step=346132): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7835 | Return: 1.69 | Eps(step=346139): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7836 | Return: 2.93 | Eps(step=346147): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7837 | Return: 2.67 | Eps(step=346156): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7838 | Return: 1.25 | Eps(step=346157): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7839 | Return: 3.17 | Eps(step=346166): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7840 | Return: 0.98 | Eps(step=346240): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7841 | Return: 2.93 | Eps(step=346248): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7842 | Return: 1.73 | Eps(step=346251): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7843 | Return: 1.47 | Eps(step=346255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7844 | Return: 1.00 | Eps(step=346256): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7845 | Return: 3.17 | Eps(step=346265): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7846 | Return: 2.69 | Eps(step=346272): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7847 | Return: 2.18 | Eps(step=346280): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7848 | Return: 2.05 | Eps(step=346301): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7849 | Return: 2.21 | Eps(step=346306): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7850 | Return: 1.97 | Eps(step=346310): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7851 | Return: 1.97 | Eps(step=346314): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7852 | Return: 2.63 | Eps(step=346327): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7853 | Return: 3.38 | Eps(step=346340): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7854 | Return: 2.45 | Eps(step=346346): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7855 | Return: 2.21 | Eps(step=346351): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7856 | Return: 2.19 | Eps(step=346358): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7857 | Return: 2.45 | Eps(step=346364): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7858 | Return: 1.95 | Eps(step=346370): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7859 | Return: 2.19 | Eps(step=346377): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7860 | Return: 2.19 | Eps(step=346384): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7861 | Return: 2.19 | Eps(step=346391): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7862 | Return: -0.51 | Eps(step=346435): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7863 | Return: 1.97 | Eps(step=346439): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7864 | Return: 2.21 | Eps(step=346444): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7865 | Return: 3.17 | Eps(step=346453): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7866 | Return: 2.68 | Eps(step=346461): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7867 | Return: 1.49 | Eps(step=346463): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7868 | Return: 3.17 | Eps(step=346472): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7869 | Return: 2.65 | Eps(step=346483): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7870 | Return: 1.97 | Eps(step=346487): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7871 | Return: 2.81 | Eps(step=346507): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7872 | Return: 1.73 | Eps(step=346510): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7873 | Return: 1.97 | Eps(step=346514): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7874 | Return: 2.45 | Eps(step=346520): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7875 | Return: 1.49 | Eps(step=346522): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7876 | Return: 1.73 | Eps(step=346525): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7877 | Return: 2.43 | Eps(step=346533): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7878 | Return: 2.19 | Eps(step=346540): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7879 | Return: 1.38 | Eps(step=346574): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7880 | Return: -0.22 | Eps(step=346595): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7881 | Return: 1.45 | Eps(step=346601): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7882 | Return: 2.93 | Eps(step=346609): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7883 | Return: 3.65 | Eps(step=346620): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7884 | Return: 2.59 | Eps(step=346637): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7885 | Return: 2.21 | Eps(step=346642): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7886 | Return: 1.91 | Eps(step=346652): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7887 | Return: 2.66 | Eps(step=346662): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7888 | Return: 2.61 | Eps(step=346678): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7889 | Return: 1.00 | Eps(step=346679): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7890 | Return: 2.81 | Eps(step=346699): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7891 | Return: 1.73 | Eps(step=346702): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7892 | Return: 1.97 | Eps(step=346706): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7893 | Return: 1.49 | Eps(step=346708): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7894 | Return: 3.65 | Eps(step=346719): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7895 | Return: 2.21 | Eps(step=346724): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7896 | Return: 3.63 | Eps(step=346737): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7897 | Return: 1.71 | Eps(step=346742): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7898 | Return: 1.45 | Eps(step=346823): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7899 | Return: 1.00 | Eps(step=346824): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7900 | Return: 1.49 | Eps(step=346826): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7901 | Return: 1.72 | Eps(step=346830): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7902 | Return: 2.45 | Eps(step=346836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7903 | Return: 3.40 | Eps(step=346847): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7904 | Return: -22.17 | Eps(step=347847): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7905 | Return: 0.35 | Eps(step=347939): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7906 | Return: 2.12 | Eps(step=347953): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7907 | Return: 2.89 | Eps(step=347965): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7908 | Return: 0.63 | Eps(step=347999): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7909 | Return: 1.49 | Eps(step=348001): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7910 | Return: 1.00 | Eps(step=348002): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7911 | Return: -0.90 | Eps(step=348032): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7912 | Return: 2.72 | Eps(step=348061): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7913 | Return: 1.25 | Eps(step=348062): 0.100 | AvgLoss: 0.0000\n",
            "Episode 7914 | Return: 1.49 | Eps(step=348064): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7915 | Return: 1.97 | Eps(step=348093): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7916 | Return: 2.87 | Eps(step=348107): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7917 | Return: 1.25 | Eps(step=348108): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7918 | Return: 2.58 | Eps(step=348126): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7919 | Return: 3.19 | Eps(step=348158): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7920 | Return: -0.37 | Eps(step=348169): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7921 | Return: 1.97 | Eps(step=348173): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7922 | Return: 2.41 | Eps(step=348183): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7923 | Return: 2.20 | Eps(step=348189): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7924 | Return: 1.39 | Eps(step=348197): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7925 | Return: 3.28 | Eps(step=348220): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7926 | Return: 3.46 | Eps(step=348250): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7927 | Return: 2.59 | Eps(step=348267): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7928 | Return: 1.61 | Eps(step=348278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7929 | Return: 0.24 | Eps(step=348281): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7930 | Return: 1.61 | Eps(step=348293): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7931 | Return: 2.16 | Eps(step=348304): 0.100 | AvgLoss: 0.0004\n",
            "Episode 7932 | Return: 2.33 | Eps(step=348322): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7933 | Return: 2.21 | Eps(step=348327): 0.100 | AvgLoss: 0.0001\n",
            "Episode 7934 | Return: 3.14 | Eps(step=348339): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7935 | Return: 3.65 | Eps(step=348350): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7936 | Return: 1.97 | Eps(step=348354): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7937 | Return: 2.69 | Eps(step=348361): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7938 | Return: 2.21 | Eps(step=348366): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7939 | Return: 2.67 | Eps(step=348375): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7940 | Return: 1.97 | Eps(step=348379): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7941 | Return: 1.65 | Eps(step=348390): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7942 | Return: 2.69 | Eps(step=348397): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7943 | Return: 0.96 | Eps(step=348403): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7944 | Return: 2.45 | Eps(step=348409): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7945 | Return: 0.72 | Eps(step=348414): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7946 | Return: 3.87 | Eps(step=348428): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7947 | Return: 3.15 | Eps(step=348439): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7948 | Return: 1.73 | Eps(step=348442): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7949 | Return: 1.44 | Eps(step=348450): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7950 | Return: 2.45 | Eps(step=348456): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7951 | Return: 1.97 | Eps(step=348460): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7952 | Return: 2.67 | Eps(step=348469): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7953 | Return: 3.17 | Eps(step=348478): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7954 | Return: 1.40 | Eps(step=348485): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7955 | Return: 1.00 | Eps(step=348486): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7956 | Return: 1.49 | Eps(step=348488): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7957 | Return: 3.41 | Eps(step=348498): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7958 | Return: 3.46 | Eps(step=348528): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7959 | Return: 3.41 | Eps(step=348538): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7960 | Return: 2.21 | Eps(step=348543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7961 | Return: 2.69 | Eps(step=348550): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7962 | Return: 2.45 | Eps(step=348556): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7963 | Return: 1.73 | Eps(step=348559): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7964 | Return: 2.89 | Eps(step=348571): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7965 | Return: 2.45 | Eps(step=348577): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7966 | Return: -0.28 | Eps(step=348583): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7967 | Return: 2.19 | Eps(step=348590): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7968 | Return: 2.65 | Eps(step=348601): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7969 | Return: 3.65 | Eps(step=348612): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7970 | Return: 1.49 | Eps(step=348614): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7971 | Return: 1.73 | Eps(step=348617): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7972 | Return: 1.73 | Eps(step=348620): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7973 | Return: 3.17 | Eps(step=348629): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7974 | Return: 1.49 | Eps(step=348631): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7975 | Return: 3.64 | Eps(step=348643): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7976 | Return: 1.66 | Eps(step=348649): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7977 | Return: 1.71 | Eps(step=348654): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7978 | Return: 2.67 | Eps(step=348663): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7979 | Return: 1.95 | Eps(step=348669): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7980 | Return: 1.73 | Eps(step=348672): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7981 | Return: 2.93 | Eps(step=348680): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7982 | Return: 2.21 | Eps(step=348685): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7983 | Return: 0.14 | Eps(step=348700): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7984 | Return: 3.14 | Eps(step=348712): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7985 | Return: 3.39 | Eps(step=348724): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7986 | Return: 1.93 | Eps(step=348732): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7987 | Return: 0.66 | Eps(step=348738): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7988 | Return: 1.73 | Eps(step=348741): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7989 | Return: 1.73 | Eps(step=348744): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7990 | Return: 1.97 | Eps(step=348748): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7991 | Return: 1.42 | Eps(step=348758): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7992 | Return: 1.97 | Eps(step=348762): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7993 | Return: 1.47 | Eps(step=348766): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7994 | Return: 2.17 | Eps(step=348775): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7995 | Return: 1.73 | Eps(step=348778): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7996 | Return: 2.21 | Eps(step=348783): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7997 | Return: 1.48 | Eps(step=348786): 0.100 | AvgLoss: 0.0003\n",
            "Episode 7998 | Return: 3.17 | Eps(step=348795): 0.100 | AvgLoss: 0.0002\n",
            "Episode 7999 | Return: 0.94 | Eps(step=348803): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8000 | Return: 1.97 | Eps(step=348807): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8001 | Return: 0.70 | Eps(step=348809): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8002 | Return: 1.97 | Eps(step=348813): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8003 | Return: 1.90 | Eps(step=348820): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8004 | Return: 2.91 | Eps(step=348830): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8005 | Return: -0.48 | Eps(step=348902): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8006 | Return: 2.21 | Eps(step=348907): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8007 | Return: 2.93 | Eps(step=348915): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8008 | Return: 1.00 | Eps(step=348916): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8009 | Return: 2.67 | Eps(step=348925): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8010 | Return: 3.06 | Eps(step=348945): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8011 | Return: 2.19 | Eps(step=348952): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8012 | Return: 1.73 | Eps(step=348980): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8013 | Return: 2.13 | Eps(step=348989): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8014 | Return: 1.49 | Eps(step=348991): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8015 | Return: 2.21 | Eps(step=348996): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8016 | Return: 1.97 | Eps(step=349000): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8017 | Return: 3.64 | Eps(step=349012): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8018 | Return: 1.00 | Eps(step=349013): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8019 | Return: -0.35 | Eps(step=349026): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8020 | Return: 2.93 | Eps(step=349034): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8021 | Return: 1.49 | Eps(step=349036): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8022 | Return: 2.43 | Eps(step=349044): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8023 | Return: 3.38 | Eps(step=349057): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8024 | Return: -17.46 | Eps(step=350057): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8025 | Return: 2.99 | Eps(step=350080): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8026 | Return: 1.42 | Eps(step=350090): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8027 | Return: 1.95 | Eps(step=350096): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8028 | Return: 3.17 | Eps(step=350105): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8029 | Return: 1.97 | Eps(step=350109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8030 | Return: 0.89 | Eps(step=350123): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8031 | Return: 1.73 | Eps(step=350126): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8032 | Return: 2.21 | Eps(step=350131): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8033 | Return: 2.58 | Eps(step=350150): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8034 | Return: 1.49 | Eps(step=350152): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8035 | Return: 2.87 | Eps(step=350191): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8036 | Return: 2.93 | Eps(step=350199): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8037 | Return: 2.21 | Eps(step=350204): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8038 | Return: 2.67 | Eps(step=350213): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8039 | Return: 1.49 | Eps(step=350215): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8040 | Return: 2.45 | Eps(step=350221): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8041 | Return: 2.66 | Eps(step=350231): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8042 | Return: 3.40 | Eps(step=350242): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8043 | Return: 1.97 | Eps(step=350246): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8044 | Return: 2.67 | Eps(step=350255): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8045 | Return: 2.66 | Eps(step=350265): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8046 | Return: 2.16 | Eps(step=350300): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8047 | Return: 1.97 | Eps(step=350304): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8048 | Return: 1.00 | Eps(step=350305): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8049 | Return: 2.17 | Eps(step=350314): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8050 | Return: 1.42 | Eps(step=350324): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8051 | Return: 1.49 | Eps(step=350326): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8052 | Return: 3.37 | Eps(step=350365): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8053 | Return: 2.44 | Eps(step=350372): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8054 | Return: 2.38 | Eps(step=350386): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8055 | Return: 1.73 | Eps(step=350389): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8056 | Return: 2.47 | Eps(step=350418): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8057 | Return: 1.73 | Eps(step=350421): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8058 | Return: -3.70 | Eps(step=350591): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8059 | Return: 1.73 | Eps(step=350594): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8060 | Return: 1.93 | Eps(step=350628): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8061 | Return: 2.21 | Eps(step=350633): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8062 | Return: 1.25 | Eps(step=350634): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8063 | Return: 1.25 | Eps(step=350635): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8064 | Return: 2.21 | Eps(step=350640): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8065 | Return: 2.43 | Eps(step=350648): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8066 | Return: 1.97 | Eps(step=350652): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8067 | Return: 1.49 | Eps(step=350654): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8068 | Return: -0.14 | Eps(step=350671): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8069 | Return: 2.93 | Eps(step=350679): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8070 | Return: 2.41 | Eps(step=350689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8071 | Return: 3.17 | Eps(step=350698): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8072 | Return: 2.45 | Eps(step=350704): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8073 | Return: 2.80 | Eps(step=350725): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8074 | Return: -24.08 | Eps(step=351725): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8075 | Return: -0.11 | Eps(step=351784): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8076 | Return: -2.73 | Eps(step=351937): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8077 | Return: 2.91 | Eps(step=351947): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8078 | Return: 1.49 | Eps(step=351949): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8079 | Return: 1.49 | Eps(step=351951): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8080 | Return: 1.73 | Eps(step=351954): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8081 | Return: 1.40 | Eps(step=351961): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8082 | Return: 2.52 | Eps(step=351985): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8083 | Return: 3.39 | Eps(step=351997): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8084 | Return: 2.45 | Eps(step=352003): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8085 | Return: 2.17 | Eps(step=352012): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8086 | Return: 3.15 | Eps(step=352023): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8087 | Return: 1.22 | Eps(step=352052): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8088 | Return: 3.63 | Eps(step=352065): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8089 | Return: 2.43 | Eps(step=352073): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8090 | Return: 3.41 | Eps(step=352083): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8091 | Return: 2.91 | Eps(step=352093): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8092 | Return: 1.49 | Eps(step=352095): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8093 | Return: 2.45 | Eps(step=352101): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8094 | Return: 2.93 | Eps(step=352109): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8095 | Return: 3.41 | Eps(step=352119): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8096 | Return: 1.88 | Eps(step=352128): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8097 | Return: 2.93 | Eps(step=352136): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8098 | Return: 2.66 | Eps(step=352146): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8099 | Return: 1.00 | Eps(step=352147): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8100 | Return: 2.92 | Eps(step=352156): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8101 | Return: 2.21 | Eps(step=352161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8102 | Return: 2.65 | Eps(step=352172): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8103 | Return: 2.21 | Eps(step=352177): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8104 | Return: 1.49 | Eps(step=352179): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8105 | Return: 1.93 | Eps(step=352187): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8106 | Return: 2.44 | Eps(step=352194): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8107 | Return: 2.69 | Eps(step=352201): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8108 | Return: 1.01 | Eps(step=352223): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8109 | Return: 2.42 | Eps(step=352232): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8110 | Return: 1.73 | Eps(step=352235): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8111 | Return: 3.84 | Eps(step=352252): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8112 | Return: 2.45 | Eps(step=352258): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8113 | Return: 2.69 | Eps(step=352265): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8114 | Return: 2.36 | Eps(step=352276): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8115 | Return: 2.62 | Eps(step=352286): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8116 | Return: 1.81 | Eps(step=352308): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8117 | Return: 1.00 | Eps(step=352309): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8118 | Return: 2.43 | Eps(step=352317): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8119 | Return: 1.71 | Eps(step=352322): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8120 | Return: 2.68 | Eps(step=352330): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8121 | Return: 1.73 | Eps(step=352333): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8122 | Return: 1.49 | Eps(step=352335): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8123 | Return: 2.69 | Eps(step=352342): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8124 | Return: 2.69 | Eps(step=352349): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8125 | Return: 2.93 | Eps(step=352357): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8126 | Return: 1.97 | Eps(step=352361): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8127 | Return: 2.84 | Eps(step=352374): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8128 | Return: 2.41 | Eps(step=352384): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8129 | Return: 1.73 | Eps(step=352387): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8130 | Return: 1.71 | Eps(step=352392): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8131 | Return: 1.62 | Eps(step=352427): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8132 | Return: 2.43 | Eps(step=352435): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8133 | Return: 1.95 | Eps(step=352441): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8134 | Return: 3.13 | Eps(step=352454): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8135 | Return: 0.73 | Eps(step=352520): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8136 | Return: 3.15 | Eps(step=352531): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8137 | Return: 1.95 | Eps(step=352537): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8138 | Return: 1.25 | Eps(step=352538): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8139 | Return: 3.89 | Eps(step=352550): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8140 | Return: 3.17 | Eps(step=352559): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8141 | Return: 0.38 | Eps(step=352574): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8142 | Return: 3.17 | Eps(step=352583): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8143 | Return: 1.90 | Eps(step=352595): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8144 | Return: 1.49 | Eps(step=352597): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8145 | Return: 1.71 | Eps(step=352602): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8146 | Return: 3.17 | Eps(step=352611): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8147 | Return: 3.41 | Eps(step=352621): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8148 | Return: 0.74 | Eps(step=352699): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8149 | Return: 1.95 | Eps(step=352705): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8150 | Return: 2.91 | Eps(step=352715): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8151 | Return: 2.93 | Eps(step=352723): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8152 | Return: 1.94 | Eps(step=352730): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8153 | Return: 1.97 | Eps(step=352734): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8154 | Return: 1.49 | Eps(step=352736): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8155 | Return: 2.49 | Eps(step=352763): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8156 | Return: 2.45 | Eps(step=352769): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8157 | Return: 2.44 | Eps(step=352776): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8158 | Return: 2.19 | Eps(step=352783): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8159 | Return: 2.45 | Eps(step=352789): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8160 | Return: -20.36 | Eps(step=353581): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8161 | Return: 1.59 | Eps(step=353598): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8162 | Return: 2.63 | Eps(step=353636): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8163 | Return: 2.74 | Eps(step=353684): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8164 | Return: 2.26 | Eps(step=353734): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8165 | Return: 2.60 | Eps(step=353746): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8166 | Return: -0.05 | Eps(step=353800): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8167 | Return: 2.84 | Eps(step=353817): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8168 | Return: 2.84 | Eps(step=353859): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8169 | Return: 2.69 | Eps(step=353866): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8170 | Return: 2.45 | Eps(step=353872): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8171 | Return: 2.21 | Eps(step=353877): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8172 | Return: 1.18 | Eps(step=353886): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8173 | Return: 2.45 | Eps(step=353892): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8174 | Return: 2.69 | Eps(step=353899): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8175 | Return: 2.42 | Eps(step=353908): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8176 | Return: 2.68 | Eps(step=353916): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8177 | Return: 2.69 | Eps(step=353923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8178 | Return: 1.82 | Eps(step=353942): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8179 | Return: -2.80 | Eps(step=354038): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8180 | Return: 1.25 | Eps(step=354039): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8181 | Return: 2.45 | Eps(step=354045): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8182 | Return: 1.73 | Eps(step=354048): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8183 | Return: 1.49 | Eps(step=354050): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8184 | Return: 2.69 | Eps(step=354057): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8185 | Return: 3.41 | Eps(step=354067): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8186 | Return: 2.44 | Eps(step=354074): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8187 | Return: 0.92 | Eps(step=354084): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8188 | Return: 1.42 | Eps(step=354094): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8189 | Return: 1.62 | Eps(step=354104): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8190 | Return: 2.45 | Eps(step=354110): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8191 | Return: 1.49 | Eps(step=354112): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8192 | Return: 1.73 | Eps(step=354115): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8193 | Return: 1.49 | Eps(step=354117): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8194 | Return: 2.69 | Eps(step=354124): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8195 | Return: 2.21 | Eps(step=354129): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8196 | Return: 2.67 | Eps(step=354138): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8197 | Return: 2.64 | Eps(step=354151): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8198 | Return: 2.45 | Eps(step=354157): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8199 | Return: 1.16 | Eps(step=354163): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8200 | Return: 2.37 | Eps(step=354178): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8201 | Return: 1.25 | Eps(step=354179): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8202 | Return: 2.93 | Eps(step=354187): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8203 | Return: 1.68 | Eps(step=354196): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8204 | Return: 1.22 | Eps(step=354221): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8205 | Return: 3.15 | Eps(step=354232): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8206 | Return: 2.01 | Eps(step=354253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8207 | Return: 3.41 | Eps(step=354263): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8208 | Return: 1.93 | Eps(step=354271): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8209 | Return: 2.91 | Eps(step=354281): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8210 | Return: 2.45 | Eps(step=354287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8211 | Return: 1.95 | Eps(step=354293): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8212 | Return: 2.37 | Eps(step=354307): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8213 | Return: 1.00 | Eps(step=354308): 0.100 | AvgLoss: 0.0006\n",
            "Episode 8214 | Return: 2.12 | Eps(step=354318): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8215 | Return: 3.39 | Eps(step=354330): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8216 | Return: 3.39 | Eps(step=354342): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8217 | Return: 2.21 | Eps(step=354347): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8218 | Return: 1.71 | Eps(step=354352): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8219 | Return: 3.64 | Eps(step=354364): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8220 | Return: 2.45 | Eps(step=354370): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8221 | Return: 1.64 | Eps(step=354378): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8222 | Return: 2.45 | Eps(step=354384): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8223 | Return: 2.93 | Eps(step=354392): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8224 | Return: 3.41 | Eps(step=354402): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8225 | Return: 2.19 | Eps(step=354409): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8226 | Return: 1.96 | Eps(step=354414): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8227 | Return: 1.25 | Eps(step=354415): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8228 | Return: 3.40 | Eps(step=354426): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8229 | Return: 2.45 | Eps(step=354432): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8230 | Return: 2.19 | Eps(step=354439): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8231 | Return: 2.69 | Eps(step=354446): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8232 | Return: 0.95 | Eps(step=354453): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8233 | Return: 3.65 | Eps(step=354464): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8234 | Return: 3.17 | Eps(step=354473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8235 | Return: 2.69 | Eps(step=354480): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8236 | Return: 2.93 | Eps(step=354488): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8237 | Return: 2.19 | Eps(step=354495): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8238 | Return: 2.12 | Eps(step=354505): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8239 | Return: 2.69 | Eps(step=354512): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8240 | Return: 3.87 | Eps(step=354526): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8241 | Return: 2.43 | Eps(step=354534): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8242 | Return: 1.18 | Eps(step=354543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8243 | Return: 2.93 | Eps(step=354551): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8244 | Return: 2.45 | Eps(step=354557): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8245 | Return: 2.21 | Eps(step=354562): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8246 | Return: 2.19 | Eps(step=354569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8247 | Return: 2.45 | Eps(step=354575): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8248 | Return: 2.43 | Eps(step=354583): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8249 | Return: 2.45 | Eps(step=354589): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8250 | Return: 1.00 | Eps(step=354590): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8251 | Return: 3.38 | Eps(step=354603): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8252 | Return: 2.93 | Eps(step=354611): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8253 | Return: 1.97 | Eps(step=354615): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8254 | Return: 2.91 | Eps(step=354625): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8255 | Return: 2.93 | Eps(step=354633): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8256 | Return: 3.63 | Eps(step=354646): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8257 | Return: 1.95 | Eps(step=354652): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8258 | Return: 2.93 | Eps(step=354660): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8259 | Return: 1.93 | Eps(step=354668): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8260 | Return: 3.15 | Eps(step=354679): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8261 | Return: 1.93 | Eps(step=354687): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8262 | Return: 1.49 | Eps(step=354689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8263 | Return: 2.32 | Eps(step=354709): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8264 | Return: 1.49 | Eps(step=354711): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8265 | Return: 1.73 | Eps(step=354714): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8266 | Return: 2.21 | Eps(step=354719): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8267 | Return: -5.25 | Eps(step=355316): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8268 | Return: 2.93 | Eps(step=355324): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8269 | Return: 2.44 | Eps(step=355356): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8270 | Return: 1.62 | Eps(step=355366): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8271 | Return: 1.97 | Eps(step=355370): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8272 | Return: 3.52 | Eps(step=355394): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8273 | Return: 2.18 | Eps(step=355402): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8274 | Return: 0.12 | Eps(step=355488): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8275 | Return: 1.23 | Eps(step=355562): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8276 | Return: 0.96 | Eps(step=355568): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8277 | Return: 1.00 | Eps(step=355569): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8278 | Return: 2.43 | Eps(step=355577): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8279 | Return: 1.00 | Eps(step=355578): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8280 | Return: 1.73 | Eps(step=355581): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8281 | Return: 1.17 | Eps(step=355586): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8282 | Return: 2.65 | Eps(step=355597): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8283 | Return: 2.67 | Eps(step=355606): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8284 | Return: 2.76 | Eps(step=355627): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8285 | Return: 1.49 | Eps(step=355629): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8286 | Return: 1.97 | Eps(step=355633): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8287 | Return: 2.43 | Eps(step=355641): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8288 | Return: 2.67 | Eps(step=355650): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8289 | Return: 2.66 | Eps(step=355685): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8290 | Return: 0.86 | Eps(step=355698): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8291 | Return: 2.65 | Eps(step=355709): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8292 | Return: 1.49 | Eps(step=355711): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8293 | Return: 2.21 | Eps(step=355716): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8294 | Return: 2.91 | Eps(step=355726): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8295 | Return: 3.15 | Eps(step=355737): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8296 | Return: 1.27 | Eps(step=355753): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8297 | Return: 2.67 | Eps(step=355762): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8298 | Return: 1.96 | Eps(step=355767): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8299 | Return: 2.67 | Eps(step=355776): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8300 | Return: 0.67 | Eps(step=355806): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8301 | Return: 1.97 | Eps(step=355810): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8302 | Return: 1.97 | Eps(step=355814): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8303 | Return: 3.17 | Eps(step=355823): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8304 | Return: 1.97 | Eps(step=355827): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8305 | Return: 1.97 | Eps(step=355831): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8306 | Return: 1.77 | Eps(step=355872): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8307 | Return: 3.17 | Eps(step=355881): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8308 | Return: 3.63 | Eps(step=355894): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8309 | Return: 2.62 | Eps(step=355908): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8310 | Return: 2.21 | Eps(step=355913): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8311 | Return: 2.43 | Eps(step=355921): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8312 | Return: 2.69 | Eps(step=355928): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8313 | Return: 2.39 | Eps(step=355940): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8314 | Return: 3.40 | Eps(step=355951): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8315 | Return: 1.69 | Eps(step=355958): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8316 | Return: 2.44 | Eps(step=355965): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8317 | Return: 2.93 | Eps(step=355973): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8318 | Return: 2.93 | Eps(step=355981): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8319 | Return: 2.21 | Eps(step=355986): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8320 | Return: 2.83 | Eps(step=356004): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8321 | Return: 3.60 | Eps(step=356020): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8322 | Return: 0.24 | Eps(step=356023): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8323 | Return: 1.25 | Eps(step=356024): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8324 | Return: 1.25 | Eps(step=356025): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8325 | Return: 2.21 | Eps(step=356030): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8326 | Return: 0.99 | Eps(step=356078): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8327 | Return: 3.14 | Eps(step=356090): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8328 | Return: 3.40 | Eps(step=356101): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8329 | Return: 2.12 | Eps(step=356115): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8330 | Return: 2.65 | Eps(step=356126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8331 | Return: 2.21 | Eps(step=356131): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8332 | Return: 2.93 | Eps(step=356139): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8333 | Return: 2.37 | Eps(step=356153): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8334 | Return: 2.45 | Eps(step=356159): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8335 | Return: -1.23 | Eps(step=356296): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8336 | Return: 0.98 | Eps(step=356299): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8337 | Return: 1.00 | Eps(step=356300): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8338 | Return: 2.21 | Eps(step=356305): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8339 | Return: 2.43 | Eps(step=356313): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8340 | Return: 1.38 | Eps(step=356322): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8341 | Return: 2.35 | Eps(step=356338): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8342 | Return: 3.81 | Eps(step=356358): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8343 | Return: 1.00 | Eps(step=356359): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8344 | Return: 1.39 | Eps(step=356371): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8345 | Return: 1.71 | Eps(step=356376): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8346 | Return: 2.21 | Eps(step=356381): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8347 | Return: 1.49 | Eps(step=356383): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8348 | Return: 2.69 | Eps(step=356390): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8349 | Return: 2.69 | Eps(step=356397): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8350 | Return: 1.49 | Eps(step=356399): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8351 | Return: 1.56 | Eps(step=356415): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8352 | Return: 3.62 | Eps(step=356429): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8353 | Return: 2.69 | Eps(step=356436): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8354 | Return: 3.13 | Eps(step=356449): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8355 | Return: 3.83 | Eps(step=356467): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8356 | Return: 2.43 | Eps(step=356475): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8357 | Return: 1.47 | Eps(step=356479): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8358 | Return: 1.97 | Eps(step=356483): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8359 | Return: 1.25 | Eps(step=356484): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8360 | Return: 2.21 | Eps(step=356489): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8361 | Return: 2.58 | Eps(step=356532): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8362 | Return: 2.69 | Eps(step=356539): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8363 | Return: 3.17 | Eps(step=356548): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8364 | Return: 3.89 | Eps(step=356560): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8365 | Return: 2.69 | Eps(step=356567): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8366 | Return: 1.49 | Eps(step=356569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8367 | Return: 1.49 | Eps(step=356571): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8368 | Return: 3.77 | Eps(step=356595): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8369 | Return: 1.97 | Eps(step=356599): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8370 | Return: 1.25 | Eps(step=356600): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8371 | Return: 1.97 | Eps(step=356604): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8372 | Return: 2.93 | Eps(step=356612): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8373 | Return: 2.69 | Eps(step=356619): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8374 | Return: 1.73 | Eps(step=356622): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8375 | Return: 2.93 | Eps(step=356630): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8376 | Return: 2.93 | Eps(step=356638): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8377 | Return: 3.39 | Eps(step=356650): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8378 | Return: 2.19 | Eps(step=356657): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8379 | Return: 1.49 | Eps(step=356659): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8380 | Return: 2.45 | Eps(step=356665): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8381 | Return: 1.12 | Eps(step=356681): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8382 | Return: 3.39 | Eps(step=356693): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8383 | Return: -22.07 | Eps(step=357693): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8384 | Return: 1.87 | Eps(step=357707): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8385 | Return: 2.69 | Eps(step=357714): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8386 | Return: 1.79 | Eps(step=357811): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8387 | Return: 1.38 | Eps(step=357820): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8388 | Return: 1.00 | Eps(step=357821): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8389 | Return: 2.12 | Eps(step=357835): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8390 | Return: 1.25 | Eps(step=357836): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8391 | Return: 2.92 | Eps(step=357845): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8392 | Return: 2.57 | Eps(step=357889): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8393 | Return: 2.21 | Eps(step=357894): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8394 | Return: 1.97 | Eps(step=357898): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8395 | Return: 2.21 | Eps(step=357903): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8396 | Return: 1.97 | Eps(step=357907): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8397 | Return: 3.17 | Eps(step=357916): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8398 | Return: 1.67 | Eps(step=357926): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8399 | Return: 1.25 | Eps(step=357927): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8400 | Return: 1.97 | Eps(step=357931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8401 | Return: 2.66 | Eps(step=357941): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8402 | Return: 2.21 | Eps(step=357946): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8403 | Return: 3.88 | Eps(step=357959): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8404 | Return: 2.91 | Eps(step=357994): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8405 | Return: 1.97 | Eps(step=357998): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8406 | Return: 0.16 | Eps(step=358056): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8407 | Return: 2.43 | Eps(step=358064): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8408 | Return: 2.93 | Eps(step=358072): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8409 | Return: 3.17 | Eps(step=358081): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8410 | Return: 3.89 | Eps(step=358093): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8411 | Return: 2.39 | Eps(step=358105): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8412 | Return: 2.69 | Eps(step=358112): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8413 | Return: 2.21 | Eps(step=358117): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8414 | Return: 2.01 | Eps(step=358159): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8415 | Return: 1.25 | Eps(step=358160): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8416 | Return: 1.73 | Eps(step=358163): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8417 | Return: 1.73 | Eps(step=358166): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8418 | Return: 1.95 | Eps(step=358172): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8419 | Return: 3.64 | Eps(step=358184): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8420 | Return: 2.21 | Eps(step=358189): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8421 | Return: 1.73 | Eps(step=358192): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8422 | Return: 3.41 | Eps(step=358202): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8423 | Return: 2.21 | Eps(step=358207): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8424 | Return: 3.17 | Eps(step=358216): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8425 | Return: 1.40 | Eps(step=358223): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8426 | Return: 2.03 | Eps(step=358238): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8427 | Return: 2.93 | Eps(step=358246): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8428 | Return: 1.73 | Eps(step=358249): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8429 | Return: 2.10 | Eps(step=358261): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8430 | Return: 1.45 | Eps(step=358267): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8431 | Return: 2.65 | Eps(step=358278): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8432 | Return: 3.16 | Eps(step=358288): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8433 | Return: 1.49 | Eps(step=358290): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8434 | Return: 2.67 | Eps(step=358299): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8435 | Return: 2.21 | Eps(step=358304): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8436 | Return: 1.97 | Eps(step=358308): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8437 | Return: 3.63 | Eps(step=358321): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8438 | Return: 2.38 | Eps(step=358330): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8439 | Return: 1.68 | Eps(step=358359): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8440 | Return: 2.16 | Eps(step=358370): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8441 | Return: -0.31 | Eps(step=358374): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8442 | Return: 2.89 | Eps(step=358386): 0.100 | AvgLoss: 0.0006\n",
            "Episode 8443 | Return: 1.49 | Eps(step=358388): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8444 | Return: 1.66 | Eps(step=358399): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8445 | Return: 2.89 | Eps(step=358411): 0.100 | AvgLoss: 0.0005\n",
            "Episode 8446 | Return: 1.73 | Eps(step=358414): 0.100 | AvgLoss: 0.0005\n",
            "Episode 8447 | Return: 1.97 | Eps(step=358418): 0.100 | AvgLoss: 0.0005\n",
            "Episode 8448 | Return: 1.97 | Eps(step=358422): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8449 | Return: 1.49 | Eps(step=358424): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8450 | Return: 2.45 | Eps(step=358430): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8451 | Return: 2.92 | Eps(step=358439): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8452 | Return: 3.39 | Eps(step=358451): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8453 | Return: 1.49 | Eps(step=358453): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8454 | Return: 2.17 | Eps(step=358462): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8455 | Return: 1.97 | Eps(step=358466): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8456 | Return: 1.49 | Eps(step=358468): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8457 | Return: 1.65 | Eps(step=358480): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8458 | Return: 1.62 | Eps(step=358490): 0.100 | AvgLoss: 0.0005\n",
            "Episode 8459 | Return: 2.93 | Eps(step=358498): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8460 | Return: 1.25 | Eps(step=358499): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8461 | Return: 1.71 | Eps(step=358530): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8462 | Return: 3.64 | Eps(step=358542): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8463 | Return: 2.45 | Eps(step=358548): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8464 | Return: 2.21 | Eps(step=358553): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8465 | Return: 1.97 | Eps(step=358557): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8466 | Return: 3.34 | Eps(step=358574): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8467 | Return: 0.74 | Eps(step=358597): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8468 | Return: 1.41 | Eps(step=358608): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8469 | Return: 3.14 | Eps(step=358620): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8470 | Return: 2.15 | Eps(step=358631): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8471 | Return: 2.69 | Eps(step=358638): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8472 | Return: 1.49 | Eps(step=358640): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8473 | Return: 2.68 | Eps(step=358648): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8474 | Return: 2.92 | Eps(step=358657): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8475 | Return: 1.49 | Eps(step=358659): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8476 | Return: 3.17 | Eps(step=358668): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8477 | Return: 1.63 | Eps(step=358702): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8478 | Return: 2.93 | Eps(step=358710): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8479 | Return: -0.44 | Eps(step=358753): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8480 | Return: 1.25 | Eps(step=358754): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8481 | Return: 1.68 | Eps(step=358763): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8482 | Return: 3.15 | Eps(step=358774): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8483 | Return: 3.61 | Eps(step=358789): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8484 | Return: 2.93 | Eps(step=358797): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8485 | Return: -1.11 | Eps(step=359006): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8486 | Return: -0.59 | Eps(step=359058): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8487 | Return: 2.67 | Eps(step=359067): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8488 | Return: 1.25 | Eps(step=359068): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8489 | Return: 2.41 | Eps(step=359078): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8490 | Return: 2.62 | Eps(step=359093): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8491 | Return: 1.97 | Eps(step=359097): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8492 | Return: 2.91 | Eps(step=359107): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8493 | Return: 1.97 | Eps(step=359111): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8494 | Return: 3.17 | Eps(step=359120): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8495 | Return: 1.51 | Eps(step=359145): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8496 | Return: 1.49 | Eps(step=359147): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8497 | Return: 3.16 | Eps(step=359157): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8498 | Return: 2.84 | Eps(step=359199): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8499 | Return: 1.25 | Eps(step=359200): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8500 | Return: 2.43 | Eps(step=359208): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8501 | Return: 1.04 | Eps(step=359231): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8502 | Return: -0.57 | Eps(step=359242): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8503 | Return: 2.42 | Eps(step=359251): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8504 | Return: -14.52 | Eps(step=360157): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8505 | Return: 2.20 | Eps(step=360163): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8506 | Return: 2.19 | Eps(step=360170): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8507 | Return: 2.93 | Eps(step=360178): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8508 | Return: 1.73 | Eps(step=360181): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8509 | Return: 3.15 | Eps(step=360192): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8510 | Return: 2.08 | Eps(step=360206): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8511 | Return: 2.45 | Eps(step=360212): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8512 | Return: 2.79 | Eps(step=360234): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8513 | Return: 2.69 | Eps(step=360241): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8514 | Return: 2.69 | Eps(step=360248): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8515 | Return: 2.93 | Eps(step=360256): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8516 | Return: 1.73 | Eps(step=360259): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8517 | Return: 2.45 | Eps(step=360265): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8518 | Return: 2.43 | Eps(step=360273): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8519 | Return: 2.67 | Eps(step=360282): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8520 | Return: 1.79 | Eps(step=360300): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8521 | Return: 2.21 | Eps(step=360305): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8522 | Return: 2.45 | Eps(step=360311): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8523 | Return: 1.93 | Eps(step=360319): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8524 | Return: 1.97 | Eps(step=360323): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8525 | Return: 3.13 | Eps(step=360336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8526 | Return: 2.69 | Eps(step=360343): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8527 | Return: 1.73 | Eps(step=360346): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8528 | Return: 2.85 | Eps(step=360363): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8529 | Return: 1.70 | Eps(step=360390): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8530 | Return: 2.21 | Eps(step=360395): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8531 | Return: 2.81 | Eps(step=360415): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8532 | Return: 3.41 | Eps(step=360425): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8533 | Return: 1.25 | Eps(step=360426): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8534 | Return: 2.68 | Eps(step=360434): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8535 | Return: 2.68 | Eps(step=360442): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8536 | Return: 2.21 | Eps(step=360447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8537 | Return: 1.49 | Eps(step=360449): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8538 | Return: 3.63 | Eps(step=360462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8539 | Return: 2.92 | Eps(step=360471): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8540 | Return: 2.45 | Eps(step=360477): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8541 | Return: 2.66 | Eps(step=360487): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8542 | Return: 1.55 | Eps(step=360500): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8543 | Return: 2.45 | Eps(step=360506): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8544 | Return: 2.92 | Eps(step=360515): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8545 | Return: 1.24 | Eps(step=360534): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8546 | Return: 0.99 | Eps(step=360536): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8547 | Return: 2.93 | Eps(step=360544): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8548 | Return: 1.25 | Eps(step=360545): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8549 | Return: 3.41 | Eps(step=360555): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8550 | Return: 1.97 | Eps(step=360559): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8551 | Return: 1.49 | Eps(step=360561): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8552 | Return: 0.24 | Eps(step=360564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8553 | Return: 3.39 | Eps(step=360576): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8554 | Return: 1.49 | Eps(step=360578): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8555 | Return: 1.97 | Eps(step=360582): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8556 | Return: 1.49 | Eps(step=360584): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8557 | Return: 1.85 | Eps(step=360600): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8558 | Return: 1.71 | Eps(step=360605): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8559 | Return: 2.21 | Eps(step=360610): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8560 | Return: 2.68 | Eps(step=360618): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8561 | Return: 2.88 | Eps(step=360631): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8562 | Return: 2.93 | Eps(step=360639): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8563 | Return: 2.45 | Eps(step=360645): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8564 | Return: 2.21 | Eps(step=360650): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8565 | Return: 3.39 | Eps(step=360662): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8566 | Return: 2.69 | Eps(step=360669): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8567 | Return: 2.93 | Eps(step=360677): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8568 | Return: 1.73 | Eps(step=360680): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8569 | Return: 2.10 | Eps(step=360692): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8570 | Return: 2.93 | Eps(step=360700): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8571 | Return: 1.73 | Eps(step=360703): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8572 | Return: 2.67 | Eps(step=360712): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8573 | Return: 1.49 | Eps(step=360714): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8574 | Return: 2.43 | Eps(step=360722): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8575 | Return: 1.03 | Eps(step=360816): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8576 | Return: 2.45 | Eps(step=360822): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8577 | Return: 1.73 | Eps(step=360825): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8578 | Return: 1.73 | Eps(step=360828): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8579 | Return: 2.14 | Eps(step=360836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8580 | Return: 3.37 | Eps(step=360850): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8581 | Return: 2.43 | Eps(step=360858): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8582 | Return: 3.41 | Eps(step=360868): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8583 | Return: 1.97 | Eps(step=360872): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8584 | Return: 2.21 | Eps(step=360877): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8585 | Return: 2.69 | Eps(step=360884): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8586 | Return: 2.45 | Eps(step=360890): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8587 | Return: -0.13 | Eps(step=360906): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8588 | Return: 3.40 | Eps(step=360917): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8589 | Return: 2.20 | Eps(step=360923): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8590 | Return: 1.62 | Eps(step=360933): 0.100 | AvgLoss: 0.0004\n",
            "Episode 8591 | Return: 3.13 | Eps(step=360946): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8592 | Return: 2.21 | Eps(step=360951): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8593 | Return: 1.25 | Eps(step=361027): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8594 | Return: 2.05 | Eps(step=361048): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8595 | Return: 2.32 | Eps(step=361067): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8596 | Return: 1.73 | Eps(step=361070): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8597 | Return: 2.45 | Eps(step=361076): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8598 | Return: 2.45 | Eps(step=361082): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8599 | Return: 1.97 | Eps(step=361086): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8600 | Return: 1.49 | Eps(step=361088): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8601 | Return: -5.49 | Eps(step=361468): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8602 | Return: 2.80 | Eps(step=361489): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8603 | Return: 2.84 | Eps(step=361506): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8604 | Return: 1.73 | Eps(step=361509): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8605 | Return: 3.36 | Eps(step=361524): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8606 | Return: 2.65 | Eps(step=361535): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8607 | Return: 2.93 | Eps(step=361543): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8608 | Return: 1.25 | Eps(step=361544): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8609 | Return: 1.95 | Eps(step=361550): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8610 | Return: 2.69 | Eps(step=361557): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8611 | Return: 1.11 | Eps(step=361568): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8612 | Return: 1.69 | Eps(step=361621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8613 | Return: 2.40 | Eps(step=361632): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8614 | Return: 1.25 | Eps(step=361633): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8615 | Return: 1.97 | Eps(step=361637): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8616 | Return: 1.86 | Eps(step=361648): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8617 | Return: 1.97 | Eps(step=361652): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8618 | Return: 1.97 | Eps(step=361656): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8619 | Return: -0.37 | Eps(step=361661): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8620 | Return: 1.71 | Eps(step=361666): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8621 | Return: 3.14 | Eps(step=361678): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8622 | Return: 2.11 | Eps(step=361693): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8623 | Return: 1.47 | Eps(step=361697): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8624 | Return: 2.59 | Eps(step=361714): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8625 | Return: 2.67 | Eps(step=361723): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8626 | Return: 2.44 | Eps(step=361730): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8627 | Return: 1.00 | Eps(step=361731): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8628 | Return: 3.41 | Eps(step=361741): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8629 | Return: 2.91 | Eps(step=361751): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8630 | Return: 2.69 | Eps(step=361758): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8631 | Return: 1.20 | Eps(step=361765): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8632 | Return: 2.91 | Eps(step=361775): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8633 | Return: 2.93 | Eps(step=361783): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8634 | Return: 1.49 | Eps(step=361785): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8635 | Return: 2.92 | Eps(step=361794): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8636 | Return: 2.69 | Eps(step=361801): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8637 | Return: 2.67 | Eps(step=361810): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8638 | Return: 0.05 | Eps(step=361833): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8639 | Return: 0.66 | Eps(step=361845): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8640 | Return: 3.14 | Eps(step=361857): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8641 | Return: 2.19 | Eps(step=361864): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8642 | Return: 2.45 | Eps(step=361870): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8643 | Return: 1.97 | Eps(step=361874): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8644 | Return: 1.00 | Eps(step=361875): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8645 | Return: 3.13 | Eps(step=361888): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8646 | Return: 2.41 | Eps(step=361898): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8647 | Return: 1.97 | Eps(step=361902): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8648 | Return: -16.52 | Eps(step=362825): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8649 | Return: 0.53 | Eps(step=362924): 0.100 | AvgLoss: 0.0000\n",
            "Episode 8650 | Return: 2.27 | Eps(step=362948): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8651 | Return: 1.47 | Eps(step=362973): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8652 | Return: 2.45 | Eps(step=362979): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8653 | Return: 2.91 | Eps(step=362989): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8654 | Return: 2.57 | Eps(step=363008): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8655 | Return: 3.17 | Eps(step=363017): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8656 | Return: 1.97 | Eps(step=363021): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8657 | Return: 1.66 | Eps(step=363027): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8658 | Return: 1.49 | Eps(step=363029): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8659 | Return: 0.34 | Eps(step=363192): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8660 | Return: 2.43 | Eps(step=363200): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8661 | Return: 3.62 | Eps(step=363214): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8662 | Return: 0.96 | Eps(step=363220): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8663 | Return: 1.40 | Eps(step=363232): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8664 | Return: 1.93 | Eps(step=363240): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8665 | Return: 1.73 | Eps(step=363243): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8666 | Return: 2.44 | Eps(step=363250): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8667 | Return: 1.48 | Eps(step=363253): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8668 | Return: 1.44 | Eps(step=363261): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8669 | Return: 2.45 | Eps(step=363267): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8670 | Return: 3.65 | Eps(step=363278): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8671 | Return: 2.91 | Eps(step=363288): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8672 | Return: 1.97 | Eps(step=363292): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8673 | Return: 1.95 | Eps(step=363298): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8674 | Return: 3.89 | Eps(step=363310): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8675 | Return: 1.97 | Eps(step=363314): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8676 | Return: 1.73 | Eps(step=363317): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8677 | Return: 1.77 | Eps(step=363387): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8678 | Return: 1.53 | Eps(step=363435): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8679 | Return: 2.19 | Eps(step=363442): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8680 | Return: 3.17 | Eps(step=363451): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8681 | Return: 3.61 | Eps(step=363466): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8682 | Return: 2.52 | Eps(step=363490): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8683 | Return: 2.21 | Eps(step=363495): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8684 | Return: 2.45 | Eps(step=363501): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8685 | Return: 1.96 | Eps(step=363506): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8686 | Return: 2.93 | Eps(step=363514): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8687 | Return: 1.97 | Eps(step=363518): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8688 | Return: 1.20 | Eps(step=363525): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8689 | Return: 1.25 | Eps(step=363526): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8690 | Return: 2.35 | Eps(step=363538): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8691 | Return: 1.49 | Eps(step=363540): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8692 | Return: 2.45 | Eps(step=363546): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8693 | Return: 2.45 | Eps(step=363552): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8694 | Return: 2.93 | Eps(step=363560): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8695 | Return: 3.13 | Eps(step=363573): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8696 | Return: 2.55 | Eps(step=363594): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8697 | Return: 1.91 | Eps(step=363604): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8698 | Return: 2.45 | Eps(step=363610): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8699 | Return: 2.07 | Eps(step=363625): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8700 | Return: 1.97 | Eps(step=363629): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8701 | Return: 2.45 | Eps(step=363635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8702 | Return: 2.93 | Eps(step=363643): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8703 | Return: 2.91 | Eps(step=363653): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8704 | Return: 1.25 | Eps(step=363654): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8705 | Return: 2.63 | Eps(step=363717): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8706 | Return: 3.15 | Eps(step=363728): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8707 | Return: 1.49 | Eps(step=363730): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8708 | Return: 2.68 | Eps(step=363738): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8709 | Return: 2.69 | Eps(step=363745): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8710 | Return: 3.65 | Eps(step=363756): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8711 | Return: 3.65 | Eps(step=363767): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8712 | Return: 3.15 | Eps(step=363778): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8713 | Return: 2.14 | Eps(step=363786): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8714 | Return: 2.93 | Eps(step=363794): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8715 | Return: 3.34 | Eps(step=363811): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8716 | Return: 2.91 | Eps(step=363821): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8717 | Return: 2.39 | Eps(step=363833): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8718 | Return: 2.93 | Eps(step=363841): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8719 | Return: 2.69 | Eps(step=363848): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8720 | Return: 1.49 | Eps(step=363850): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8721 | Return: 2.41 | Eps(step=363860): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8722 | Return: 1.90 | Eps(step=363867): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8723 | Return: 3.65 | Eps(step=363878): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8724 | Return: 3.17 | Eps(step=363887): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8725 | Return: 1.40 | Eps(step=363900): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8726 | Return: 2.67 | Eps(step=363909): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8727 | Return: 1.97 | Eps(step=363913): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8728 | Return: 3.17 | Eps(step=363922): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8729 | Return: 2.85 | Eps(step=363938): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8730 | Return: 1.20 | Eps(step=363945): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8731 | Return: 1.56 | Eps(step=363965): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8732 | Return: -0.15 | Eps(step=363983): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8733 | Return: 1.49 | Eps(step=363985): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8734 | Return: 0.10 | Eps(step=363993): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8735 | Return: 1.46 | Eps(step=363998): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8736 | Return: 1.64 | Eps(step=364006): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8737 | Return: 1.00 | Eps(step=364007): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8738 | Return: 2.45 | Eps(step=364013): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8739 | Return: 1.12 | Eps(step=364028): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8740 | Return: 3.41 | Eps(step=364038): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8741 | Return: 1.71 | Eps(step=364043): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8742 | Return: 2.45 | Eps(step=364049): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8743 | Return: 2.19 | Eps(step=364056): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8744 | Return: 1.49 | Eps(step=364058): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8745 | Return: 1.73 | Eps(step=364061): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8746 | Return: 1.49 | Eps(step=364063): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8747 | Return: 1.71 | Eps(step=364068): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8748 | Return: 2.13 | Eps(step=364077): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8749 | Return: 1.49 | Eps(step=364079): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8750 | Return: 2.69 | Eps(step=364086): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8751 | Return: 2.13 | Eps(step=364099): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8752 | Return: 1.25 | Eps(step=364100): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8753 | Return: 2.67 | Eps(step=364109): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8754 | Return: 2.69 | Eps(step=364116): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8755 | Return: 3.89 | Eps(step=364128): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8756 | Return: 2.21 | Eps(step=364133): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8757 | Return: 1.25 | Eps(step=364134): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8758 | Return: 1.95 | Eps(step=364140): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8759 | Return: 2.53 | Eps(step=364163): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8760 | Return: 1.47 | Eps(step=364167): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8761 | Return: 2.20 | Eps(step=364173): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8762 | Return: 2.68 | Eps(step=364181): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8763 | Return: 2.12 | Eps(step=364191): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8764 | Return: 2.21 | Eps(step=364196): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8765 | Return: 1.49 | Eps(step=364198): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8766 | Return: 2.21 | Eps(step=364203): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8767 | Return: 2.21 | Eps(step=364208): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8768 | Return: 2.17 | Eps(step=364217): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8769 | Return: 3.17 | Eps(step=364226): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8770 | Return: 1.73 | Eps(step=364229): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8771 | Return: 1.49 | Eps(step=364231): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8772 | Return: 2.67 | Eps(step=364240): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8773 | Return: 1.97 | Eps(step=364244): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8774 | Return: 2.21 | Eps(step=364249): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8775 | Return: 1.00 | Eps(step=364250): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8776 | Return: 1.71 | Eps(step=364255): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8777 | Return: 1.43 | Eps(step=364264): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8778 | Return: 1.40 | Eps(step=364271): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8779 | Return: 1.49 | Eps(step=364273): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8780 | Return: 2.93 | Eps(step=364281): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8781 | Return: 2.45 | Eps(step=364287): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8782 | Return: 2.14 | Eps(step=364295): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8783 | Return: 3.14 | Eps(step=364307): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8784 | Return: 3.17 | Eps(step=364316): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8785 | Return: 1.42 | Eps(step=364321): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8786 | Return: 1.93 | Eps(step=364329): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8787 | Return: 3.17 | Eps(step=364338): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8788 | Return: 2.19 | Eps(step=364345): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8789 | Return: 2.43 | Eps(step=364353): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8790 | Return: 2.19 | Eps(step=364360): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8791 | Return: 1.49 | Eps(step=364362): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8792 | Return: 2.88 | Eps(step=364375): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8793 | Return: 3.15 | Eps(step=364386): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8794 | Return: 1.35 | Eps(step=364402): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8795 | Return: 2.93 | Eps(step=364410): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8796 | Return: 2.43 | Eps(step=364418): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8797 | Return: 3.17 | Eps(step=364427): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8798 | Return: 2.56 | Eps(step=364447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8799 | Return: 2.93 | Eps(step=364455): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8800 | Return: 2.19 | Eps(step=364462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8801 | Return: 2.40 | Eps(step=364474): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8802 | Return: 3.65 | Eps(step=364485): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8803 | Return: 1.97 | Eps(step=364489): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8804 | Return: 1.73 | Eps(step=364492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8805 | Return: 1.97 | Eps(step=364496): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8806 | Return: 1.25 | Eps(step=364497): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8807 | Return: 0.52 | Eps(step=364517): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8808 | Return: 1.44 | Eps(step=364525): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8809 | Return: 2.41 | Eps(step=364535): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8810 | Return: 2.91 | Eps(step=364545): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8811 | Return: 3.15 | Eps(step=364556): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8812 | Return: 3.63 | Eps(step=364569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8813 | Return: 2.45 | Eps(step=364575): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8814 | Return: 2.19 | Eps(step=364582): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8815 | Return: 2.91 | Eps(step=364592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8816 | Return: 2.59 | Eps(step=364609): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8817 | Return: 1.97 | Eps(step=364613): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8818 | Return: 2.45 | Eps(step=364619): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8819 | Return: 0.21 | Eps(step=364626): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8820 | Return: 2.69 | Eps(step=364633): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8821 | Return: 1.49 | Eps(step=364635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8822 | Return: 1.69 | Eps(step=364642): 0.100 | AvgLoss: 0.0003\n",
            "Episode 8823 | Return: 2.45 | Eps(step=364648): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8824 | Return: 2.93 | Eps(step=364656): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8825 | Return: 1.73 | Eps(step=364659): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8826 | Return: 2.21 | Eps(step=364664): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8827 | Return: 3.65 | Eps(step=364675): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8828 | Return: 1.47 | Eps(step=364679): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8829 | Return: 2.19 | Eps(step=364686): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8830 | Return: 2.45 | Eps(step=364692): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8831 | Return: 1.97 | Eps(step=364696): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8832 | Return: 1.00 | Eps(step=364697): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8833 | Return: 2.69 | Eps(step=364704): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8834 | Return: 3.17 | Eps(step=364713): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8835 | Return: 3.41 | Eps(step=364723): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8836 | Return: 3.62 | Eps(step=364737): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8837 | Return: 1.25 | Eps(step=364738): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8838 | Return: 1.97 | Eps(step=364742): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8839 | Return: 2.93 | Eps(step=364750): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8840 | Return: 1.47 | Eps(step=364754): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8841 | Return: 2.21 | Eps(step=364759): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8842 | Return: 2.92 | Eps(step=364768): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8843 | Return: 2.43 | Eps(step=364776): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8844 | Return: 2.45 | Eps(step=364782): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8845 | Return: 2.93 | Eps(step=364790): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8846 | Return: 1.73 | Eps(step=364793): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8847 | Return: 2.89 | Eps(step=364805): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8848 | Return: 3.17 | Eps(step=364814): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8849 | Return: 3.88 | Eps(step=364827): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8850 | Return: 1.97 | Eps(step=364831): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8851 | Return: 3.62 | Eps(step=364845): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8852 | Return: 3.89 | Eps(step=364857): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8853 | Return: 3.17 | Eps(step=364866): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8854 | Return: 2.69 | Eps(step=364873): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8855 | Return: 3.13 | Eps(step=364886): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8856 | Return: 2.21 | Eps(step=364891): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8857 | Return: 2.14 | Eps(step=364904): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8858 | Return: 2.21 | Eps(step=364909): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8859 | Return: 1.25 | Eps(step=364910): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8860 | Return: 1.25 | Eps(step=364911): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8861 | Return: 2.43 | Eps(step=364919): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8862 | Return: 2.37 | Eps(step=364934): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8863 | Return: 1.25 | Eps(step=364935): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8864 | Return: 1.73 | Eps(step=364938): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8865 | Return: 0.96 | Eps(step=364944): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8866 | Return: 1.64 | Eps(step=364952): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8867 | Return: 3.07 | Eps(step=364967): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8868 | Return: 2.69 | Eps(step=364974): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8869 | Return: 3.14 | Eps(step=364986): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8870 | Return: 2.21 | Eps(step=364991): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8871 | Return: 2.45 | Eps(step=364997): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8872 | Return: 2.18 | Eps(step=365055): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8873 | Return: 1.49 | Eps(step=365057): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8874 | Return: 1.72 | Eps(step=365061): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8875 | Return: 3.65 | Eps(step=365072): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8876 | Return: 1.73 | Eps(step=365075): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8877 | Return: 1.28 | Eps(step=365144): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8878 | Return: 2.93 | Eps(step=365152): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8879 | Return: 3.62 | Eps(step=365166): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8880 | Return: 2.21 | Eps(step=365171): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8881 | Return: 1.95 | Eps(step=365177): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8882 | Return: 0.95 | Eps(step=365184): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8883 | Return: 1.95 | Eps(step=365190): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8884 | Return: 1.71 | Eps(step=365216): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8885 | Return: 1.00 | Eps(step=365217): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8886 | Return: 3.05 | Eps(step=365238): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8887 | Return: 1.91 | Eps(step=365249): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8888 | Return: 1.97 | Eps(step=365253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8889 | Return: 3.40 | Eps(step=365264): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8890 | Return: 2.69 | Eps(step=365271): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8891 | Return: 2.17 | Eps(step=365280): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8892 | Return: 2.45 | Eps(step=365286): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8893 | Return: 2.45 | Eps(step=365292): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8894 | Return: 3.65 | Eps(step=365303): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8895 | Return: 1.82 | Eps(step=365322): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8896 | Return: 2.69 | Eps(step=365329): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8897 | Return: 2.44 | Eps(step=365336): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8898 | Return: 1.00 | Eps(step=365337): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8899 | Return: 2.21 | Eps(step=365342): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8900 | Return: 2.69 | Eps(step=365349): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8901 | Return: 2.40 | Eps(step=365361): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8902 | Return: 1.73 | Eps(step=365364): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8903 | Return: 2.21 | Eps(step=365369): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8904 | Return: 1.97 | Eps(step=365373): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8905 | Return: 3.17 | Eps(step=365382): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8906 | Return: 0.97 | Eps(step=365403): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8907 | Return: 3.17 | Eps(step=365412): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8908 | Return: 3.15 | Eps(step=365423): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8909 | Return: -0.40 | Eps(step=365760): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8910 | Return: 1.25 | Eps(step=365761): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8911 | Return: 2.69 | Eps(step=365768): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8912 | Return: 2.88 | Eps(step=365782): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8913 | Return: 1.97 | Eps(step=365786): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8914 | Return: 2.38 | Eps(step=365795): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8915 | Return: 1.72 | Eps(step=365799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8916 | Return: 3.17 | Eps(step=365808): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8917 | Return: 2.45 | Eps(step=365814): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8918 | Return: 0.90 | Eps(step=365851): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8919 | Return: 2.69 | Eps(step=365858): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8920 | Return: 2.14 | Eps(step=365866): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8921 | Return: 3.65 | Eps(step=365877): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8922 | Return: 2.21 | Eps(step=365882): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8923 | Return: 1.69 | Eps(step=365889): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8924 | Return: 2.21 | Eps(step=365894): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8925 | Return: 2.93 | Eps(step=365902): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8926 | Return: 3.41 | Eps(step=365912): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8927 | Return: 3.15 | Eps(step=365923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8928 | Return: -0.05 | Eps(step=365931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8929 | Return: 2.69 | Eps(step=365938): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8930 | Return: 2.45 | Eps(step=365944): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8931 | Return: 2.59 | Eps(step=365957): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8932 | Return: 2.45 | Eps(step=365963): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8933 | Return: 2.45 | Eps(step=365969): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8934 | Return: 2.43 | Eps(step=365977): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8935 | Return: 2.45 | Eps(step=365983): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8936 | Return: 3.14 | Eps(step=366020): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8937 | Return: 2.17 | Eps(step=366029): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8938 | Return: -1.32 | Eps(step=366111): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8939 | Return: 1.25 | Eps(step=366112): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8940 | Return: 3.40 | Eps(step=366148): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8941 | Return: 2.45 | Eps(step=366154): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8942 | Return: 1.00 | Eps(step=366155): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8943 | Return: 2.45 | Eps(step=366161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8944 | Return: 2.68 | Eps(step=366169): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8945 | Return: 2.21 | Eps(step=366174): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8946 | Return: 0.98 | Eps(step=366198): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8947 | Return: 2.20 | Eps(step=366204): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8948 | Return: 2.67 | Eps(step=366213): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8949 | Return: 1.47 | Eps(step=366217): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8950 | Return: 1.97 | Eps(step=366221): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8951 | Return: 1.71 | Eps(step=366226): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8952 | Return: 3.64 | Eps(step=366238): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8953 | Return: 1.71 | Eps(step=366243): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8954 | Return: 2.21 | Eps(step=366248): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8955 | Return: 1.73 | Eps(step=366251): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8956 | Return: 1.49 | Eps(step=366253): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8957 | Return: 2.21 | Eps(step=366258): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8958 | Return: 1.95 | Eps(step=366264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8959 | Return: 1.71 | Eps(step=366269): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8960 | Return: 1.00 | Eps(step=366270): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8961 | Return: 2.69 | Eps(step=366277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8962 | Return: 2.45 | Eps(step=366283): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8963 | Return: 3.10 | Eps(step=366299): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8964 | Return: 3.13 | Eps(step=366312): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8965 | Return: 3.17 | Eps(step=366321): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8966 | Return: 2.69 | Eps(step=366328): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8967 | Return: 2.63 | Eps(step=366366): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8968 | Return: 1.95 | Eps(step=366372): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8969 | Return: 2.93 | Eps(step=366380): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8970 | Return: 2.90 | Eps(step=366391): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8971 | Return: 3.87 | Eps(step=366405): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8972 | Return: 2.45 | Eps(step=366411): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8973 | Return: 3.15 | Eps(step=366422): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8974 | Return: 1.49 | Eps(step=366424): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8975 | Return: 1.58 | Eps(step=366442): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8976 | Return: 3.87 | Eps(step=366456): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8977 | Return: 2.69 | Eps(step=366463): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8978 | Return: 1.49 | Eps(step=366465): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8979 | Return: 3.03 | Eps(step=366488): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8980 | Return: 3.88 | Eps(step=366501): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8981 | Return: 2.41 | Eps(step=366511): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8982 | Return: 2.93 | Eps(step=366519): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8983 | Return: 1.40 | Eps(step=366526): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8984 | Return: 2.56 | Eps(step=366546): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8985 | Return: 1.73 | Eps(step=366549): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8986 | Return: 2.61 | Eps(step=366564): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8987 | Return: 2.21 | Eps(step=366569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8988 | Return: 1.49 | Eps(step=366571): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8989 | Return: 2.21 | Eps(step=366576): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8990 | Return: 1.64 | Eps(step=366584): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8991 | Return: 3.16 | Eps(step=366594): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8992 | Return: 1.97 | Eps(step=366598): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8993 | Return: 2.67 | Eps(step=366607): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8994 | Return: 2.45 | Eps(step=366613): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8995 | Return: 1.71 | Eps(step=366618): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8996 | Return: 1.49 | Eps(step=366620): 0.100 | AvgLoss: 0.0001\n",
            "Episode 8997 | Return: 3.53 | Eps(step=366643): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8998 | Return: 3.39 | Eps(step=366655): 0.100 | AvgLoss: 0.0002\n",
            "Episode 8999 | Return: 2.19 | Eps(step=366662): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9000 | Return: 1.71 | Eps(step=366667): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9001 | Return: 1.47 | Eps(step=366671): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9002 | Return: 2.21 | Eps(step=366676): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9003 | Return: 3.16 | Eps(step=366686): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9004 | Return: 2.93 | Eps(step=366694): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9005 | Return: 2.91 | Eps(step=366704): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9006 | Return: 3.85 | Eps(step=366720): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9007 | Return: 2.93 | Eps(step=366728): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9008 | Return: 2.21 | Eps(step=366733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9009 | Return: 1.97 | Eps(step=366737): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9010 | Return: 1.25 | Eps(step=366738): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9011 | Return: 2.44 | Eps(step=366745): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9012 | Return: 2.19 | Eps(step=366752): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9013 | Return: 3.14 | Eps(step=366764): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9014 | Return: 1.49 | Eps(step=366766): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9015 | Return: 1.97 | Eps(step=366770): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9016 | Return: 2.86 | Eps(step=366781): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9017 | Return: 3.17 | Eps(step=366790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9018 | Return: 1.68 | Eps(step=366799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9019 | Return: 2.21 | Eps(step=366804): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9020 | Return: 1.97 | Eps(step=366808): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9021 | Return: 2.93 | Eps(step=366816): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9022 | Return: 2.93 | Eps(step=366824): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9023 | Return: 0.09 | Eps(step=366838): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9024 | Return: 2.65 | Eps(step=366849): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9025 | Return: 3.62 | Eps(step=366863): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9026 | Return: 1.97 | Eps(step=366867): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9027 | Return: 2.20 | Eps(step=366873): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9028 | Return: 2.58 | Eps(step=366891): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9029 | Return: 2.98 | Eps(step=366919): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9030 | Return: 2.69 | Eps(step=366926): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9031 | Return: 2.69 | Eps(step=366933): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9032 | Return: 2.45 | Eps(step=366939): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9033 | Return: 1.97 | Eps(step=366943): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9034 | Return: 0.94 | Eps(step=366951): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9035 | Return: 2.91 | Eps(step=366961): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9036 | Return: 1.95 | Eps(step=366967): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9037 | Return: 1.97 | Eps(step=366971): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9038 | Return: 1.49 | Eps(step=366973): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9039 | Return: 3.65 | Eps(step=366984): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9040 | Return: 1.73 | Eps(step=366987): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9041 | Return: 3.17 | Eps(step=366996): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9042 | Return: 1.25 | Eps(step=366997): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9043 | Return: 1.73 | Eps(step=367000): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9044 | Return: 1.20 | Eps(step=367007): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9045 | Return: 2.69 | Eps(step=367014): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9046 | Return: 2.18 | Eps(step=367022): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9047 | Return: 3.37 | Eps(step=367036): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9048 | Return: 2.69 | Eps(step=367043): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9049 | Return: 2.19 | Eps(step=367050): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9050 | Return: 1.97 | Eps(step=367054): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9051 | Return: 2.36 | Eps(step=367120): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9052 | Return: 3.65 | Eps(step=367131): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9053 | Return: 1.49 | Eps(step=367133): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9054 | Return: 2.67 | Eps(step=367142): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9055 | Return: 3.35 | Eps(step=367158): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9056 | Return: 2.66 | Eps(step=367168): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9057 | Return: 1.56 | Eps(step=367213): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9058 | Return: 1.97 | Eps(step=367217): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9059 | Return: 1.01 | Eps(step=367268): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9060 | Return: 1.47 | Eps(step=367272): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9061 | Return: 2.91 | Eps(step=367282): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9062 | Return: 2.92 | Eps(step=367291): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9063 | Return: 1.00 | Eps(step=367292): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9064 | Return: 2.69 | Eps(step=367299): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9065 | Return: 2.60 | Eps(step=367365): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9066 | Return: 1.25 | Eps(step=367366): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9067 | Return: 2.67 | Eps(step=367375): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9068 | Return: 2.21 | Eps(step=367380): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9069 | Return: 3.63 | Eps(step=367393): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9070 | Return: 3.62 | Eps(step=367432): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9071 | Return: 3.40 | Eps(step=367443): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9072 | Return: 1.73 | Eps(step=367446): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9073 | Return: 2.45 | Eps(step=367452): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9074 | Return: 1.97 | Eps(step=367456): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9075 | Return: 1.73 | Eps(step=367459): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9076 | Return: 3.65 | Eps(step=367470): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9077 | Return: 0.00 | Eps(step=367472): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9078 | Return: 2.21 | Eps(step=367477): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9079 | Return: 2.93 | Eps(step=367485): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9080 | Return: 2.93 | Eps(step=367493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9081 | Return: -0.55 | Eps(step=367496): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9082 | Return: -0.18 | Eps(step=367508): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9083 | Return: 2.00 | Eps(step=367530): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9084 | Return: 2.93 | Eps(step=367538): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9085 | Return: 1.18 | Eps(step=367663): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9086 | Return: 3.65 | Eps(step=367674): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9087 | Return: 2.93 | Eps(step=367682): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9088 | Return: 2.91 | Eps(step=367692): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9089 | Return: 2.43 | Eps(step=367700): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9090 | Return: 0.44 | Eps(step=367703): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9091 | Return: 1.25 | Eps(step=367704): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9092 | Return: 2.21 | Eps(step=367709): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9093 | Return: -0.25 | Eps(step=367723): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9094 | Return: 3.17 | Eps(step=367732): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9095 | Return: 2.17 | Eps(step=367791): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9096 | Return: 2.93 | Eps(step=367799): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9097 | Return: 1.00 | Eps(step=367800): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9098 | Return: 2.67 | Eps(step=367809): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9099 | Return: 2.89 | Eps(step=367821): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9100 | Return: 2.45 | Eps(step=367827): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9101 | Return: 1.73 | Eps(step=367830): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9102 | Return: 2.45 | Eps(step=367836): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9103 | Return: 1.73 | Eps(step=367839): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9104 | Return: 3.41 | Eps(step=367849): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9105 | Return: 1.25 | Eps(step=367850): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9106 | Return: 2.69 | Eps(step=367857): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9107 | Return: 3.13 | Eps(step=367870): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9108 | Return: 1.00 | Eps(step=367871): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9109 | Return: 2.64 | Eps(step=367883): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9110 | Return: 2.16 | Eps(step=367918): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9111 | Return: 3.01 | Eps(step=367943): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9112 | Return: 2.21 | Eps(step=367948): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9113 | Return: 1.49 | Eps(step=367950): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9114 | Return: 2.67 | Eps(step=367959): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9115 | Return: 2.66 | Eps(step=367969): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9116 | Return: 3.15 | Eps(step=367980): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9117 | Return: 2.12 | Eps(step=367990): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9118 | Return: 3.06 | Eps(step=368010): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9119 | Return: 2.14 | Eps(step=368018): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9120 | Return: 2.93 | Eps(step=368026): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9121 | Return: 2.21 | Eps(step=368031): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9122 | Return: 1.25 | Eps(step=368032): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9123 | Return: 1.73 | Eps(step=368035): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9124 | Return: 2.45 | Eps(step=368041): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9125 | Return: 1.49 | Eps(step=368043): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9126 | Return: 3.33 | Eps(step=368061): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9127 | Return: 3.64 | Eps(step=368073): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9128 | Return: 2.39 | Eps(step=368085): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9129 | Return: 2.67 | Eps(step=368094): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9130 | Return: 1.96 | Eps(step=368099): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9131 | Return: 1.97 | Eps(step=368103): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9132 | Return: 1.89 | Eps(step=368115): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9133 | Return: 2.93 | Eps(step=368123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9134 | Return: 1.73 | Eps(step=368126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9135 | Return: 1.49 | Eps(step=368128): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9136 | Return: 2.87 | Eps(step=368143): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9137 | Return: 3.34 | Eps(step=368160): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9138 | Return: 2.91 | Eps(step=368170): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9139 | Return: 1.00 | Eps(step=368171): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9140 | Return: 1.97 | Eps(step=368175): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9141 | Return: 1.70 | Eps(step=368181): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9142 | Return: 1.73 | Eps(step=368184): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9143 | Return: 1.49 | Eps(step=368186): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9144 | Return: 1.96 | Eps(step=368191): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9145 | Return: 2.19 | Eps(step=368198): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9146 | Return: 0.92 | Eps(step=368203): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9147 | Return: -1.19 | Eps(step=368332): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9148 | Return: 2.69 | Eps(step=368339): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9149 | Return: 1.97 | Eps(step=368343): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9150 | Return: 1.13 | Eps(step=368381): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9151 | Return: 2.45 | Eps(step=368387): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9152 | Return: 2.93 | Eps(step=368395): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9153 | Return: 2.45 | Eps(step=368401): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9154 | Return: 1.73 | Eps(step=368404): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9155 | Return: 1.97 | Eps(step=368408): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9156 | Return: 2.65 | Eps(step=368419): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9157 | Return: 2.93 | Eps(step=368427): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9158 | Return: 2.93 | Eps(step=368435): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9159 | Return: 1.49 | Eps(step=368437): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9160 | Return: 3.17 | Eps(step=368446): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9161 | Return: 1.73 | Eps(step=368449): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9162 | Return: -0.71 | Eps(step=368642): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9163 | Return: 1.47 | Eps(step=368646): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9164 | Return: 2.37 | Eps(step=368660): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9165 | Return: 2.19 | Eps(step=368667): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9166 | Return: 2.21 | Eps(step=368672): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9167 | Return: 1.97 | Eps(step=368676): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9168 | Return: 2.69 | Eps(step=368683): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9169 | Return: 1.58 | Eps(step=368697): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9170 | Return: 3.62 | Eps(step=368711): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9171 | Return: 2.43 | Eps(step=368719): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9172 | Return: 2.69 | Eps(step=368726): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9173 | Return: 3.41 | Eps(step=368736): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9174 | Return: 1.73 | Eps(step=368739): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9175 | Return: 2.02 | Eps(step=368763): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9176 | Return: 1.97 | Eps(step=368767): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9177 | Return: 2.05 | Eps(step=368780): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9178 | Return: 1.25 | Eps(step=368781): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9179 | Return: 3.39 | Eps(step=368793): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9180 | Return: 1.73 | Eps(step=368796): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9181 | Return: 3.15 | Eps(step=368807): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9182 | Return: 3.41 | Eps(step=368817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9183 | Return: 2.85 | Eps(step=368834): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9184 | Return: 1.94 | Eps(step=368841): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9185 | Return: 1.73 | Eps(step=368844): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9186 | Return: 3.65 | Eps(step=368855): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9187 | Return: 3.88 | Eps(step=368868): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9188 | Return: 1.40 | Eps(step=368875): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9189 | Return: 1.73 | Eps(step=368878): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9190 | Return: 2.17 | Eps(step=368887): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9191 | Return: 2.69 | Eps(step=368894): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9192 | Return: 3.17 | Eps(step=368903): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9193 | Return: 2.45 | Eps(step=368909): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9194 | Return: 1.97 | Eps(step=368913): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9195 | Return: 3.17 | Eps(step=368922): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9196 | Return: 2.45 | Eps(step=368928): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9197 | Return: 2.41 | Eps(step=368938): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9198 | Return: 2.21 | Eps(step=368943): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9199 | Return: 2.93 | Eps(step=368951): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9200 | Return: 1.49 | Eps(step=368953): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9201 | Return: 2.90 | Eps(step=368964): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9202 | Return: 2.45 | Eps(step=368970): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9203 | Return: 3.17 | Eps(step=368979): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9204 | Return: 1.97 | Eps(step=368983): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9205 | Return: 0.04 | Eps(step=369027): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9206 | Return: 2.21 | Eps(step=369032): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9207 | Return: 1.25 | Eps(step=369033): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9208 | Return: 0.00 | Eps(step=369035): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9209 | Return: 2.68 | Eps(step=369043): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9210 | Return: 3.65 | Eps(step=369054): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9211 | Return: 2.31 | Eps(step=369074): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9212 | Return: 1.52 | Eps(step=369098): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9213 | Return: 2.65 | Eps(step=369109): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9214 | Return: 1.25 | Eps(step=369110): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9215 | Return: 1.97 | Eps(step=369114): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9216 | Return: 1.23 | Eps(step=369117): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9217 | Return: 1.73 | Eps(step=369120): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9218 | Return: 2.45 | Eps(step=369126): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9219 | Return: 2.21 | Eps(step=369131): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9220 | Return: 0.71 | Eps(step=369137): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9221 | Return: 2.45 | Eps(step=369143): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9222 | Return: 1.49 | Eps(step=369145): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9223 | Return: 1.25 | Eps(step=369146): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9224 | Return: 2.42 | Eps(step=369155): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9225 | Return: 2.91 | Eps(step=369165): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9226 | Return: 2.93 | Eps(step=369173): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9227 | Return: 2.92 | Eps(step=369182): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9228 | Return: 2.45 | Eps(step=369188): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9229 | Return: 1.20 | Eps(step=369195): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9230 | Return: 2.45 | Eps(step=369201): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9231 | Return: 1.97 | Eps(step=369205): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9232 | Return: 3.17 | Eps(step=369214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9233 | Return: 2.21 | Eps(step=369219): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9234 | Return: 1.46 | Eps(step=369224): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9235 | Return: 2.92 | Eps(step=369233): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9236 | Return: 1.97 | Eps(step=369237): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9237 | Return: 2.59 | Eps(step=369254): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9238 | Return: 3.87 | Eps(step=369268): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9239 | Return: 3.65 | Eps(step=369279): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9240 | Return: 1.97 | Eps(step=369283): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9241 | Return: -11.03 | Eps(step=370283): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9242 | Return: -4.56 | Eps(step=370545): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9243 | Return: 1.73 | Eps(step=370548): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9244 | Return: 0.74 | Eps(step=370626): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9245 | Return: 1.73 | Eps(step=370629): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9246 | Return: 2.45 | Eps(step=370635): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9247 | Return: 2.93 | Eps(step=370643): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9248 | Return: 1.73 | Eps(step=370646): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9249 | Return: 3.17 | Eps(step=370655): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9250 | Return: 1.49 | Eps(step=370657): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9251 | Return: 2.37 | Eps(step=370717): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9252 | Return: 1.50 | Eps(step=370739): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9253 | Return: 3.63 | Eps(step=370752): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9254 | Return: 3.65 | Eps(step=370763): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9255 | Return: 1.73 | Eps(step=370766): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9256 | Return: 2.45 | Eps(step=370772): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9257 | Return: 1.00 | Eps(step=370773): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9258 | Return: 1.25 | Eps(step=370774): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9259 | Return: 2.44 | Eps(step=370781): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9260 | Return: 3.17 | Eps(step=370790): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9261 | Return: 2.45 | Eps(step=370796): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9262 | Return: 1.00 | Eps(step=370797): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9263 | Return: 2.41 | Eps(step=370828): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9264 | Return: 2.45 | Eps(step=370834): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9265 | Return: 2.17 | Eps(step=370843): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9266 | Return: 1.73 | Eps(step=370846): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9267 | Return: 1.00 | Eps(step=370847): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9268 | Return: 3.41 | Eps(step=370857): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9269 | Return: 2.69 | Eps(step=370864): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9270 | Return: 2.67 | Eps(step=370873): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9271 | Return: 1.49 | Eps(step=370875): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9272 | Return: 1.49 | Eps(step=370877): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9273 | Return: 2.21 | Eps(step=370882): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9274 | Return: 2.45 | Eps(step=370888): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9275 | Return: 2.21 | Eps(step=370893): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9276 | Return: 1.49 | Eps(step=370895): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9277 | Return: 2.21 | Eps(step=370900): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9278 | Return: 1.25 | Eps(step=370901): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9279 | Return: 1.49 | Eps(step=370903): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9280 | Return: 2.67 | Eps(step=370912): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9281 | Return: 1.73 | Eps(step=370915): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9282 | Return: 2.19 | Eps(step=370922): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9283 | Return: 3.17 | Eps(step=370931): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9284 | Return: 1.67 | Eps(step=370941): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9285 | Return: 1.73 | Eps(step=370944): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9286 | Return: 3.15 | Eps(step=370955): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9287 | Return: 1.73 | Eps(step=370958): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9288 | Return: 2.69 | Eps(step=370965): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9289 | Return: 0.96 | Eps(step=370971): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9290 | Return: 0.96 | Eps(step=370977): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9291 | Return: 1.73 | Eps(step=370980): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9292 | Return: 3.15 | Eps(step=370991): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9293 | Return: 1.97 | Eps(step=370995): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9294 | Return: 1.91 | Eps(step=371005): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9295 | Return: 2.67 | Eps(step=371014): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9296 | Return: 3.40 | Eps(step=371025): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9297 | Return: 2.45 | Eps(step=371031): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9298 | Return: -1.02 | Eps(step=371126): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9299 | Return: 3.17 | Eps(step=371135): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9300 | Return: 3.41 | Eps(step=371145): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9301 | Return: 2.93 | Eps(step=371153): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9302 | Return: 1.97 | Eps(step=371157): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9303 | Return: 2.45 | Eps(step=371163): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9304 | Return: 2.41 | Eps(step=371173): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9305 | Return: 2.93 | Eps(step=371181): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9306 | Return: 3.63 | Eps(step=371194): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9307 | Return: 1.66 | Eps(step=371200): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9308 | Return: 1.73 | Eps(step=371203): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9309 | Return: 3.14 | Eps(step=371215): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9310 | Return: 1.00 | Eps(step=371216): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9311 | Return: 3.17 | Eps(step=371225): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9312 | Return: 2.21 | Eps(step=371230): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9313 | Return: 2.69 | Eps(step=371237): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9314 | Return: 3.17 | Eps(step=371246): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9315 | Return: 1.84 | Eps(step=371259): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9316 | Return: 1.73 | Eps(step=371262): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9317 | Return: 2.43 | Eps(step=371270): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9318 | Return: 1.73 | Eps(step=371273): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9319 | Return: 1.90 | Eps(step=371280): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9320 | Return: 3.63 | Eps(step=371293): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9321 | Return: 2.92 | Eps(step=371302): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9322 | Return: 0.91 | Eps(step=371329): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9323 | Return: 1.94 | Eps(step=371336): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9324 | Return: -0.26 | Eps(step=371415): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9325 | Return: 2.21 | Eps(step=371420): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9326 | Return: 0.72 | Eps(step=371425): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9327 | Return: 1.28 | Eps(step=371449): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9328 | Return: 3.63 | Eps(step=371462): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9329 | Return: 2.41 | Eps(step=371472): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9330 | Return: 1.49 | Eps(step=371474): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9331 | Return: 2.93 | Eps(step=371482): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9332 | Return: 2.41 | Eps(step=371492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9333 | Return: 1.12 | Eps(step=371507): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9334 | Return: 2.75 | Eps(step=371533): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9335 | Return: 3.65 | Eps(step=371544): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9336 | Return: 1.73 | Eps(step=371547): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9337 | Return: 2.69 | Eps(step=371554): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9338 | Return: 2.13 | Eps(step=371567): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9339 | Return: 1.91 | Eps(step=371577): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9340 | Return: 1.97 | Eps(step=371581): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9341 | Return: 2.21 | Eps(step=371586): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9342 | Return: 2.20 | Eps(step=371592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9343 | Return: 2.90 | Eps(step=371603): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9344 | Return: 1.49 | Eps(step=371605): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9345 | Return: 2.45 | Eps(step=371611): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9346 | Return: 3.17 | Eps(step=371620): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9347 | Return: 2.42 | Eps(step=371629): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9348 | Return: 2.21 | Eps(step=371634): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9349 | Return: 3.11 | Eps(step=371649): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9350 | Return: 1.73 | Eps(step=371652): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9351 | Return: 2.69 | Eps(step=371659): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9352 | Return: 1.95 | Eps(step=371665): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9353 | Return: 0.43 | Eps(step=371675): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9354 | Return: 1.97 | Eps(step=371679): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9355 | Return: 2.67 | Eps(step=371688): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9356 | Return: 2.21 | Eps(step=371693): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9357 | Return: 2.93 | Eps(step=371701): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9358 | Return: 2.69 | Eps(step=371708): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9359 | Return: 2.21 | Eps(step=371713): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9360 | Return: 2.60 | Eps(step=371725): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9361 | Return: 3.16 | Eps(step=371735): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9362 | Return: -15.17 | Eps(step=372346): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9363 | Return: 1.49 | Eps(step=372348): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9364 | Return: -0.91 | Eps(step=372513): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9365 | Return: 2.16 | Eps(step=372523): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9366 | Return: 3.41 | Eps(step=372533): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9367 | Return: 2.93 | Eps(step=372541): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9368 | Return: 1.16 | Eps(step=372552): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9369 | Return: 3.39 | Eps(step=372564): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9370 | Return: 1.97 | Eps(step=372568): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9371 | Return: 2.21 | Eps(step=372573): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9372 | Return: 3.14 | Eps(step=372585): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9373 | Return: 1.49 | Eps(step=372587): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9374 | Return: 3.64 | Eps(step=372599): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9375 | Return: 2.79 | Eps(step=372621): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9376 | Return: 2.18 | Eps(step=372629): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9377 | Return: 3.37 | Eps(step=372643): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9378 | Return: 2.67 | Eps(step=372652): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9379 | Return: 2.19 | Eps(step=372659): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9380 | Return: 1.71 | Eps(step=372664): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9381 | Return: 1.97 | Eps(step=372668): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9382 | Return: 2.37 | Eps(step=372682): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9383 | Return: 2.93 | Eps(step=372690): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9384 | Return: 0.99 | Eps(step=372692): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9385 | Return: 1.47 | Eps(step=372696): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9386 | Return: 1.25 | Eps(step=372697): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9387 | Return: 1.49 | Eps(step=372699): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9388 | Return: 1.71 | Eps(step=372704): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9389 | Return: 3.16 | Eps(step=372714): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9390 | Return: 2.21 | Eps(step=372719): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9391 | Return: 2.15 | Eps(step=372776): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9392 | Return: 2.19 | Eps(step=372783): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9393 | Return: 2.69 | Eps(step=372790): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9394 | Return: 2.19 | Eps(step=372797): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9395 | Return: 3.41 | Eps(step=372807): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9396 | Return: 3.41 | Eps(step=372817): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9397 | Return: 2.40 | Eps(step=372828): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9398 | Return: 2.69 | Eps(step=372835): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9399 | Return: 1.73 | Eps(step=372838): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9400 | Return: 2.69 | Eps(step=372845): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9401 | Return: 3.15 | Eps(step=372856): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9402 | Return: 3.38 | Eps(step=372869): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9403 | Return: -12.46 | Eps(step=373869): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9404 | Return: 3.40 | Eps(step=373880): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9405 | Return: 1.49 | Eps(step=373882): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9406 | Return: 2.69 | Eps(step=373889): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9407 | Return: 2.45 | Eps(step=373895): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9408 | Return: 2.45 | Eps(step=373901): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9409 | Return: 2.21 | Eps(step=373906): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9410 | Return: 1.37 | Eps(step=373970): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9411 | Return: 2.32 | Eps(step=374039): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9412 | Return: 1.25 | Eps(step=374040): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9413 | Return: -2.43 | Eps(step=374148): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9414 | Return: 2.41 | Eps(step=374158): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9415 | Return: 3.04 | Eps(step=374205): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9416 | Return: 2.36 | Eps(step=374216): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9417 | Return: 3.40 | Eps(step=374227): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9418 | Return: 2.21 | Eps(step=374232): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9419 | Return: 2.93 | Eps(step=374240): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9420 | Return: 2.69 | Eps(step=374247): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9421 | Return: 2.41 | Eps(step=374257): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9422 | Return: 1.73 | Eps(step=374260): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9423 | Return: 2.45 | Eps(step=374266): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9424 | Return: 1.00 | Eps(step=374267): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9425 | Return: 2.02 | Eps(step=374291): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9426 | Return: 1.95 | Eps(step=374297): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9427 | Return: 1.49 | Eps(step=374299): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9428 | Return: 2.93 | Eps(step=374307): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9429 | Return: 2.43 | Eps(step=374315): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9430 | Return: 2.42 | Eps(step=374324): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9431 | Return: 3.05 | Eps(step=374345): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9432 | Return: 2.69 | Eps(step=374352): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9433 | Return: 2.67 | Eps(step=374361): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9434 | Return: 1.97 | Eps(step=374365): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9435 | Return: 2.45 | Eps(step=374371): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9436 | Return: 2.20 | Eps(step=374377): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9437 | Return: 2.13 | Eps(step=374415): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9438 | Return: 2.68 | Eps(step=374423): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9439 | Return: 3.13 | Eps(step=374436): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9440 | Return: 2.21 | Eps(step=374441): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9441 | Return: 3.17 | Eps(step=374450): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9442 | Return: 2.45 | Eps(step=374456): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9443 | Return: 1.93 | Eps(step=374464): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9444 | Return: 3.89 | Eps(step=374476): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9445 | Return: 1.97 | Eps(step=374480): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9446 | Return: 1.95 | Eps(step=374486): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9447 | Return: 1.25 | Eps(step=374487): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9448 | Return: 2.37 | Eps(step=374501): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9449 | Return: 2.18 | Eps(step=374509): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9450 | Return: -2.69 | Eps(step=374525): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9451 | Return: 1.00 | Eps(step=374526): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9452 | Return: 2.45 | Eps(step=374532): 0.100 | AvgLoss: 0.0020\n",
            "Episode 9453 | Return: 2.92 | Eps(step=374541): 0.100 | AvgLoss: 0.0007\n",
            "Episode 9454 | Return: 2.68 | Eps(step=374574): 0.100 | AvgLoss: 0.0006\n",
            "Episode 9455 | Return: 0.45 | Eps(step=374582): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9456 | Return: 1.00 | Eps(step=374583): 0.100 | AvgLoss: 0.0011\n",
            "Episode 9457 | Return: 1.25 | Eps(step=374584): 0.100 | AvgLoss: 0.0012\n",
            "Episode 9458 | Return: 1.49 | Eps(step=374586): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9459 | Return: 1.39 | Eps(step=374649): 0.100 | AvgLoss: 0.0006\n",
            "Episode 9460 | Return: 1.97 | Eps(step=374653): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9461 | Return: 2.93 | Eps(step=374661): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9462 | Return: 1.95 | Eps(step=374667): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9463 | Return: 2.43 | Eps(step=374675): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9464 | Return: 2.45 | Eps(step=374681): 0.100 | AvgLoss: 0.0006\n",
            "Episode 9465 | Return: 2.65 | Eps(step=374692): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9466 | Return: -2.94 | Eps(step=374777): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9467 | Return: 2.17 | Eps(step=374786): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9468 | Return: 1.97 | Eps(step=374790): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9469 | Return: -7.51 | Eps(step=375041): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9470 | Return: 1.71 | Eps(step=375046): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9471 | Return: 1.39 | Eps(step=375060): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9472 | Return: 2.92 | Eps(step=375069): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9473 | Return: 1.25 | Eps(step=375070): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9474 | Return: 2.07 | Eps(step=375090): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9475 | Return: 1.27 | Eps(step=375114): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9476 | Return: 2.87 | Eps(step=375129): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9477 | Return: 3.15 | Eps(step=375140): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9478 | Return: 2.55 | Eps(step=375161): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9479 | Return: 2.69 | Eps(step=375168): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9480 | Return: 3.17 | Eps(step=375177): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9481 | Return: 3.17 | Eps(step=375186): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9482 | Return: 2.21 | Eps(step=375191): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9483 | Return: 2.86 | Eps(step=375207): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9484 | Return: 1.73 | Eps(step=375210): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9485 | Return: 1.97 | Eps(step=375214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9486 | Return: 2.69 | Eps(step=375221): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9487 | Return: 3.17 | Eps(step=375255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9488 | Return: 3.17 | Eps(step=375264): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9489 | Return: 2.88 | Eps(step=375277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9490 | Return: 3.87 | Eps(step=375291): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9491 | Return: 2.69 | Eps(step=375298): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9492 | Return: 0.60 | Eps(step=375311): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9493 | Return: 2.41 | Eps(step=375321): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9494 | Return: 1.95 | Eps(step=375327): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9495 | Return: 2.45 | Eps(step=375333): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9496 | Return: 2.93 | Eps(step=375341): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9497 | Return: 2.45 | Eps(step=375347): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9498 | Return: 2.54 | Eps(step=375369): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9499 | Return: 2.41 | Eps(step=375379): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9500 | Return: 1.96 | Eps(step=375384): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9501 | Return: 1.73 | Eps(step=375387): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9502 | Return: 1.73 | Eps(step=375390): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9503 | Return: 2.93 | Eps(step=375398): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9504 | Return: 2.93 | Eps(step=375406): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9505 | Return: 2.45 | Eps(step=375412): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9506 | Return: 1.91 | Eps(step=375448): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9507 | Return: 3.89 | Eps(step=375460): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9508 | Return: 1.49 | Eps(step=375462): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9509 | Return: 1.71 | Eps(step=375467): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9510 | Return: 1.49 | Eps(step=375469): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9511 | Return: 2.78 | Eps(step=375492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9512 | Return: 1.97 | Eps(step=375496): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9513 | Return: 3.15 | Eps(step=375507): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9514 | Return: 2.43 | Eps(step=375515): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9515 | Return: 2.17 | Eps(step=375524): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9516 | Return: 2.45 | Eps(step=375530): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9517 | Return: 1.72 | Eps(step=375534): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9518 | Return: 2.13 | Eps(step=375547): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9519 | Return: 3.17 | Eps(step=375556): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9520 | Return: 3.63 | Eps(step=375569): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9521 | Return: 3.03 | Eps(step=375592): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9522 | Return: 3.39 | Eps(step=375604): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9523 | Return: 1.25 | Eps(step=375605): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9524 | Return: 2.93 | Eps(step=375613): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9525 | Return: 2.93 | Eps(step=375621): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9526 | Return: 2.45 | Eps(step=375627): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9527 | Return: 3.17 | Eps(step=375636): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9528 | Return: 3.16 | Eps(step=375646): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9529 | Return: 3.15 | Eps(step=375657): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9530 | Return: 1.95 | Eps(step=375663): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9531 | Return: 3.87 | Eps(step=375677): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9532 | Return: 1.91 | Eps(step=375688): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9533 | Return: 3.41 | Eps(step=375698): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9534 | Return: 2.43 | Eps(step=375706): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9535 | Return: 1.49 | Eps(step=375708): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9536 | Return: 2.45 | Eps(step=375714): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9537 | Return: 2.45 | Eps(step=375720): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9538 | Return: -15.10 | Eps(step=376556): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9539 | Return: 2.41 | Eps(step=376566): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9540 | Return: 2.14 | Eps(step=376579): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9541 | Return: 2.21 | Eps(step=376584): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9542 | Return: 1.20 | Eps(step=376591): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9543 | Return: 2.65 | Eps(step=376602): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9544 | Return: 2.93 | Eps(step=376610): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9545 | Return: 2.14 | Eps(step=376623): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9546 | Return: 2.69 | Eps(step=376630): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9547 | Return: 0.66 | Eps(step=376636): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9548 | Return: 0.90 | Eps(step=376648): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9549 | Return: 2.45 | Eps(step=376654): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9550 | Return: -0.67 | Eps(step=376764): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9551 | Return: 1.73 | Eps(step=376767): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9552 | Return: 2.38 | Eps(step=376781): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9553 | Return: -16.84 | Eps(step=377575): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9554 | Return: -0.71 | Eps(step=377600): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9555 | Return: 2.21 | Eps(step=377605): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9556 | Return: 2.57 | Eps(step=377624): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9557 | Return: -0.68 | Eps(step=377666): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9558 | Return: 2.45 | Eps(step=377672): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9559 | Return: 1.49 | Eps(step=377674): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9560 | Return: 1.92 | Eps(step=377684): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9561 | Return: 3.09 | Eps(step=377701): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9562 | Return: 2.02 | Eps(step=377721): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9563 | Return: 2.55 | Eps(step=377742): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9564 | Return: 1.97 | Eps(step=377746): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9565 | Return: -0.78 | Eps(step=377789): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9566 | Return: 1.77 | Eps(step=377813): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9567 | Return: 2.79 | Eps(step=377835): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9568 | Return: 2.07 | Eps(step=377850): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9569 | Return: 2.60 | Eps(step=377862): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9570 | Return: 1.73 | Eps(step=377865): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9571 | Return: 2.21 | Eps(step=377870): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9572 | Return: 1.71 | Eps(step=377875): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9573 | Return: 2.67 | Eps(step=377884): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9574 | Return: 2.21 | Eps(step=377889): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9575 | Return: 2.45 | Eps(step=377895): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9576 | Return: 1.49 | Eps(step=377897): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9577 | Return: 1.97 | Eps(step=377901): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9578 | Return: 1.97 | Eps(step=377905): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9579 | Return: 2.69 | Eps(step=377912): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9580 | Return: 2.21 | Eps(step=377917): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9581 | Return: 2.79 | Eps(step=377939): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9582 | Return: 1.97 | Eps(step=377943): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9583 | Return: 1.73 | Eps(step=377946): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9584 | Return: 3.61 | Eps(step=377961): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9585 | Return: 1.65 | Eps(step=377989): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9586 | Return: 2.45 | Eps(step=377995): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9587 | Return: 2.90 | Eps(step=378006): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9588 | Return: 2.21 | Eps(step=378011): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9589 | Return: 3.41 | Eps(step=378021): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9590 | Return: 2.18 | Eps(step=378054): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9591 | Return: 2.19 | Eps(step=378061): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9592 | Return: 1.97 | Eps(step=378065): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9593 | Return: 2.69 | Eps(step=378072): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9594 | Return: 2.88 | Eps(step=378085): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9595 | Return: 3.16 | Eps(step=378095): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9596 | Return: 2.21 | Eps(step=378100): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9597 | Return: 0.70 | Eps(step=378127): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9598 | Return: 2.21 | Eps(step=378132): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9599 | Return: 2.19 | Eps(step=378139): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9600 | Return: 1.49 | Eps(step=378162): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9601 | Return: 3.13 | Eps(step=378175): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9602 | Return: 2.21 | Eps(step=378180): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9603 | Return: 1.73 | Eps(step=378183): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9604 | Return: 3.65 | Eps(step=378194): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9605 | Return: 0.07 | Eps(step=378235): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9606 | Return: 2.83 | Eps(step=378253): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9607 | Return: 2.90 | Eps(step=378264): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9608 | Return: 2.03 | Eps(step=378279): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9609 | Return: 1.97 | Eps(step=378283): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9610 | Return: 3.39 | Eps(step=378295): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9611 | Return: 2.61 | Eps(step=378310): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9612 | Return: 1.25 | Eps(step=378311): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9613 | Return: 1.93 | Eps(step=378319): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9614 | Return: 1.46 | Eps(step=378350): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9615 | Return: 1.00 | Eps(step=378351): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9616 | Return: 1.97 | Eps(step=378355): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9617 | Return: 3.17 | Eps(step=378364): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9618 | Return: 2.69 | Eps(step=378371): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9619 | Return: 2.69 | Eps(step=378378): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9620 | Return: 1.97 | Eps(step=378382): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9621 | Return: 0.99 | Eps(step=378384): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9622 | Return: 2.93 | Eps(step=378392): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9623 | Return: 2.21 | Eps(step=378397): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9624 | Return: 2.60 | Eps(step=378409): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9625 | Return: 2.93 | Eps(step=378417): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9626 | Return: 2.69 | Eps(step=378424): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9627 | Return: 2.36 | Eps(step=378440): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9628 | Return: 2.69 | Eps(step=378447): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9629 | Return: 1.29 | Eps(step=378544): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9630 | Return: 3.41 | Eps(step=378554): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9631 | Return: 3.17 | Eps(step=378563): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9632 | Return: 1.71 | Eps(step=378568): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9633 | Return: 1.25 | Eps(step=378569): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9634 | Return: 1.71 | Eps(step=378574): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9635 | Return: 1.73 | Eps(step=378577): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9636 | Return: 2.45 | Eps(step=378583): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9637 | Return: 0.99 | Eps(step=378585): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9638 | Return: 2.45 | Eps(step=378591): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9639 | Return: 2.93 | Eps(step=378599): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9640 | Return: 0.68 | Eps(step=378609): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9641 | Return: 1.69 | Eps(step=378616): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9642 | Return: 3.89 | Eps(step=378628): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9643 | Return: 2.44 | Eps(step=378635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9644 | Return: 0.99 | Eps(step=378637): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9645 | Return: 2.63 | Eps(step=378651): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9646 | Return: 1.67 | Eps(step=378660): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9647 | Return: 1.87 | Eps(step=378670): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9648 | Return: 3.16 | Eps(step=378680): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9649 | Return: 3.17 | Eps(step=378689): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9650 | Return: 2.67 | Eps(step=378698): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9651 | Return: 1.25 | Eps(step=378699): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9652 | Return: 2.16 | Eps(step=378710): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9653 | Return: 1.74 | Eps(step=378737): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9654 | Return: 2.44 | Eps(step=378744): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9655 | Return: 1.73 | Eps(step=378747): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9656 | Return: 2.67 | Eps(step=378756): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9657 | Return: 1.97 | Eps(step=378760): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9658 | Return: 2.69 | Eps(step=378767): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9659 | Return: 3.13 | Eps(step=378780): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9660 | Return: 1.47 | Eps(step=378784): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9661 | Return: 2.21 | Eps(step=378789): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9662 | Return: 3.40 | Eps(step=378800): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9663 | Return: 2.45 | Eps(step=378806): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9664 | Return: 1.97 | Eps(step=378810): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9665 | Return: 1.40 | Eps(step=378817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9666 | Return: 2.19 | Eps(step=378824): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9667 | Return: 3.41 | Eps(step=378834): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9668 | Return: 1.72 | Eps(step=378838): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9669 | Return: -22.96 | Eps(step=379838): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9670 | Return: -11.26 | Eps(step=380385): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9671 | Return: 2.45 | Eps(step=380391): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9672 | Return: 2.79 | Eps(step=380413): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9673 | Return: 1.57 | Eps(step=380433): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9674 | Return: 0.33 | Eps(step=380651): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9675 | Return: 1.49 | Eps(step=380653): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9676 | Return: 2.41 | Eps(step=380663): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9677 | Return: 2.30 | Eps(step=380680): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9678 | Return: 3.15 | Eps(step=380691): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9679 | Return: 2.21 | Eps(step=380696): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9680 | Return: 1.00 | Eps(step=380697): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9681 | Return: 1.53 | Eps(step=380720): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9682 | Return: 2.91 | Eps(step=380730): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9683 | Return: 1.73 | Eps(step=380733): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9684 | Return: 1.97 | Eps(step=380737): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9685 | Return: 2.62 | Eps(step=380751): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9686 | Return: 3.64 | Eps(step=380763): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9687 | Return: 2.41 | Eps(step=380773): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9688 | Return: 1.59 | Eps(step=380792): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9689 | Return: 2.67 | Eps(step=380801): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9690 | Return: 2.69 | Eps(step=380808): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9691 | Return: 1.97 | Eps(step=380812): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9692 | Return: -8.90 | Eps(step=381181): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9693 | Return: 1.68 | Eps(step=381190): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9694 | Return: 1.97 | Eps(step=381194): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9695 | Return: 1.00 | Eps(step=381195): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9696 | Return: 2.92 | Eps(step=381204): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9697 | Return: 2.19 | Eps(step=381211): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9698 | Return: 1.97 | Eps(step=381215): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9699 | Return: 2.15 | Eps(step=381226): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9700 | Return: 2.45 | Eps(step=381232): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9701 | Return: 3.09 | Eps(step=381249): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9702 | Return: 2.91 | Eps(step=381259): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9703 | Return: 1.25 | Eps(step=381260): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9704 | Return: 1.00 | Eps(step=381261): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9705 | Return: 2.41 | Eps(step=381271): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9706 | Return: 2.45 | Eps(step=381277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9707 | Return: 3.09 | Eps(step=381294): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9708 | Return: 2.93 | Eps(step=381302): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9709 | Return: 2.17 | Eps(step=381311): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9710 | Return: 2.19 | Eps(step=381318): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9711 | Return: 1.95 | Eps(step=381324): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9712 | Return: 1.73 | Eps(step=381327): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9713 | Return: 2.45 | Eps(step=381333): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9714 | Return: 3.16 | Eps(step=381343): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9715 | Return: 2.17 | Eps(step=381352): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9716 | Return: 2.65 | Eps(step=381363): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9717 | Return: 1.71 | Eps(step=381368): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9718 | Return: 2.21 | Eps(step=381373): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9719 | Return: 2.20 | Eps(step=381379): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9720 | Return: 1.97 | Eps(step=381383): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9721 | Return: 3.89 | Eps(step=381395): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9722 | Return: 2.09 | Eps(step=381412): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9723 | Return: 2.69 | Eps(step=381419): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9724 | Return: 1.47 | Eps(step=381423): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9725 | Return: 2.20 | Eps(step=381429): 0.100 | AvgLoss: 0.0005\n",
            "Episode 9726 | Return: -2.39 | Eps(step=381543): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9727 | Return: -0.89 | Eps(step=381601): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9728 | Return: 2.12 | Eps(step=381611): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9729 | Return: 3.17 | Eps(step=381620): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9730 | Return: 1.97 | Eps(step=381624): 0.100 | AvgLoss: 0.0004\n",
            "Episode 9731 | Return: 1.97 | Eps(step=381628): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9732 | Return: 1.25 | Eps(step=381629): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9733 | Return: 2.93 | Eps(step=381637): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9734 | Return: 2.91 | Eps(step=381647): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9735 | Return: 2.93 | Eps(step=381655): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9736 | Return: 3.41 | Eps(step=381665): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9737 | Return: 3.17 | Eps(step=381674): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9738 | Return: 3.17 | Eps(step=381683): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9739 | Return: 2.45 | Eps(step=381689): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9740 | Return: 3.40 | Eps(step=381700): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9741 | Return: 2.93 | Eps(step=381708): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9742 | Return: 2.21 | Eps(step=381713): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9743 | Return: 1.84 | Eps(step=381726): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9744 | Return: 2.45 | Eps(step=381732): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9745 | Return: 3.89 | Eps(step=381744): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9746 | Return: 1.73 | Eps(step=381747): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9747 | Return: 1.97 | Eps(step=381751): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9748 | Return: 2.69 | Eps(step=381758): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9749 | Return: 3.17 | Eps(step=381767): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9750 | Return: 2.47 | Eps(step=381797): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9751 | Return: 2.19 | Eps(step=381804): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9752 | Return: 2.84 | Eps(step=381821): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9753 | Return: 3.49 | Eps(step=381848): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9754 | Return: 3.39 | Eps(step=381860): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9755 | Return: 1.95 | Eps(step=381866): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9756 | Return: 3.65 | Eps(step=381877): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9757 | Return: 1.40 | Eps(step=381884): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9758 | Return: 1.30 | Eps(step=381905): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9759 | Return: 3.63 | Eps(step=381918): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9760 | Return: 2.68 | Eps(step=381926): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9761 | Return: 2.45 | Eps(step=381932): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9762 | Return: 0.96 | Eps(step=381938): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9763 | Return: 2.69 | Eps(step=381945): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9764 | Return: 1.97 | Eps(step=381949): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9765 | Return: 2.45 | Eps(step=381955): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9766 | Return: 2.33 | Eps(step=381973): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9767 | Return: 1.25 | Eps(step=381974): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9768 | Return: 3.39 | Eps(step=381986): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9769 | Return: 3.41 | Eps(step=381996): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9770 | Return: 1.95 | Eps(step=382002): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9771 | Return: 2.19 | Eps(step=382009): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9772 | Return: 2.45 | Eps(step=382015): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9773 | Return: 2.67 | Eps(step=382024): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9774 | Return: 2.67 | Eps(step=382033): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9775 | Return: 2.45 | Eps(step=382039): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9776 | Return: 3.15 | Eps(step=382050): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9777 | Return: 2.92 | Eps(step=382059): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9778 | Return: 0.90 | Eps(step=382066): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9779 | Return: 1.49 | Eps(step=382068): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9780 | Return: 2.69 | Eps(step=382075): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9781 | Return: 2.69 | Eps(step=382082): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9782 | Return: 2.45 | Eps(step=382088): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9783 | Return: 3.17 | Eps(step=382097): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9784 | Return: 3.88 | Eps(step=382110): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9785 | Return: 2.19 | Eps(step=382117): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9786 | Return: 2.45 | Eps(step=382123): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9787 | Return: 2.18 | Eps(step=382131): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9788 | Return: 1.97 | Eps(step=382135): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9789 | Return: 3.56 | Eps(step=382155): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9790 | Return: 3.17 | Eps(step=382164): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9791 | Return: 2.19 | Eps(step=382171): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9792 | Return: 1.42 | Eps(step=382181): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9793 | Return: 3.14 | Eps(step=382193): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9794 | Return: 2.69 | Eps(step=382200): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9795 | Return: 2.67 | Eps(step=382209): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9796 | Return: 2.21 | Eps(step=382214): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9797 | Return: 1.73 | Eps(step=382217): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9798 | Return: 2.19 | Eps(step=382224): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9799 | Return: 1.97 | Eps(step=382228): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9800 | Return: 1.73 | Eps(step=382231): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9801 | Return: 1.92 | Eps(step=382240): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9802 | Return: 3.16 | Eps(step=382250): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9803 | Return: 1.95 | Eps(step=382256): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9804 | Return: 2.92 | Eps(step=382265): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9805 | Return: 1.55 | Eps(step=382286): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9806 | Return: 2.69 | Eps(step=382293): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9807 | Return: 1.49 | Eps(step=382295): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9808 | Return: 2.21 | Eps(step=382300): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9809 | Return: 2.43 | Eps(step=382308): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9810 | Return: 3.14 | Eps(step=382320): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9811 | Return: 2.20 | Eps(step=382326): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9812 | Return: 2.20 | Eps(step=382332): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9813 | Return: 2.41 | Eps(step=382342): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9814 | Return: 2.19 | Eps(step=382349): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9815 | Return: 2.45 | Eps(step=382355): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9816 | Return: 1.49 | Eps(step=382357): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9817 | Return: 1.97 | Eps(step=382361): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9818 | Return: 2.45 | Eps(step=382367): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9819 | Return: 2.93 | Eps(step=382375): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9820 | Return: 1.61 | Eps(step=382387): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9821 | Return: 2.69 | Eps(step=382394): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9822 | Return: 1.97 | Eps(step=382398): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9823 | Return: 2.02 | Eps(step=382422): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9824 | Return: 2.93 | Eps(step=382430): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9825 | Return: 2.21 | Eps(step=382435): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9826 | Return: 3.16 | Eps(step=382445): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9827 | Return: 2.69 | Eps(step=382452): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9828 | Return: 2.21 | Eps(step=382457): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9829 | Return: 3.85 | Eps(step=382473): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9830 | Return: 1.97 | Eps(step=382477): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9831 | Return: 0.27 | Eps(step=382493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9832 | Return: 1.96 | Eps(step=382498): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9833 | Return: 2.18 | Eps(step=382506): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9834 | Return: 2.92 | Eps(step=382515): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9835 | Return: 0.25 | Eps(step=382533): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9836 | Return: 1.47 | Eps(step=382537): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9837 | Return: 2.69 | Eps(step=382544): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9838 | Return: 1.73 | Eps(step=382547): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9839 | Return: 2.64 | Eps(step=382559): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9840 | Return: 3.17 | Eps(step=382568): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9841 | Return: 2.45 | Eps(step=382574): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9842 | Return: 2.43 | Eps(step=382582): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9843 | Return: 1.25 | Eps(step=382583): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9844 | Return: 2.21 | Eps(step=382588): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9845 | Return: 2.12 | Eps(step=382598): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9846 | Return: 2.91 | Eps(step=382608): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9847 | Return: 2.08 | Eps(step=382627): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9848 | Return: 2.68 | Eps(step=382635): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9849 | Return: 2.45 | Eps(step=382641): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9850 | Return: 1.94 | Eps(step=382648): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9851 | Return: 3.40 | Eps(step=382659): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9852 | Return: 1.49 | Eps(step=382661): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9853 | Return: 2.67 | Eps(step=382670): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9854 | Return: 2.21 | Eps(step=382675): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9855 | Return: 2.69 | Eps(step=382682): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9856 | Return: 2.18 | Eps(step=382690): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9857 | Return: 2.93 | Eps(step=382698): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9858 | Return: 2.69 | Eps(step=382705): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9859 | Return: 3.17 | Eps(step=382714): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9860 | Return: 1.35 | Eps(step=382726): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9861 | Return: 1.49 | Eps(step=382728): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9862 | Return: 1.90 | Eps(step=382735): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9863 | Return: 1.95 | Eps(step=382741): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9864 | Return: 2.45 | Eps(step=382747): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9865 | Return: 3.15 | Eps(step=382758): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9866 | Return: 2.45 | Eps(step=382764): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9867 | Return: 2.21 | Eps(step=382769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9868 | Return: 3.65 | Eps(step=382780): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9869 | Return: 2.28 | Eps(step=382803): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9870 | Return: 2.45 | Eps(step=382809): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9871 | Return: 1.97 | Eps(step=382813): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9872 | Return: 2.45 | Eps(step=382819): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9873 | Return: 2.69 | Eps(step=382826): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9874 | Return: 2.21 | Eps(step=382831): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9875 | Return: 1.71 | Eps(step=382836): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9876 | Return: 3.17 | Eps(step=382845): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9877 | Return: 2.21 | Eps(step=382850): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9878 | Return: 2.43 | Eps(step=382858): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9879 | Return: 1.47 | Eps(step=382862): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9880 | Return: -0.11 | Eps(step=382896): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9881 | Return: -1.73 | Eps(step=383391): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9882 | Return: 3.31 | Eps(step=383411): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9883 | Return: -13.15 | Eps(step=384411): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9884 | Return: 2.77 | Eps(step=384435): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9885 | Return: 2.97 | Eps(step=384464): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9886 | Return: 2.11 | Eps(step=384479): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9887 | Return: 1.14 | Eps(step=384541): 0.100 | AvgLoss: 0.0000\n",
            "Episode 9888 | Return: 2.40 | Eps(step=384627): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9889 | Return: 2.16 | Eps(step=384638): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9890 | Return: 2.16 | Eps(step=384648): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9891 | Return: 1.49 | Eps(step=384650): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9892 | Return: 1.97 | Eps(step=384654): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9893 | Return: 3.57 | Eps(step=384673): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9894 | Return: 2.20 | Eps(step=384679): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9895 | Return: 1.19 | Eps(step=384687): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9896 | Return: 1.97 | Eps(step=384691): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9897 | Return: 2.45 | Eps(step=384743): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9898 | Return: 2.12 | Eps(step=384753): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9899 | Return: 1.85 | Eps(step=384769): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9900 | Return: 1.97 | Eps(step=384773): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9901 | Return: 1.71 | Eps(step=384778): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9902 | Return: -0.42 | Eps(step=384799): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9903 | Return: 2.44 | Eps(step=384806): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9904 | Return: 3.09 | Eps(step=384823): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9905 | Return: 1.00 | Eps(step=384824): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9906 | Return: 0.88 | Eps(step=384858): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9907 | Return: 1.00 | Eps(step=384859): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9908 | Return: 2.67 | Eps(step=384868): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9909 | Return: 1.25 | Eps(step=384869): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9910 | Return: 3.17 | Eps(step=384878): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9911 | Return: 2.16 | Eps(step=384888): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9912 | Return: 1.95 | Eps(step=384894): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9913 | Return: 2.68 | Eps(step=384902): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9914 | Return: 2.17 | Eps(step=384911): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9915 | Return: 2.21 | Eps(step=384916): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9916 | Return: 2.69 | Eps(step=384923): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9917 | Return: 0.69 | Eps(step=384926): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9918 | Return: 1.49 | Eps(step=384928): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9919 | Return: 3.39 | Eps(step=384940): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9920 | Return: 1.78 | Eps(step=384955): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9921 | Return: 2.93 | Eps(step=384963): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9922 | Return: 2.65 | Eps(step=384974): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9923 | Return: 2.64 | Eps(step=384986): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9924 | Return: 2.09 | Eps(step=385028): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9925 | Return: 1.73 | Eps(step=385031): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9926 | Return: 2.45 | Eps(step=385037): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9927 | Return: 1.97 | Eps(step=385041): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9928 | Return: 2.93 | Eps(step=385049): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9929 | Return: 2.47 | Eps(step=385078): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9930 | Return: 3.17 | Eps(step=385087): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9931 | Return: 1.25 | Eps(step=385088): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9932 | Return: 2.93 | Eps(step=385096): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9933 | Return: 1.73 | Eps(step=385099): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9934 | Return: 1.00 | Eps(step=385100): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9935 | Return: 3.88 | Eps(step=385113): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9936 | Return: 1.00 | Eps(step=385114): 0.100 | AvgLoss: 0.0001\n",
            "Episode 9937 | Return: 3.17 | Eps(step=385123): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9938 | Return: 2.45 | Eps(step=385129): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9939 | Return: 3.85 | Eps(step=385145): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9940 | Return: 3.13 | Eps(step=385158): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9941 | Return: 3.63 | Eps(step=385171): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9942 | Return: 3.65 | Eps(step=385182): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9943 | Return: 3.65 | Eps(step=385193): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9944 | Return: 2.67 | Eps(step=385202): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9945 | Return: 2.69 | Eps(step=385209): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9946 | Return: 1.49 | Eps(step=385211): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9947 | Return: 2.21 | Eps(step=385216): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9948 | Return: 3.64 | Eps(step=385228): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9949 | Return: 1.25 | Eps(step=385229): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9950 | Return: 2.10 | Eps(step=385241): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9951 | Return: 1.14 | Eps(step=385249): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9952 | Return: 1.73 | Eps(step=385252): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9953 | Return: 1.73 | Eps(step=385255): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9954 | Return: 2.45 | Eps(step=385261): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9955 | Return: 1.49 | Eps(step=385263): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9956 | Return: 2.19 | Eps(step=385270): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9957 | Return: 2.19 | Eps(step=385277): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9958 | Return: 1.64 | Eps(step=385285): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9959 | Return: 3.88 | Eps(step=385298): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9960 | Return: 2.19 | Eps(step=385305): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9961 | Return: 2.43 | Eps(step=385313): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9962 | Return: 2.45 | Eps(step=385319): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9963 | Return: 2.79 | Eps(step=385337): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9964 | Return: 1.12 | Eps(step=385352): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9965 | Return: 1.84 | Eps(step=385369): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9966 | Return: 2.69 | Eps(step=385376): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9967 | Return: 2.61 | Eps(step=385391): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9968 | Return: 0.94 | Eps(step=385419): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9969 | Return: 2.67 | Eps(step=385428): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9970 | Return: 2.93 | Eps(step=385436): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9971 | Return: -0.42 | Eps(step=385476): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9972 | Return: 3.17 | Eps(step=385485): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9973 | Return: 2.69 | Eps(step=385492): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9974 | Return: 1.25 | Eps(step=385493): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9975 | Return: 2.45 | Eps(step=385499): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9976 | Return: 2.40 | Eps(step=385531): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9977 | Return: 2.21 | Eps(step=385536): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9978 | Return: 1.73 | Eps(step=385539): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9979 | Return: 2.68 | Eps(step=385547): 0.100 | AvgLoss: 0.0003\n",
            "Episode 9980 | Return: 0.59 | Eps(step=385640): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9981 | Return: 2.69 | Eps(step=385647): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9982 | Return: 2.17 | Eps(step=385656): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9983 | Return: 2.66 | Eps(step=385666): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9984 | Return: 2.69 | Eps(step=385673): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9985 | Return: 2.62 | Eps(step=385683): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9986 | Return: 2.21 | Eps(step=385688): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9987 | Return: 1.49 | Eps(step=385690): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9988 | Return: 1.97 | Eps(step=385694): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9989 | Return: 1.72 | Eps(step=385769): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9990 | Return: 0.96 | Eps(step=385775): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9991 | Return: 1.90 | Eps(step=385782): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9992 | Return: 1.95 | Eps(step=385788): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9993 | Return: 2.20 | Eps(step=385794): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9994 | Return: 2.93 | Eps(step=385802): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9995 | Return: 2.21 | Eps(step=385807): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9996 | Return: 3.41 | Eps(step=385817): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9997 | Return: 2.93 | Eps(step=385825): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9998 | Return: 1.73 | Eps(step=385828): 0.100 | AvgLoss: 0.0002\n",
            "Episode 9999 | Return: 1.49 | Eps(step=385830): 0.100 | AvgLoss: 0.0002\n",
            "[np.float64(-231.0799999999996), np.float64(-1.46), np.float64(2.19), np.float64(2.6799999999999997), np.float64(2.5999999999999996), np.float64(3.17), np.float64(2.45), np.float64(1.97), np.float64(3.6500000000000004), np.float64(1.18), np.float64(2.69), np.float64(1.6199999999999999), np.float64(2.21), np.float64(3.8900000000000006), np.float64(1.97), np.float64(1.7), np.float64(1.23), np.float64(1.25), np.float64(0.99), np.float64(1.1499999999999997), np.float64(1.67), np.float64(1.0), np.float64(2.12), np.float64(2.17), np.float64(2.66), np.float64(1.25), np.float64(1.47), np.float64(2.45), np.float64(3.07), np.float64(1.94), np.float64(2.21), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.0), np.float64(1.73), np.float64(3.8900000000000006), np.float64(1.92), np.float64(3.4), np.float64(1.0), np.float64(2.6399999999999997), np.float64(2.15), np.float64(2.16), np.float64(1.4), np.float64(1.97), np.float64(1.73), np.float64(2.69), np.float64(0.94), np.float64(1.71), np.float64(2.12), np.float64(2.8), np.float64(3.41), np.float64(2.21), np.float64(1.95), np.float64(2.21), np.float64(2.45), np.float64(-3.1699999999999804), np.float64(1.7699999999999998), np.float64(3.6500000000000004), np.float64(3.17), np.float64(2.45), np.float64(2.17), np.float64(2.9), np.float64(3.6500000000000004), np.float64(0.96), np.float64(2.69), np.float64(2.45), np.float64(2.21), np.float64(2.12), np.float64(3.0199999999999996), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.21), np.float64(1.0), np.float64(2.9), np.float64(2.21), np.float64(0.43999999999999995), np.float64(1.25), np.float64(2.21), np.float64(3.16), np.float64(2.67), np.float64(1.97), np.float64(2.45), np.float64(3.17), np.float64(1.25), np.float64(2.21), np.float64(2.69), np.float64(2.04), np.float64(1.72), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.73), np.float64(1.97), np.float64(1.23), np.float64(0.9499999999999997), np.float64(3.6500000000000004), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.11), np.float64(1.16), np.float64(2.21), np.float64(1.91), np.float64(3.1), np.float64(1.5199999999999998), np.float64(1.42), np.float64(2.05), np.float64(2.69), np.float64(2.69), np.float64(1.97), np.float64(3.41), np.float64(1.8499999999999996), np.float64(-0.41000000000000014), np.float64(1.97), np.float64(1.31), np.float64(1.49), np.float64(1.47), np.float64(-0.919999999999999), np.float64(3.1399999999999997), np.float64(1.6299999999999994), np.float64(1.2099999999999997), np.float64(2.15), np.float64(2.8200000000000003), np.float64(-3.7199999999999855), np.float64(-0.8399999999999954), np.float64(2.88), np.float64(-21.270000000000415), np.float64(-19.85000000000031), np.float64(2.9699999999999998), np.float64(-21.710000000000417), np.float64(-15.009999999999945), np.float64(-29.720000000000336), np.float64(-29.47000000000041), np.float64(2.459999999999999), np.float64(-11.769999999999882), np.float64(-23.280000000000314), np.float64(1.9099999999999997), np.float64(-10.229999999999936), np.float64(-19.47000000000012), np.float64(1.8499999999999999), np.float64(-22.24000000000031), np.float64(-0.6099999999999992), np.float64(-2.79999999999999), np.float64(-23.360000000000188), np.float64(-7.259999999999929), np.float64(-31.650000000000766), np.float64(-0.5200000000000002), np.float64(-2.139999999999989), np.float64(-0.5400000000000007), np.float64(-23.000000000000504), np.float64(-16.319999999999844), np.float64(-10.289999999999832), np.float64(-27.22000000000085), np.float64(1.2599999999999998), np.float64(-22.01000000000043), np.float64(-15.689999999999811), np.float64(-13.209999999999816), np.float64(1.44), np.float64(-13.58999999999983), np.float64(-20.310000000000255), np.float64(1.0), np.float64(1.6199999999999999), np.float64(-0.32000000000000095), np.float64(-15.539999999999829), np.float64(-21.60000000000026), np.float64(-3.4999999999999796), np.float64(-7.689999999999973), np.float64(-12.279999999999816), np.float64(-1.9399999999999586), np.float64(-8.999999999999885), np.float64(-35.340000000000565), np.float64(-18.08000000000013), np.float64(-19.970000000000066), np.float64(-17.26000000000002), np.float64(1.0), np.float64(-22.790000000000383), np.float64(-3.8999999999999906), np.float64(-32.49000000000015), np.float64(0.6899999999999984), np.float64(-3.579999999999984), np.float64(0.7699999999999994), np.float64(-8.52999999999996), np.float64(-1.4899999999999922), np.float64(-26.290000000000187), np.float64(-14.059999999999802), np.float64(-18.1600000000001), np.float64(-24.010000000000236), np.float64(-16.51999999999995), np.float64(-1.0700000000000003), np.float64(-53.41999999999953), np.float64(-1.4999999999999742), np.float64(-0.4300000000000008), np.float64(-24.660000000000355), np.float64(-5.139999999999978), np.float64(-27.480000000000526), np.float64(-1.2699999999999987), np.float64(-0.599999999999999), np.float64(-20.460000000000274), np.float64(-10.059999999999869), np.float64(-6.00999999999996), np.float64(-0.8299999999999992), np.float64(-18.90999999999996), np.float64(-28.780000000000435), np.float64(-37.719999999999956), np.float64(-1.6499999999999595), np.float64(-3.6399999999999793), np.float64(-2.1599999999999833), np.float64(-16.230000000000054), np.float64(-14.749999999999973), np.float64(-25.720000000000162), np.float64(1.9999999999999998), np.float64(1.1599999999999993), np.float64(2.1399999999999997), np.float64(2.34), np.float64(-1.2699999999999942), np.float64(-32.51000000000054), np.float64(3.5700000000000003), np.float64(2.4299999999999997), np.float64(3.05), np.float64(1.8499999999999999), np.float64(1.49), np.float64(3.4499999999999993), np.float64(1.4999999999999996), np.float64(2.9299999999999997), np.float64(1.4599999999999997), np.float64(-4.0399999999999805), np.float64(2.59), np.float64(0.23999999999999977), np.float64(1.97), np.float64(2.67), np.float64(1.3199999999999996), np.float64(1.0), np.float64(-23.730000000000658), np.float64(2.75), np.float64(0.08999999999999941), np.float64(0.7999999999999996), np.float64(1.7299999999999995), np.float64(3.6500000000000004), np.float64(1.97), np.float64(2.28), np.float64(2.67), np.float64(1.73), np.float64(1.1399999999999997), np.float64(-5.64999999999997), np.float64(-2.7199999999999855), np.float64(2.1099999999999994), np.float64(2.0799999999999996), np.float64(1.97), np.float64(0.6299999999999994), np.float64(-3.229999999999974), np.float64(3.59), np.float64(1.66), np.float64(2.69), np.float64(2.5999999999999996), np.float64(3.42), np.float64(2.6199999999999997), np.float64(1.4499999999999984), np.float64(3.1999999999999997), np.float64(-0.15000000000000013), np.float64(0.629999999999999), np.float64(2.9699999999999998), np.float64(1.0699999999999994), np.float64(1.48), np.float64(1.89), np.float64(2.9899999999999998), np.float64(1.49), np.float64(2.1799999999999997), np.float64(2.9299999999999997), np.float64(3.15), np.float64(3.2399999999999998), np.float64(3.41), np.float64(2.4), np.float64(1.73), np.float64(2.4699999999999998), np.float64(3.58), np.float64(3.41), np.float64(3.4), np.float64(1.97), np.float64(3.15), np.float64(1.1899999999999993), np.float64(1.95), np.float64(0.9099999999999999), np.float64(0.4399999999999997), np.float64(1.5699999999999998), np.float64(1.97), np.float64(2.67), np.float64(1.5699999999999996), np.float64(1.97), np.float64(2.6799999999999997), np.float64(1.25), np.float64(2.9299999999999997), np.float64(1.97), np.float64(-0.9799999999999969), np.float64(1.65), np.float64(1.97), np.float64(3.17), np.float64(-5.259999999999929), np.float64(2.19), np.float64(3.17), np.float64(0.5899999999999999), np.float64(1.439999999999999), np.float64(3.880000000000001), np.float64(1.8899999999999997), np.float64(1.9899999999999998), np.float64(2.91), np.float64(1.73), np.float64(1.49), np.float64(2.21), np.float64(3.5300000000000002), np.float64(0.07000000000000073), np.float64(2.45), np.float64(1.49), np.float64(-4.079999999999977), np.float64(1.71), np.float64(2.69), np.float64(3.41), np.float64(2.5599999999999996), np.float64(1.97), np.float64(2.92), np.float64(1.3299999999999994), np.float64(3.6500000000000004), np.float64(2.2), np.float64(1.0), np.float64(1.97), np.float64(0.99), np.float64(1.49), np.float64(-17.720000000000045), np.float64(2.759999999999999), np.float64(0.0), np.float64(1.73), np.float64(1.49), np.float64(1.8399999999999999), np.float64(0.0), np.float64(2.58), np.float64(2.45), np.float64(3.63), np.float64(1.25), np.float64(1.73), np.float64(-0.010000000000001563), np.float64(3.0199999999999996), np.float64(1.88), np.float64(3.6500000000000004), np.float64(1.73), np.float64(1.1499999999999995), np.float64(3.39), np.float64(1.1099999999999999), np.float64(2.63), np.float64(1.19), np.float64(2.42), np.float64(2.41), np.float64(3.41), np.float64(2.2), np.float64(2.91), np.float64(2.69), np.float64(2.1999999999999993), np.float64(1.73), np.float64(2.67), np.float64(1.8299999999999998), np.float64(0.5599999999999998), np.float64(-36.22999999999997), np.float64(2.92), np.float64(1.0299999999999998), np.float64(1.8199999999999998), np.float64(1.9499999999999993), np.float64(1.48), np.float64(2.7699999999999996), np.float64(-3.109999999999987), np.float64(-2.919999999999992), np.float64(1.5799999999999998), np.float64(1.73), np.float64(2.1399999999999997), np.float64(1.71), np.float64(1.25), np.float64(0.8699999999999997), np.float64(2.7699999999999996), np.float64(1.97), np.float64(1.2199999999999995), np.float64(2.69), np.float64(2.21), np.float64(-0.4899999999999989), np.float64(2.9499999999999993), np.float64(2.2299999999999995), np.float64(2.1999999999999997), np.float64(1.47), np.float64(0.6099999999999997), np.float64(2.6399999999999997), np.float64(2.17), np.float64(1.25), np.float64(-0.6999999999999968), np.float64(0.33999999999999897), np.float64(1.97), np.float64(-1.21), np.float64(0.5699999999999996), np.float64(1.1199999999999999), np.float64(2.4299999999999997), np.float64(2.15), np.float64(-15.499999999999968), np.float64(2.9299999999999997), np.float64(0.2900000000000007), np.float64(2.38), np.float64(1.42), np.float64(2.21), np.float64(1.0), np.float64(1.25), np.float64(3.5300000000000002), np.float64(3.4899999999999998), np.float64(1.0), np.float64(3.41), np.float64(2.9299999999999997), np.float64(1.49), np.float64(1.2), np.float64(3.4699999999999998), np.float64(1.49), np.float64(1.71), np.float64(3.0299999999999994), np.float64(2.21), np.float64(-12.019999999999902), np.float64(-2.079999999999991), np.float64(2.12), np.float64(0.72), np.float64(-0.7899999999999983), np.float64(2.87), np.float64(3.63), np.float64(1.9799999999999995), np.float64(1.4899999999999995), np.float64(1.45), np.float64(-6.43999999999996), np.float64(3.19), np.float64(2.1799999999999997), np.float64(1.5799999999999994), np.float64(2.6399999999999997), np.float64(2.2199999999999998), np.float64(2.69), np.float64(2.0199999999999996), np.float64(1.3099999999999996), np.float64(2.6399999999999997), np.float64(1.25), np.float64(1.23), np.float64(3.16), np.float64(2.45), np.float64(1.49), np.float64(0.49999999999999956), np.float64(2.69), np.float64(3.4499999999999997), np.float64(2.9299999999999997), np.float64(3.37), np.float64(2.19), np.float64(3.13), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.19), np.float64(2.9299999999999997), np.float64(3.3899999999999997), np.float64(1.73), np.float64(2.62), np.float64(1.73), np.float64(2.69), np.float64(3.11), np.float64(-6.399999999999986), np.float64(2.45), np.float64(1.49), np.float64(2.69), np.float64(2.45), np.float64(3.16), np.float64(1.73), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.8999999999999995), np.float64(3.66), np.float64(1.8499999999999999), np.float64(2.67), np.float64(-18.770000000000028), np.float64(2.1799999999999997), np.float64(1.5199999999999994), np.float64(1.0), np.float64(0.8399999999999992), np.float64(1.5799999999999998), np.float64(1.73), np.float64(1.3699999999999994), np.float64(2.84), np.float64(1.27), np.float64(1.47), np.float64(2.45), np.float64(1.2199999999999998), np.float64(2.86), np.float64(1.47), np.float64(1.49), np.float64(3.1499999999999995), np.float64(0.7499999999999991), np.float64(-0.6199999999999799), np.float64(1.95), np.float64(2.3899999999999997), np.float64(2.16), np.float64(1.49), np.float64(1.88), np.float64(1.97), np.float64(2.3499999999999996), np.float64(3.1399999999999997), np.float64(1.44), np.float64(3.41), np.float64(1.4699999999999995), np.float64(1.25), np.float64(1.6899999999999997), np.float64(1.25), np.float64(2.38), np.float64(1.49), np.float64(2.17), np.float64(2.9299999999999997), np.float64(3.41), np.float64(2.0599999999999996), np.float64(1.96), np.float64(3.32), np.float64(1.14), np.float64(3.3899999999999997), np.float64(1.4999999999999998), np.float64(3.17), np.float64(3.37), np.float64(3.17), np.float64(2.2), np.float64(2.8099999999999996), np.float64(2.26), np.float64(1.3299999999999994), np.float64(2.83), np.float64(2.9299999999999997), np.float64(2.84), np.float64(2.21), np.float64(1.73), np.float64(2.4699999999999998), np.float64(2.69), np.float64(3.17), np.float64(1.95), np.float64(1.5099999999999998), np.float64(3.3899999999999997), np.float64(2.7299999999999995), np.float64(3.87), np.float64(1.73), np.float64(1.49), np.float64(3.3899999999999997), np.float64(2.6799999999999997), np.float64(1.1699999999999997), np.float64(1.0799999999999998), np.float64(2.21), np.float64(2.6799999999999997), np.float64(1.97), np.float64(1.68), np.float64(2.36), np.float64(2.21), np.float64(1.49), np.float64(0.7099999999999993), np.float64(3.17), np.float64(-0.30000000000000027), np.float64(1.97), np.float64(1.25), np.float64(2.12), np.float64(2.45), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.25), np.float64(0.09999999999999987), np.float64(2.12), np.float64(3.62), np.float64(3.15), np.float64(1.73), np.float64(1.39), np.float64(3.0599999999999996), np.float64(2.96), np.float64(2.45), np.float64(1.43), np.float64(3.41), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.6799999999999997), np.float64(1.97), np.float64(1.71), np.float64(2.67), np.float64(1.97), np.float64(2.19), np.float64(0.94), np.float64(2.42), np.float64(1.73), np.float64(1.15), np.float64(0.25999999999999956), np.float64(1.69), np.float64(2.69), np.float64(2.42), np.float64(1.73), np.float64(3.6500000000000004), np.float64(2.08), np.float64(2.45), np.float64(0.9699999999999995), np.float64(1.6099999999999999), np.float64(-0.38000000000000034), np.float64(2.9299999999999997), np.float64(1.4499999999999993), np.float64(3.0599999999999996), np.float64(1.25), np.float64(3.41), np.float64(2.91), np.float64(2.1999999999999997), np.float64(2.01), np.float64(2.3), np.float64(2.9299999999999997), np.float64(2.41), np.float64(1.25), np.float64(2.289999999999999), np.float64(1.49), np.float64(3.63), np.float64(1.0), np.float64(2.82), np.float64(3.17), np.float64(3.63), np.float64(1.97), np.float64(2.59), np.float64(2.69), np.float64(2.19), np.float64(1.97), np.float64(2.21), np.float64(3.0999999999999996), np.float64(2.45), np.float64(3.87), np.float64(1.73), np.float64(2.69), np.float64(1.71), np.float64(2.12), np.float64(2.4299999999999997), np.float64(-0.2799999999999998), np.float64(2.8099999999999996), np.float64(3.6400000000000006), np.float64(1.49), np.float64(1.73), np.float64(1.7899999999999998), np.float64(3.870000000000001), np.float64(0.7099999999999995), np.float64(-0.2000000000000004), np.float64(2.29), np.float64(3.8100000000000005), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.88), np.float64(2.21), np.float64(3.29), np.float64(2.9899999999999993), np.float64(-1.0899999999999963), np.float64(3.37), np.float64(-0.499999999999996), np.float64(1.71), np.float64(1.25), np.float64(2.63), np.float64(2.21), np.float64(1.25), np.float64(1.0499999999999996), np.float64(1.49), np.float64(2.65), np.float64(2.1399999999999997), np.float64(2.4299999999999997), np.float64(2.61), np.float64(1.47), np.float64(1.6799999999999995), np.float64(2.69), np.float64(2.21), np.float64(2.19), np.float64(2.86), np.float64(1.73), np.float64(2.7299999999999995), np.float64(1.0499999999999994), np.float64(1.96), np.float64(3.8500000000000005), np.float64(3.09), np.float64(0.8999999999999999), np.float64(0.5199999999999998), np.float64(1.25), np.float64(3.17), np.float64(2.87), np.float64(1.25), np.float64(1.25), np.float64(2.91), np.float64(1.73), np.float64(2.41), np.float64(1.73), np.float64(1.9699999999999998), np.float64(1.95), np.float64(1.97), np.float64(3.34), np.float64(1.7), np.float64(1.73), np.float64(2.9299999999999997), np.float64(1.47), np.float64(1.6199999999999999), np.float64(2.19), np.float64(2.65), np.float64(2.2), np.float64(2.6399999999999997), np.float64(1.73), np.float64(2.41), np.float64(2.67), np.float64(3.15), np.float64(1.97), np.float64(2.5999999999999996), np.float64(3.8900000000000006), np.float64(3.17), np.float64(1.68), np.float64(3.62), np.float64(1.5599999999999996), np.float64(2.1399999999999997), np.float64(1.38), np.float64(1.17), np.float64(2.63), np.float64(-1.8099999999999996), np.float64(2.69), np.float64(2.86), np.float64(3.17), np.float64(2.67), np.float64(1.25), np.float64(1.4899999999999998), np.float64(3.3499999999999996), np.float64(1.49), np.float64(1.97), np.float64(1.49), np.float64(0.1299999999999999), np.float64(2.5699999999999994), np.float64(0.5199999999999994), np.float64(-2.9499999999999877), np.float64(1.6899999999999997), np.float64(-17.47000000000018), np.float64(-1.829999999999985), np.float64(3.1099999999999994), np.float64(1.25), np.float64(0.09999999999999964), np.float64(2.19), np.float64(1.25), np.float64(-26.330000000000357), np.float64(2.67), np.float64(2.4099999999999997), np.float64(-3.459999999999976), np.float64(-1.7399999999999913), np.float64(1.65), np.float64(1.25), np.float64(3.13), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.21), np.float64(2.21), np.float64(2.45), np.float64(1.95), np.float64(1.9499999999999997), np.float64(1.73), np.float64(1.0), np.float64(1.49), np.float64(2.69), np.float64(1.73), np.float64(1.97), np.float64(1.25), np.float64(2.19), np.float64(1.25), np.float64(2.45), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.12), np.float64(2.12), np.float64(2.17), np.float64(2.3999999999999995), np.float64(1.73), np.float64(1.8899999999999997), np.float64(2.1799999999999997), np.float64(1.25), np.float64(2.69), np.float64(2.9299999999999997), np.float64(2.2699999999999996), np.float64(2.19), np.float64(2.2199999999999998), np.float64(2.1799999999999997), np.float64(2.6799999999999997), np.float64(3.6500000000000004), np.float64(2.9299999999999997), np.float64(0.94), np.float64(2.4299999999999997), np.float64(1.25), np.float64(0.10000000000000142), np.float64(2.91), np.float64(1.25), np.float64(2.4299999999999997), np.float64(3.6500000000000004), np.float64(2.4299999999999997), np.float64(1.7699999999999996), np.float64(2.67), np.float64(2.6799999999999997), np.float64(0.13999999999999946), np.float64(0.9899999999999998), np.float64(3.6500000000000004), np.float64(2.57), np.float64(3.17), np.float64(1.92), np.float64(3.13), np.float64(1.25), np.float64(2.4), np.float64(2.62), np.float64(1.49), np.float64(2.45), np.float64(2.3899999999999997), np.float64(2.66), np.float64(3.4), np.float64(2.45), np.float64(3.17), np.float64(1.8599999999999997), np.float64(1.49), np.float64(3.37), np.float64(3.15), np.float64(2.57), np.float64(1.0), np.float64(1.73), np.float64(1.95), np.float64(3.87), np.float64(2.9299999999999997), np.float64(3.15), np.float64(2.45), np.float64(1.25), np.float64(-0.48), np.float64(2.41), np.float64(1.95), np.float64(2.3499999999999996), np.float64(1.47), np.float64(1.73), np.float64(3.63), np.float64(1.49), np.float64(2.459999999999999), np.float64(1.95), np.float64(2.4), np.float64(1.49), np.float64(2.8), np.float64(1.8999999999999995), np.float64(2.45), np.float64(2.45), np.float64(2.16), np.float64(2.25), np.float64(1.97), np.float64(2.21), np.float64(1.42), np.float64(1.4), np.float64(2.45), np.float64(1.97), np.float64(1.95), np.float64(0.99), np.float64(2.3099999999999996), np.float64(2.21), np.float64(2.65), np.float64(2.3899999999999997), np.float64(2.34), np.float64(1.66), np.float64(2.67), np.float64(1.96), np.float64(2.88), np.float64(1.9199999999999997), np.float64(3.3499999999999996), np.float64(1.25), np.float64(3.17), np.float64(2.1799999999999997), np.float64(1.95), np.float64(2.4299999999999997), np.float64(1.2899999999999998), np.float64(2.61), np.float64(2.21), np.float64(1.71), np.float64(2.9299999999999997), np.float64(2.65), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.0), np.float64(1.97), np.float64(3.620000000000001), np.float64(-4.229999999999992), np.float64(0.0), np.float64(2.9299999999999997), np.float64(-20.619999999999976), np.float64(1.73), np.float64(1.8499999999999999), np.float64(-26.13000000000076), np.float64(3.570000000000001), np.float64(2.2399999999999998), np.float64(2.21), np.float64(-0.4500000000000013), np.float64(2.34), np.float64(1.73), np.float64(1.47), np.float64(1.6799999999999997), np.float64(1.65), np.float64(1.97), np.float64(2.1899999999999995), np.float64(2.8099999999999996), np.float64(1.97), np.float64(2.4), np.float64(1.71), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.9199999999999995), np.float64(3.17), np.float64(2.4299999999999997), np.float64(2.2799999999999994), np.float64(1.73), np.float64(2.3899999999999997), np.float64(1.23), np.float64(2.45), np.float64(2.69), np.float64(3.8900000000000006), np.float64(2.66), np.float64(3.17), np.float64(3.17), np.float64(2.67), np.float64(3.09), np.float64(2.92), np.float64(2.91), np.float64(-18.64000000000004), np.float64(-0.05000000000000049), np.float64(1.5099999999999998), np.float64(2.8099999999999996), np.float64(0.7999999999999996), np.float64(2.42), np.float64(2.17), np.float64(1.25), np.float64(2.03), np.float64(0.9299999999999997), np.float64(1.73), np.float64(3.17), np.float64(3.6500000000000004), np.float64(1.3399999999999996), np.float64(1.7599999999999996), np.float64(1.25), np.float64(2.65), np.float64(2.67), np.float64(3.0999999999999996), np.float64(2.16), np.float64(-6.669999999999982), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.63), np.float64(-0.11000000000000076), np.float64(1.95), np.float64(3.41), np.float64(2.37), np.float64(2.45), np.float64(1.25), np.float64(3.41), np.float64(3.1399999999999997), np.float64(2.4899999999999998), np.float64(2.9299999999999997), np.float64(2.1399999999999997), np.float64(3.6500000000000004), np.float64(2.21), np.float64(3.17), np.float64(1.47), np.float64(3.09), np.float64(2.41), np.float64(1.95), np.float64(2.41), np.float64(1.97), np.float64(1.8799999999999997), np.float64(2.45), np.float64(2.61), np.float64(1.2799999999999998), np.float64(1.0), np.float64(1.2799999999999998), np.float64(1.73), np.float64(1.73), np.float64(1.95), np.float64(2.32), np.float64(3.07), np.float64(2.34), np.float64(3.87), np.float64(2.8899999999999997), np.float64(2.3900000000000006), np.float64(1.25), np.float64(1.97), np.float64(1.72), np.float64(0.5699999999999992), np.float64(1.0), np.float64(0.6799999999999993), np.float64(1.25), np.float64(1.7399999999999998), np.float64(1.73), np.float64(1.62), np.float64(1.2899999999999998), np.float64(3.17), np.float64(2.69), np.float64(1.95), np.float64(2.57), np.float64(2.67), np.float64(2.45), np.float64(2.21), np.float64(2.21), np.float64(2.63), np.float64(2.3099999999999996), np.float64(1.95), np.float64(1.91), np.float64(2.1799999999999997), np.float64(2.45), np.float64(2.69), np.float64(-1.7799999999999923), np.float64(3.41), np.float64(1.0), np.float64(2.69), np.float64(1.49), np.float64(2.21), np.float64(1.2199999999999998), np.float64(2.21), np.float64(1.97), np.float64(2.45), np.float64(2.1799999999999997), np.float64(2.4299999999999997), np.float64(2.11), np.float64(2.69), np.float64(1.73), np.float64(1.95), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.44), np.float64(3.3899999999999997), np.float64(2.9299999999999997), np.float64(2.6799999999999997), np.float64(0.7), np.float64(2.37), np.float64(2.6799999999999997), np.float64(3.17), np.float64(2.4299999999999997), np.float64(1.49), np.float64(2.67), np.float64(1.95), np.float64(1.49), np.float64(2.69), np.float64(2.45), np.float64(1.25), np.float64(3.13), np.float64(1.0), np.float64(2.67), np.float64(1.449999999999999), np.float64(-0.72), np.float64(2.9299999999999997), np.float64(-6.979999999999931), np.float64(1.97), np.float64(3.39), np.float64(1.25), np.float64(1.0399999999999998), np.float64(2.45), np.float64(1.97), np.float64(2.45), np.float64(1.97), np.float64(2.21), np.float64(1.95), np.float64(2.67), np.float64(1.47), np.float64(1.95), np.float64(2.69), np.float64(3.4000000000000004), np.float64(1.25), np.float64(1.97), np.float64(2.6799999999999997), np.float64(1.73), np.float64(3.8500000000000005), np.float64(3.17), np.float64(2.69), np.float64(1.49), np.float64(1.97), np.float64(-0.33000000000000007), np.float64(3.63), np.float64(2.9299999999999997), np.float64(2.19), np.float64(2.69), np.float64(1.0399999999999998), np.float64(3.6400000000000006), np.float64(2.42), np.float64(2.1799999999999997), np.float64(1.7699999999999998), np.float64(2.17), np.float64(3.17), np.float64(1.49), np.float64(1.49), np.float64(2.4299999999999997), np.float64(2.61), np.float64(0.48), np.float64(2.44), np.float64(2.69), np.float64(2.8600000000000003), np.float64(2.21), np.float64(2.69), np.float64(2.9), np.float64(1.3299999999999996), np.float64(2.79), np.float64(1.25), np.float64(1.6699999999999997), np.float64(0.6699999999999999), np.float64(2.21), np.float64(2.21), np.float64(2.21), np.float64(1.73), np.float64(1.23), np.float64(2.4), np.float64(2.8099999999999996), np.float64(1.49), np.float64(1.72), np.float64(3.41), np.float64(3.41), np.float64(1.24), np.float64(0.8699999999999999), np.float64(1.97), np.float64(2.21), np.float64(2.45), np.float64(1.73), np.float64(2.21), np.float64(2.4299999999999997), np.float64(3.12), np.float64(1.17), np.float64(1.73), np.float64(2.69), np.float64(2.9699999999999998), np.float64(2.9), np.float64(1.5699999999999998), np.float64(1.44), np.float64(1.7399999999999993), np.float64(1.66), np.float64(2.21), np.float64(2.21), np.float64(1.73), np.float64(1.49), np.float64(1.96), np.float64(1.49), np.float64(1.0499999999999996), np.float64(3.38), np.float64(2.2), np.float64(2.41), np.float64(2.1799999999999997), np.float64(1.7799999999999998), np.float64(2.3499999999999996), np.float64(2.69), np.float64(2.8499999999999996), np.float64(-0.379999999999991), np.float64(2.45), np.float64(1.43), np.float64(1.5799999999999998), np.float64(1.49), np.float64(2.2), np.float64(-0.6900000000000008), np.float64(2.9299999999999997), np.float64(2.1399999999999997), np.float64(2.9299999999999997), np.float64(2.92), np.float64(2.41), np.float64(1.47), np.float64(1.2), np.float64(2.17), np.float64(1.49), np.float64(1.25), np.float64(1.8399999999999999), np.float64(2.21), np.float64(1.0), np.float64(1.2), np.float64(2.69), np.float64(2.37), np.float64(3.11), np.float64(2.21), np.float64(3.41), np.float64(3.15), np.float64(2.16), np.float64(1.73), np.float64(3.17), np.float64(1.49), np.float64(1.49), np.float64(2.21), np.float64(1.49), np.float64(2.4299999999999997), np.float64(1.93), np.float64(3.17), np.float64(-5.089999999999965), np.float64(3.79), np.float64(2.69), np.float64(2.45), np.float64(2.63), np.float64(2.91), np.float64(1.97), np.float64(0.6099999999999998), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.0), np.float64(1.97), np.float64(2.42), np.float64(2.3899999999999997), np.float64(1.73), np.float64(1.71), np.float64(2.44), np.float64(1.2), np.float64(2.21), np.float64(2.44), np.float64(2.38), np.float64(2.41), np.float64(2.8899999999999997), np.float64(1.97), np.float64(2.19), np.float64(1.0), np.float64(1.49), np.float64(1.97), np.float64(1.88), np.float64(2.2), np.float64(2.84), np.float64(2.45), np.float64(2.4299999999999997), np.float64(1.16), np.float64(2.4299999999999997), np.float64(3.6399999999999997), np.float64(3.36), np.float64(2.45), np.float64(1.39), np.float64(1.6299999999999997), np.float64(3.37), np.float64(1.41), np.float64(2.9299999999999997), np.float64(2.69), np.float64(3.1899999999999995), np.float64(2.69), np.float64(-1.3999999999999968), np.float64(2.8799999999999994), np.float64(2.9299999999999997), np.float64(2.67), np.float64(2.21), np.float64(1.73), np.float64(-10.879999999999956), np.float64(1.770000000000003), np.float64(2.57), np.float64(2.21), np.float64(1.0), np.float64(3.3499999999999996), np.float64(2.4499999999999997), np.float64(1.13), np.float64(2.45), np.float64(0.7199999999999991), np.float64(3.3899999999999997), np.float64(2.9299999999999997), np.float64(1.0999999999999999), np.float64(2.19), np.float64(1.73), np.float64(2.9299999999999997), np.float64(3.8600000000000003), np.float64(3.62), np.float64(2.45), np.float64(2.42), np.float64(2.17), np.float64(0.72), np.float64(2.21), np.float64(3.41), np.float64(2.9299999999999997), np.float64(2.59), np.float64(2.21), np.float64(1.25), np.float64(1.47), np.float64(2.19), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.91), np.float64(1.91), np.float64(2.67), np.float64(2.9299999999999997), np.float64(3.63), np.float64(-1.9799999999999827), np.float64(1.47), np.float64(1.9), np.float64(2.69), np.float64(1.64), np.float64(1.97), np.float64(1.97), np.float64(3.6500000000000004), np.float64(2.19), np.float64(1.49), np.float64(2.11), np.float64(3.4), np.float64(-0.030000000000000693), np.float64(2.45), np.float64(3.6500000000000004), np.float64(1.65), np.float64(2.3599999999999994), np.float64(-9.84999999999994), np.float64(2.8099999999999996), np.float64(3.39), np.float64(2.38), np.float64(2.67), np.float64(-18.650000000000087), np.float64(1.97), np.float64(1.73), np.float64(2.69), np.float64(3.05), np.float64(1.49), np.float64(3.440000000000001), np.float64(1.73), np.float64(1.49), np.float64(3.8900000000000006), np.float64(2.2199999999999998), np.float64(2.4499999999999997), np.float64(1.97), np.float64(1.49), np.float64(2.21), np.float64(2.67), np.float64(2.6399999999999997), np.float64(1.49), np.float64(2.69), np.float64(1.42), np.float64(1.25), np.float64(2.1399999999999997), np.float64(1.97), np.float64(-0.3800000000000001), np.float64(1.25), np.float64(1.0), np.float64(3.41), np.float64(3.17), np.float64(1.73), np.float64(2.86), np.float64(3.6500000000000004), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.72), np.float64(2.17), np.float64(-1.1599999999999815), np.float64(3.6399999999999997), np.float64(2.8499999999999996), np.float64(1.25), np.float64(1.49), np.float64(1.71), np.float64(1.7800000000000011), np.float64(1.25), np.float64(2.9099999999999993), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.04), np.float64(1.4899999999999998), np.float64(3.15), np.float64(1.25), np.float64(2.17), np.float64(1.73), np.float64(1.97), np.float64(1.18), np.float64(2.45), np.float64(3.34), np.float64(3.34), np.float64(3.41), np.float64(2.6899999999999995), np.float64(2.82), np.float64(1.97), np.float64(2.8999999999999995), np.float64(3.17), np.float64(3.3899999999999997), np.float64(-1.9000000000000004), np.float64(2.03), np.float64(3.17), np.float64(2.15), np.float64(2.6799999999999997), np.float64(2.67), np.float64(2.19), np.float64(1.73), np.float64(2.8499999999999996), np.float64(1.4399999999999995), np.float64(2.19), np.float64(3.6500000000000004), np.float64(2.91), np.float64(2.63), np.float64(2.29), np.float64(2.19), np.float64(1.97), np.float64(2.21), np.float64(2.05), np.float64(3.6500000000000004), np.float64(2.17), np.float64(0.9199999999999999), np.float64(2.45), np.float64(1.04), np.float64(2.21), np.float64(3.17), np.float64(2.69), np.float64(2.66), np.float64(2.21), np.float64(2.91), np.float64(1.6199999999999997), np.float64(1.88), np.float64(2.3599999999999994), np.float64(1.94), np.float64(2.45), np.float64(3.17), np.float64(2.71), np.float64(1.64), np.float64(2.67), np.float64(0.41999999999999904), np.float64(1.73), np.float64(-0.1100000000000001), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.3299999999999996), np.float64(2.0199999999999996), np.float64(3.2399999999999998), np.float64(1.4699999999999998), np.float64(2.91), np.float64(2.69), np.float64(1.49), np.float64(3.17), np.float64(0.95), np.float64(-0.5500000000000003), np.float64(1.73), np.float64(0.45999999999999996), np.float64(2.87), np.float64(1.73), np.float64(3.15), np.float64(1.0), np.float64(2.67), np.float64(-13.009999999999875), np.float64(0.7299999999999994), np.float64(1.71), np.float64(2.6899999999999995), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.91), np.float64(1.5999999999999996), np.float64(1.49), np.float64(-5.509999999999957), np.float64(3.580000000000001), np.float64(2.09), np.float64(1.8299999999999996), np.float64(1.0499999999999992), np.float64(3.4699999999999998), np.float64(3.17), np.float64(1.2), np.float64(2.5999999999999996), np.float64(2.21), np.float64(3.6099999999999994), np.float64(1.25), np.float64(1.73), np.float64(-2.539999999999985), np.float64(2.67), np.float64(2.67), np.float64(1.8599999999999999), np.float64(0.94), np.float64(1.49), np.float64(0.20999999999999974), np.float64(0.4599999999999993), np.float64(0.6099999999999999), np.float64(1.49), np.float64(1.73), np.float64(1.43), np.float64(2.45), np.float64(3.1799999999999997), np.float64(1.8899999999999997), np.float64(1.25), np.float64(1.9), np.float64(0.6999999999999993), np.float64(2.69), np.float64(1.45), np.float64(1.25), np.float64(3.4), np.float64(2.36), np.float64(2.41), np.float64(2.4299999999999997), np.float64(1.2899999999999996), np.float64(1.15), np.float64(3.62), np.float64(1.97), np.float64(2.21), np.float64(2.92), np.float64(1.72), np.float64(2.15), np.float64(2.6799999999999997), np.float64(2.69), np.float64(1.16), np.float64(2.62), np.float64(1.66), np.float64(3.17), np.float64(2.67), np.float64(1.52), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.67), np.float64(1.49), np.float64(2.66), np.float64(1.0599999999999998), np.float64(2.4299999999999997), np.float64(2.8299999999999996), np.float64(1.97), np.float64(2.91), np.float64(2.17), np.float64(2.21), np.float64(2.69), np.float64(2.4), np.float64(2.45), np.float64(1.3699999999999999), np.float64(2.17), np.float64(1.25), np.float64(1.97), np.float64(0.72), np.float64(2.2), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.41), np.float64(1.73), np.float64(2.6799999999999997), np.float64(2.45), np.float64(2.69), np.float64(2.9), np.float64(1.73), np.float64(1.97), np.float64(2.6799999999999997), np.float64(2.21), np.float64(3.37), np.float64(1.71), np.float64(1.43), np.float64(2.91), np.float64(2.9299999999999997), np.float64(1.95), np.float64(1.66), np.float64(1.93), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.69), np.float64(2.17), np.float64(1.64), np.float64(2.62), np.float64(2.4299999999999997), np.float64(2.69), np.float64(2.38), np.float64(1.1499999999999995), np.float64(3.4), np.float64(2.67), np.float64(1.73), np.float64(2.21), np.float64(1.25), np.float64(1.95), np.float64(1.95), np.float64(1.41), np.float64(2.21), np.float64(3.26), np.float64(1.97), np.float64(1.96), np.float64(3.17), np.float64(2.21), np.float64(1.97), np.float64(2.69), np.float64(1.49), np.float64(1.97), np.float64(1.14), np.float64(2.13), np.float64(1.25), np.float64(1.97), np.float64(1.25), np.float64(2.45), np.float64(3.17), np.float64(1.49), np.float64(2.32), np.float64(3.88), np.float64(2.8499999999999996), np.float64(2.9299999999999997), np.float64(3.15), np.float64(2.9299999999999997), np.float64(2.03), np.float64(3.87), np.float64(2.38), np.float64(2.1099999999999994), np.float64(0.6499999999999999), np.float64(1.49), np.float64(2.21), np.float64(2.67), np.float64(2.69), np.float64(3.37), np.float64(2.6799999999999997), np.float64(2.4299999999999997), np.float64(1.97), np.float64(3.41), np.float64(1.49), np.float64(2.0599999999999996), np.float64(2.41), np.float64(2.2), np.float64(2.21), np.float64(2.61), np.float64(1.0), np.float64(2.21), np.float64(2.21), np.float64(2.45), np.float64(1.49), np.float64(2.45), np.float64(1.8699999999999999), np.float64(-0.10000000000000009), np.float64(2.4), np.float64(1.73), np.float64(2.45), np.float64(2.42), np.float64(2.2699999999999996), np.float64(3.3899999999999997), np.float64(2.5199999999999996), np.float64(2.45), np.float64(2.2), np.float64(0.5099999999999998), np.float64(0.8199999999999996), np.float64(3.17), np.float64(0.96), np.float64(2.1399999999999997), np.float64(3.1399999999999997), np.float64(2.33), np.float64(2.9), np.float64(1.44), np.float64(2.69), np.float64(2.21), np.float64(2.69), np.float64(1.48), np.float64(2.67), np.float64(1.0), np.float64(1.2199999999999998), np.float64(2.45), np.float64(1.97), np.float64(2.4299999999999997), np.float64(0.7699999999999998), np.float64(1.71), np.float64(1.16), np.float64(0.20999999999999974), np.float64(2.87), np.float64(3.17), np.float64(2.2), np.float64(3.88), np.float64(2.67), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.6499999999999995), np.float64(1.49), np.float64(3.41), np.float64(3.4), np.float64(2.19), np.float64(2.69), np.float64(1.25), np.float64(1.97), np.float64(1.67), np.float64(1.97), np.float64(2.45), np.float64(3.63), np.float64(3.17), np.float64(1.49), np.float64(1.73), np.float64(0.1900000000000004), np.float64(1.25), np.float64(2.69), np.float64(2.21), np.float64(2.17), np.float64(1.25), np.float64(1.73), np.float64(1.73), np.float64(1.73), np.float64(1.49), np.float64(2.45), np.float64(3.4), np.float64(2.45), np.float64(1.18), np.float64(1.97), np.float64(1.2699999999999996), np.float64(3.41), np.float64(2.1799999999999997), np.float64(-0.9399999999999986), np.float64(2.59), np.float64(1.67), np.float64(1.25), np.float64(1.49), np.float64(1.38), np.float64(1.13), np.float64(-0.46000000000000085), np.float64(0.4699999999999993), np.float64(-0.9299999999999997), np.float64(-4.059999999999998), np.float64(1.16), np.float64(2.4299999999999997), np.float64(2.45), np.float64(1.97), np.float64(1.97), np.float64(2.21), np.float64(2.21), np.float64(1.49), np.float64(1.5599999999999998), np.float64(3.62), np.float64(2.45), np.float64(1.49), np.float64(2.9), np.float64(1.44), np.float64(2.3599999999999994), np.float64(2.21), np.float64(1.49), np.float64(1.49), np.float64(3.5599999999999996), np.float64(2.17), np.float64(2.45), np.float64(3.41), np.float64(-12.719999999999951), np.float64(1.4), np.float64(1.97), np.float64(2.17), np.float64(1.97), np.float64(0.5799999999999998), np.float64(3.41), np.float64(1.25), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.6799999999999997), np.float64(2.21), np.float64(0.97), np.float64(2.44), np.float64(1.97), np.float64(3.17), np.float64(0.9000000000000001), np.float64(0.13000000000000078), np.float64(2.21), np.float64(1.97), np.float64(3.41), np.float64(1.48), np.float64(2.69), np.float64(3.3799999999999994), np.float64(2.62), np.float64(2.45), np.float64(1.73), np.float64(1.97), np.float64(2.19), np.float64(1.73), np.float64(3.15), np.float64(3.39), np.float64(3.41), np.float64(1.96), np.float64(1.49), np.float64(2.67), np.float64(0.5799999999999998), np.float64(2.11), np.float64(2.4299999999999997), np.float64(3.0199999999999996), np.float64(2.37), np.float64(1.47), np.float64(1.73), np.float64(0.6299999999999999), np.float64(0.22999999999999954), np.float64(1.49), np.float64(0.6799999999999999), np.float64(1.25), np.float64(1.49), np.float64(0.6199999999999997), np.float64(2.0599999999999996), np.float64(2.45), np.float64(2.45), np.float64(1.73), np.float64(2.42), np.float64(2.9299999999999997), np.float64(0.11999999999999944), np.float64(0.7199999999999995), np.float64(3.88), np.float64(2.9299999999999997), np.float64(0.22999999999999998), np.float64(2.7299999999999995), np.float64(3.37), np.float64(1.73), np.float64(2.8600000000000003), np.float64(1.25), np.float64(2.45), np.float64(1.25), np.float64(2.69), np.float64(1.73), np.float64(2.17), np.float64(2.51), np.float64(2.45), np.float64(0.9199999999999999), np.float64(1.97), np.float64(1.49), np.float64(2.04), np.float64(3.6500000000000004), np.float64(2.45), np.float64(2.57), np.float64(3.17), np.float64(0.19999999999999996), np.float64(1.96), np.float64(2.21), np.float64(1.2399999999999998), np.float64(3.63), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.69), np.float64(1.96), np.float64(1.4), np.float64(3.3899999999999997), np.float64(2.45), np.float64(2.61), np.float64(1.49), np.float64(3.17), np.float64(0.6799999999999999), np.float64(1.42), np.float64(3.37), np.float64(-0.41000000000000125), np.float64(3.17), np.float64(2.69), np.float64(2.69), np.float64(1.3699999999999999), np.float64(1.0), np.float64(2.67), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.0), np.float64(-10.489999999999942), np.float64(1.6199999999999997), np.float64(1.25), np.float64(1.25), np.float64(1.8099999999999998), np.float64(1.2499999999999998), np.float64(1.47), np.float64(1.5299999999999996), np.float64(0.9199999999999999), np.float64(1.73), np.float64(2.82), np.float64(2.3899999999999997), np.float64(1.73), np.float64(1.3599999999999997), np.float64(2.55), np.float64(1.8199999999999998), np.float64(2.59), np.float64(1.71), np.float64(3.41), np.float64(1.42), np.float64(1.96), np.float64(1.9499999999999997), np.float64(2.92), np.float64(-0.6499999999999979), np.float64(1.72), np.float64(1.73), np.float64(1.9899999999999998), np.float64(1.97), np.float64(1.97), np.float64(1.97), np.float64(1.97), np.float64(3.3899999999999997), np.float64(1.49), np.float64(2.67), np.float64(2.6799999999999997), np.float64(1.2), np.float64(2.25), np.float64(2.69), np.float64(1.6799999999999997), np.float64(2.41), np.float64(1.49), np.float64(2.17), np.float64(1.97), np.float64(2.67), np.float64(1.64), np.float64(3.3899999999999997), np.float64(1.73), np.float64(2.67), np.float64(1.97), np.float64(2.44), np.float64(1.65), np.float64(0.72), np.float64(1.5899999999999999), np.float64(1.2699999999999998), np.float64(1.49), np.float64(1.73), np.float64(1.73), np.float64(2.21), np.float64(1.2), np.float64(1.49), np.float64(1.7), np.float64(0.1399999999999999), np.float64(1.97), np.float64(2.32), np.float64(2.69), np.float64(2.69), np.float64(3.41), np.float64(2.9299999999999997), np.float64(2.4899999999999998), np.float64(1.42), np.float64(1.8699999999999999), np.float64(2.45), np.float64(1.5999999999999999), np.float64(3.15), np.float64(2.21), np.float64(3.6500000000000004), np.float64(1.49), np.float64(2.91), np.float64(0.16999999999999948), np.float64(2.9799999999999995), np.float64(2.9299999999999997), np.float64(1.96), np.float64(3.15), np.float64(1.66), np.float64(1.73), np.float64(1.4), np.float64(1.9499999999999997), np.float64(1.97), np.float64(1.25), np.float64(1.95), np.float64(2.91), np.float64(2.53), np.float64(3.8900000000000006), np.float64(3.6400000000000006), np.float64(2.4299999999999997), np.float64(2.69), np.float64(1.25), np.float64(2.1799999999999997), np.float64(2.19), np.float64(2.44), np.float64(1.97), np.float64(3.17), np.float64(3.41), np.float64(2.9299999999999997), np.float64(3.38), np.float64(1.49), np.float64(0.21999999999999975), np.float64(3.41), np.float64(2.19), np.float64(1.16), np.float64(3.4499999999999993), np.float64(2.9299999999999997), np.float64(3.5700000000000003), np.float64(2.19), np.float64(2.45), np.float64(1.25), np.float64(1.97), np.float64(3.37), np.float64(2.58), np.float64(1.5899999999999999), np.float64(3.3), np.float64(1.0299999999999998), np.float64(1.0), np.float64(2.2199999999999998), np.float64(1.97), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.97), np.float64(2.1799999999999997), np.float64(-0.17999999999999883), np.float64(2.9299999999999997), np.float64(2.8899999999999997), np.float64(2.69), np.float64(2.84), np.float64(1.73), np.float64(0.72), np.float64(1.8299999999999996), np.float64(2.69), np.float64(2.21), np.float64(2.67), np.float64(1.41), np.float64(1.2), np.float64(2.91), np.float64(2.8899999999999997), np.float64(1.73), np.float64(2.21), np.float64(1.73), np.float64(3.63), np.float64(2.21), np.float64(1.2), np.float64(1.19), np.float64(1.3199999999999996), np.float64(3.63), np.float64(1.95), np.float64(3.16), np.float64(2.69), np.float64(1.95), np.float64(2.45), np.float64(-11.349999999999914), np.float64(2.21), np.float64(1.97), np.float64(3.27), np.float64(2.45), np.float64(1.8199999999999998), np.float64(1.73), np.float64(1.97), np.float64(1.49), np.float64(3.13), np.float64(1.49), np.float64(2.17), np.float64(2.69), np.float64(0.8999999999999999), np.float64(1.73), np.float64(3.41), np.float64(1.97), np.float64(1.6199999999999999), np.float64(1.7899999999999998), np.float64(2.45), np.float64(2.92), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.2), np.float64(3.17), np.float64(-2.6099999999999977), np.float64(2.21), np.float64(2.45), np.float64(1.69), np.float64(0.72), np.float64(3.6899999999999995), np.float64(1.72), np.float64(2.87), np.float64(2.2), np.float64(2.45), np.float64(1.97), np.float64(2.21), np.float64(0.6499999999999999), np.float64(2.45), np.float64(1.44), np.float64(2.21), np.float64(1.73), np.float64(2.19), np.float64(2.91), np.float64(1.19), np.float64(-2.4399999999999595), np.float64(1.2), np.float64(0.5099999999999996), np.float64(1.42), np.float64(2.9299999999999997), np.float64(2.69), np.float64(3.41), np.float64(1.47), np.float64(1.73), np.float64(2.5999999999999988), np.float64(1.71), np.float64(1.96), np.float64(3.17), np.float64(1.16), np.float64(2.19), np.float64(3.17), np.float64(2.69), np.float64(2.67), np.float64(2.65), np.float64(2.4), np.float64(2.45), np.float64(3.17), np.float64(1.97), np.float64(1.73), np.float64(3.6500000000000004), np.float64(2.69), np.float64(-7.879999999999967), np.float64(2.9299999999999997), np.float64(1.71), np.float64(0.14999999999999947), np.float64(0.5999999999999996), np.float64(1.71), np.float64(1.49), np.float64(0.48), np.float64(1.97), np.float64(2.4699999999999998), np.float64(2.92), np.float64(1.73), np.float64(3.12), np.float64(2.46), np.float64(0.2799999999999998), np.float64(1.97), np.float64(2.6799999999999997), np.float64(1.97), np.float64(1.71), np.float64(2.91), np.float64(2.87), np.float64(2.9299999999999997), np.float64(3.0999999999999996), np.float64(1.66), np.float64(2.21), np.float64(1.7399999999999998), np.float64(1.25), np.float64(2.21), np.float64(1.0), np.float64(2.41), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.88), np.float64(1.73), np.float64(1.94), np.float64(3.17), np.float64(1.48), np.float64(1.0), np.float64(2.15), np.float64(2.19), np.float64(1.3699999999999999), np.float64(1.25), np.float64(2.66), np.float64(2.9), np.float64(1.47), np.float64(2.4299999999999997), np.float64(1.25), np.float64(2.2199999999999998), np.float64(3.54), np.float64(2.67), np.float64(3.870000000000001), np.float64(2.91), np.float64(2.45), np.float64(3.15), np.float64(2.2), np.float64(2.91), np.float64(2.21), np.float64(1.49), np.float64(3.05), np.float64(2.65), np.float64(2.41), np.float64(2.45), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.25), np.float64(3.63), np.float64(1.47), np.float64(3.62), np.float64(2.69), np.float64(1.49), np.float64(2.65), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.38), np.float64(2.45), np.float64(1.25), np.float64(2.45), np.float64(2.2), np.float64(2.67), np.float64(1.25), np.float64(1.68), np.float64(1.72), np.float64(3.15), np.float64(2.69), np.float64(1.25), np.float64(2.42), np.float64(1.73), np.float64(2.21), np.float64(2.6399999999999997), np.float64(2.21), np.float64(3.15), np.float64(2.09), np.float64(2.69), np.float64(2.21), np.float64(2.21), np.float64(1.8099999999999996), np.float64(1.97), np.float64(3.17), np.float64(3.15), np.float64(2.42), np.float64(2.45), np.float64(2.92), np.float64(2.9299999999999997), np.float64(3.3099999999999996), np.float64(2.66), np.float64(3.8900000000000006), np.float64(1.73), np.float64(2.45), np.float64(2.6199999999999997), np.float64(2.3899999999999997), np.float64(1.97), np.float64(3.6500000000000004), np.float64(2.19), np.float64(2.69), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.21), np.float64(2.69), np.float64(1.8599999999999999), np.float64(3.15), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.9), np.float64(1.72), np.float64(1.0), np.float64(3.41), np.float64(2.69), np.float64(3.15), np.float64(1.49), np.float64(2.75), np.float64(3.5000000000000018), np.float64(2.45), np.float64(2.69), np.float64(2.71), np.float64(2.45), np.float64(0.24), np.float64(1.2999999999999996), np.float64(1.97), np.float64(2.67), np.float64(1.73), np.float64(2.1799999999999997), np.float64(2.67), np.float64(-0.6999999999999986), np.float64(0.24), np.float64(2.45), np.float64(2.79), np.float64(2.5999999999999996), np.float64(3.4), np.float64(1.9499999999999995), np.float64(2.8899999999999997), np.float64(2.91), np.float64(1.73), np.float64(2.6799999999999997), np.float64(3.6100000000000003), np.float64(2.21), np.float64(2.45), np.float64(0.4099999999999999), np.float64(1.97), np.float64(1.73), np.float64(2.21), np.float64(3.8900000000000006), np.float64(1.49), np.float64(2.19), np.float64(2.79), np.float64(1.9999999999999996), np.float64(3.17), np.float64(2.9299999999999997), np.float64(3.41), np.float64(2.41), np.float64(1.73), np.float64(2.45), np.float64(2.44), np.float64(3.3899999999999997), np.float64(2.67), np.float64(1.49), np.float64(0.6499999999999999), np.float64(2.92), np.float64(1.69), np.float64(2.67), np.float64(3.13), np.float64(3.6500000000000004), np.float64(-7.3599999999999195), np.float64(2.9299999999999997), np.float64(1.0), np.float64(3.15), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.17), np.float64(0.9799999999999998), np.float64(2.1399999999999997), np.float64(1.15), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(1.95), np.float64(3.0599999999999996), np.float64(1.96), np.float64(1.73), np.float64(1.9199999999999995), np.float64(2.2), np.float64(2.78), np.float64(2.9299999999999997), np.float64(1.89), np.float64(1.93), np.float64(1.49), np.float64(1.49), np.float64(2.91), np.float64(0.9199999999999999), np.float64(1.97), np.float64(1.25), np.float64(2.69), np.float64(3.16), np.float64(1.41), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(2.5999999999999996), np.float64(1.44), np.float64(2.69), np.float64(2.4299999999999997), np.float64(3.17), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.38), np.float64(1.0), np.float64(0.5199999999999998), np.float64(1.25), np.float64(-24.390000000000434), np.float64(2.45), np.float64(2.4299999999999997), np.float64(1.95), np.float64(2.2399999999999998), np.float64(2.4299999999999997), np.float64(-1.6699999999999786), np.float64(1.0), np.float64(1.25), np.float64(2.8899999999999997), np.float64(1.25), np.float64(1.41), np.float64(2.69), np.float64(2.91), np.float64(0.6500000000000008), np.float64(1.97), np.float64(1.2999999999999998), np.float64(1.49), np.float64(2.45), np.float64(3.1599999999999993), np.float64(1.66), np.float64(2.45), np.float64(2.45), np.float64(1.25), np.float64(2.2299999999999995), np.float64(2.67), np.float64(2.69), np.float64(2.21), np.float64(1.97), np.float64(2.4299999999999997), np.float64(3.13), np.float64(0.9499999999999997), np.float64(2.209999999999999), np.float64(1.97), np.float64(2.87), np.float64(2.9299999999999997), np.float64(3.16), np.float64(2.9299999999999997), np.float64(3.38), np.float64(2.21), np.float64(1.73), np.float64(1.97), np.float64(1.97), np.float64(2.4299999999999997), np.float64(1.73), np.float64(1.95), np.float64(1.49), np.float64(1.49), np.float64(1.97), np.float64(1.48), np.float64(3.17), np.float64(2.69), np.float64(2.15), np.float64(3.6500000000000004), np.float64(3.17), np.float64(2.21), np.float64(2.91), np.float64(3.17), np.float64(1.47), np.float64(2.44), np.float64(2.69), np.float64(1.49), np.float64(1.97), np.float64(2.45), np.float64(1.73), np.float64(2.69), np.float64(2.3899999999999997), np.float64(3.17), np.float64(1.25), np.float64(1.0), np.float64(2.67), np.float64(2.9299999999999997), np.float64(1.3099999999999998), np.float64(2.740000000000002), np.float64(3.41), np.float64(2.19), np.float64(2.19), np.float64(0.8799999999999999), np.float64(2.19), np.float64(2.4399999999999995), np.float64(3.09), np.float64(3.34), np.float64(2.69), np.float64(2.8899999999999997), np.float64(2.45), np.float64(1.73), np.float64(1.73), np.float64(3.17), np.float64(3.31), np.float64(2.61), np.float64(2.11), np.float64(3.13), np.float64(2.9299999999999997), np.float64(2.84), np.float64(3.17), np.float64(3.3099999999999996), np.float64(1.5799999999999998), np.float64(1.96), np.float64(2.91), np.float64(1.0), np.float64(3.13), np.float64(2.21), np.float64(2.12), np.float64(-0.35999999999999943), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.49), np.float64(3.16), np.float64(3.17), np.float64(2.55), np.float64(1.73), np.float64(2.1899999999999995), np.float64(1.97), np.float64(1.15), np.float64(0.34999999999999987), np.float64(0.8499999999999999), np.float64(1.0), np.float64(3.6500000000000004), np.float64(0.0), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.47), np.float64(2.45), np.float64(2.6899999999999995), np.float64(0.72), np.float64(2.9299999999999997), np.float64(1.95), np.float64(3.3499999999999996), np.float64(3.37), np.float64(1.64), np.float64(2.17), np.float64(3.8900000000000006), np.float64(2.4299999999999997), np.float64(2.69), np.float64(3.7299999999999995), np.float64(2.3), np.float64(1.67), np.float64(1.73), np.float64(2.4299999999999997), np.float64(1.1199999999999997), np.float64(1.8299999999999998), np.float64(0.3199999999999996), np.float64(2.69), np.float64(2.8899999999999997), np.float64(1.25), np.float64(1.96), np.float64(2.45), np.float64(1.24), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.3099999999999996), np.float64(2.9299999999999997), np.float64(1.49), np.float64(1.49), np.float64(1.25), np.float64(1.66), np.float64(1.97), np.float64(1.73), np.float64(1.16), np.float64(2.69), np.float64(3.41), np.float64(2.91), np.float64(2.9299999999999997), np.float64(0.9199999999999999), np.float64(1.73), np.float64(2.4), np.float64(3.2499999999999996), np.float64(1.96), np.float64(2.41), np.float64(1.5699999999999998), np.float64(1.63), np.float64(2.41), np.float64(3.11), np.float64(0.44999999999999973), np.float64(1.9), np.float64(1.2), np.float64(2.67), np.float64(2.46), np.float64(1.49), np.float64(2.16), np.float64(2.78), np.float64(3.41), np.float64(0.6199999999999999), np.float64(0.48), np.float64(3.3899999999999997), np.float64(3.15), np.float64(1.73), np.float64(2.37), np.float64(1.95), np.float64(2.4799999999999995), np.float64(2.69), np.float64(-23.21000000000035), np.float64(3.13), np.float64(1.4299999999999997), np.float64(1.97), np.float64(1.72), np.float64(1.25), np.float64(1.89), np.float64(3.5700000000000003), np.float64(1.49), np.float64(2.6799999999999997), np.float64(0.9699999999999998), np.float64(-0.8099999999999943), np.float64(2.45), np.float64(2.67), np.float64(2.13), np.float64(1.97), np.float64(3.8900000000000006), np.float64(1.93), np.float64(1.97), np.float64(2.45), np.float64(2.67), np.float64(2.21), np.float64(2.69), np.float64(2.69), np.float64(2.21), np.float64(2.91), np.float64(1.47), np.float64(-17.20999999999991), np.float64(2.9299999999999997), np.float64(1.44), np.float64(1.49), np.float64(1.97), np.float64(1.2599999999999987), np.float64(2.21), np.float64(-1.0699999999999825), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.49), np.float64(1.0), np.float64(2.69), np.float64(2.45), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.21), np.float64(1.71), np.float64(3.15), np.float64(2.45), np.float64(1.96), np.float64(2.45), np.float64(1.49), np.float64(3.17), np.float64(2.6799999999999997), np.float64(3.17), np.float64(1.25), np.float64(2.9299999999999997), np.float64(1.96), np.float64(2.21), np.float64(1.49), np.float64(0.48), np.float64(1.94), np.float64(2.91), np.float64(1.49), np.float64(3.1399999999999997), np.float64(2.19), np.float64(2.45), np.float64(3.88), np.float64(0.2999999999999998), np.float64(3.17), np.float64(2.86), np.float64(1.4099999999999997), np.float64(2.65), np.float64(2.21), np.float64(2.8899999999999997), np.float64(2.21), np.float64(2.2), np.float64(2.21), np.float64(2.7899999999999996), np.float64(1.68), np.float64(2.21), np.float64(2.91), np.float64(2.07), np.float64(2.21), np.float64(1.95), np.float64(1.0), np.float64(2.45), np.float64(1.8299999999999994), np.float64(1.8299999999999996), np.float64(3.41), np.float64(2.15), np.float64(2.45), np.float64(1.97), np.float64(2.19), np.float64(1.9999999999999996), np.float64(2.3899999999999997), np.float64(1.0299999999999998), np.float64(2.9299999999999997), np.float64(2.91), np.float64(2.1799999999999997), np.float64(2.67), np.float64(2.45), np.float64(2.33), np.float64(1.0), np.float64(2.9299999999999997), np.float64(-2.4099999999999886), np.float64(2.1399999999999997), np.float64(2.45), np.float64(3.6399999999999997), np.float64(2.69), np.float64(3.09), np.float64(0.9199999999999999), np.float64(1.97), np.float64(2.21), np.float64(2.13), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.91), np.float64(3.630000000000001), np.float64(2.17), np.float64(-1.769999999999997), np.float64(-0.4300000000000004), np.float64(2.45), np.float64(1.95), np.float64(2.21), np.float64(0.7299999999999989), np.float64(2.9299999999999997), np.float64(3.17), np.float64(3.6500000000000004), np.float64(1.42), np.float64(2.54), np.float64(0.9999999999999998), np.float64(3.39), np.float64(1.93), np.float64(2.17), np.float64(1.73), np.float64(3.6500000000000004), np.float64(3.8900000000000006), np.float64(2.67), np.float64(2.09), np.float64(1.97), np.float64(2.13), np.float64(2.1799999999999997), np.float64(3.17), np.float64(2.9299999999999997), np.float64(2.17), np.float64(3.17), np.float64(2.1399999999999997), np.float64(1.44), np.float64(1.4499999999999997), np.float64(3.36), np.float64(1.69), np.float64(0.22999999999999976), np.float64(1.49), np.float64(2.58), np.float64(2.45), np.float64(2.69), np.float64(1.44), np.float64(1.95), np.float64(2.67), np.float64(2.45), np.float64(2.66), np.float64(3.6500000000000004), np.float64(2.69), np.float64(2.2), np.float64(1.34), np.float64(1.49), np.float64(3.3899999999999997), np.float64(3.16), np.float64(2.67), np.float64(2.45), np.float64(2.21), np.float64(2.21), np.float64(1.47), np.float64(3.17), np.float64(3.3899999999999997), np.float64(2.92), np.float64(1.4699999999999998), np.float64(2.19), np.float64(2.92), np.float64(1.0), np.float64(1.0), np.float64(3.3899999999999997), np.float64(2.91), np.float64(1.97), np.float64(1.0), np.float64(1.18), np.float64(1.97), np.float64(2.69), np.float64(1.97), np.float64(1.13), np.float64(1.68), np.float64(2.69), np.float64(0.9899999999999998), np.float64(2.65), np.float64(1.47), np.float64(1.49), np.float64(2.34), np.float64(-16.819999999999954), np.float64(-11.25999999999992), np.float64(-1.8099999999999952), np.float64(0.31999999999999873), np.float64(2.05), np.float64(2.34), np.float64(1.73), np.float64(1.73), np.float64(2.3899999999999997), np.float64(1.97), np.float64(1.49), np.float64(2.29), np.float64(1.9599999999999997), np.float64(2.54), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.3899999999999997), np.float64(2.6799999999999997), np.float64(3.6500000000000004), np.float64(1.97), np.float64(3.41), np.float64(3.3699999999999997), np.float64(2.8899999999999997), np.float64(0.8999999999999999), np.float64(1.49), np.float64(2.44), np.float64(1.0), np.float64(2.69), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.97), np.float64(1.95), np.float64(1.97), np.float64(2.69), np.float64(2.4299999999999997), np.float64(3.41), np.float64(0.96), np.float64(1.9), np.float64(3.4), np.float64(0.7899999999999994), np.float64(2.92), np.float64(3.3899999999999997), np.float64(1.47), np.float64(1.6199999999999999), np.float64(1.71), np.float64(2.67), np.float64(3.16), np.float64(2.3499999999999996), np.float64(2.9299999999999997), np.float64(3.0999999999999996), np.float64(1.95), np.float64(2.69), np.float64(3.4), np.float64(3.15), np.float64(2.67), np.float64(-1.6599999999999993), np.float64(-2.4699999999999545), np.float64(3.59), np.float64(1.66), np.float64(1.25), np.float64(1.49), np.float64(2.19), np.float64(1.0), np.float64(1.73), np.float64(2.6399999999999997), np.float64(2.69), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.97), np.float64(1.25), np.float64(1.49), np.float64(2.3), np.float64(-1.4299999999999917), np.float64(1.49), np.float64(1.49), np.float64(2.67), np.float64(1.49), np.float64(3.05), np.float64(2.69), np.float64(1.25), np.float64(2.91), np.float64(1.73), np.float64(2.21), np.float64(0.5599999999999998), np.float64(1.49), np.float64(3.5299999999999994), np.float64(2.45), np.float64(1.95), np.float64(1.39), np.float64(3.6399999999999997), np.float64(0.3499999999999994), np.float64(2.38), np.float64(3.17), np.float64(1.73), np.float64(2.41), np.float64(1.23), np.float64(1.97), np.float64(2.86), np.float64(2.45), np.float64(2.45), np.float64(1.0), np.float64(2.17), np.float64(1.73), np.float64(1.25), np.float64(2.21), np.float64(1.49), np.float64(1.71), np.float64(2.4), np.float64(2.45), np.float64(2.19), np.float64(0.6699999999999997), np.float64(3.16), np.float64(1.49), np.float64(3.169999999999999), np.float64(1.73), np.float64(1.73), np.float64(2.8099999999999996), np.float64(2.19), np.float64(1.95), np.float64(2.69), np.float64(2.21), np.float64(2.69), np.float64(2.45), np.float64(2.8299999999999996), np.float64(2.21), np.float64(2.3899999999999997), np.float64(1.25), np.float64(2.67), np.float64(1.14), np.float64(1.73), np.float64(3.41), np.float64(1.97), np.float64(2.69), np.float64(2.1399999999999997), np.float64(2.3999999999999995), np.float64(2.91), np.float64(3.3899999999999997), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.44), np.float64(2.91), np.float64(1.73), np.float64(2.2), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.44), np.float64(1.0), np.float64(3.6500000000000004), np.float64(1.25), np.float64(1.2), np.float64(1.73), np.float64(3.3899999999999997), np.float64(-27.260000000000595), np.float64(1.0), np.float64(3.8900000000000006), np.float64(1.3099999999999987), np.float64(2.07), np.float64(2.59), np.float64(2.62), np.float64(1.94), np.float64(2.1799999999999997), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.49), np.float64(2.2699999999999996), np.float64(1.73), np.float64(1.73), np.float64(1.4), np.float64(3.3999999999999995), np.float64(3.55), np.float64(0.16999999999999904), np.float64(2.19), np.float64(0.47999999999999976), np.float64(1.6099999999999997), np.float64(1.49), np.float64(1.95), np.float64(0.7699999999999996), np.float64(2.45), np.float64(1.73), np.float64(1.92), np.float64(0.7699999999999998), np.float64(1.47), np.float64(1.0), np.float64(2.45), np.float64(3.46), np.float64(1.71), np.float64(2.1099999999999994), np.float64(2.45), np.float64(2.57), np.float64(2.69), np.float64(1.9), np.float64(-0.6200000000000008), np.float64(1.5599999999999998), np.float64(2.09), np.float64(2.69), np.float64(2.92), np.float64(-0.5800000000000005), np.float64(1.47), np.float64(2.3599999999999994), np.float64(2.45), np.float64(1.42), np.float64(1.0), np.float64(2.91), np.float64(1.49), np.float64(2.9299999999999997), np.float64(3.17), np.float64(3.17), np.float64(3.15), np.float64(2.45), np.float64(2.45), np.float64(2.69), np.float64(1.95), np.float64(1.73), np.float64(2.5599999999999996), np.float64(1.97), np.float64(1.49), np.float64(2.21), np.float64(1.6099999999999999), np.float64(0.69), np.float64(2.17), np.float64(1.97), np.float64(3.870000000000001), np.float64(1.8699999999999999), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.69), np.float64(3.1399999999999997), np.float64(1.73), np.float64(1.6099999999999999), np.float64(2.57), np.float64(1.25), np.float64(1.38), np.float64(1.71), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.97), np.float64(2.21), np.float64(1.97), np.float64(2.45), np.float64(-9.82999999999998), np.float64(2.8899999999999997), np.float64(2.69), np.float64(2.6399999999999997), np.float64(2.45), np.float64(0.8799999999999999), np.float64(0.48999999999999955), np.float64(2.28), np.float64(1.7599999999999996), np.float64(2.1899999999999995), np.float64(1.73), np.float64(2.67), np.float64(2.67), np.float64(2.69), np.float64(1.49), np.float64(2.69), np.float64(1.73), np.float64(3.6399999999999997), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(2.4299999999999997), np.float64(3.15), np.float64(1.49), np.float64(3.88), np.float64(1.97), np.float64(2.12), np.float64(2.6799999999999997), np.float64(3.3899999999999997), np.float64(2.9299999999999997), np.float64(2.17), np.float64(1.16), np.float64(1.47), np.float64(1.49), np.float64(2.19), np.float64(2.4299999999999997), np.float64(2.45), np.float64(1.25), np.float64(2.45), np.float64(1.2699999999999994), np.float64(2.69), np.float64(3.16), np.float64(1.73), np.float64(1.25), np.float64(1.44), np.float64(3.41), np.float64(1.97), np.float64(2.0999999999999996), np.float64(1.0), np.float64(2.4299999999999997), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.4299999999999997), np.float64(2.69), np.float64(0.9199999999999999), np.float64(2.3699999999999997), np.float64(1.73), np.float64(-0.03000000000000047), np.float64(1.71), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.0899999999999999), np.float64(2.3999999999999995), np.float64(2.41), np.float64(3.59), np.float64(2.91), np.float64(1.64), np.float64(2.91), np.float64(2.9299999999999997), np.float64(2.11), np.float64(2.61), np.float64(2.17), np.float64(3.6500000000000004), np.float64(2.6799999999999997), np.float64(1.49), np.float64(1.4699999999999998), np.float64(1.25), np.float64(2.92), np.float64(2.21), np.float64(2.45), np.float64(2.69), np.float64(2.57), np.float64(2.3899999999999997), np.float64(2.69), np.float64(1.1799999999999997), np.float64(1.6999999999999997), np.float64(3.17), np.float64(2.36), np.float64(1.71), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.19), np.float64(1.0), np.float64(0.6899999999999995), np.float64(2.83), np.float64(2.17), np.float64(1.0), np.float64(2.4299999999999997), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.92), np.float64(2.45), np.float64(1.73), np.float64(-0.27), np.float64(1.0), np.float64(1.65), np.float64(1.73), np.float64(2.11), np.float64(3.38), np.float64(2.69), np.float64(-1.6999999999999993), np.float64(1.0), np.float64(1.4699999999999995), np.float64(1.8099999999999998), np.float64(2.2), np.float64(2.17), np.float64(2.4299999999999997), np.float64(2.3), np.float64(3.15), np.float64(0.18999999999999995), np.float64(1.42), np.float64(1.95), np.float64(2.69), np.float64(2.21), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.4299999999999997), np.float64(1.97), np.float64(1.7899999999999998), np.float64(1.25), np.float64(1.73), np.float64(2.21), np.float64(3.21), np.float64(1.73), np.float64(2.92), np.float64(3.38), np.float64(3.16), np.float64(3.17), np.float64(1.97), np.float64(2.19), np.float64(2.7699999999999996), np.float64(2.21), np.float64(1.8699999999999999), np.float64(1.73), np.float64(1.48), np.float64(2.9299999999999997), np.float64(3.17), np.float64(-20.990000000000414), np.float64(0.7999999999999996), np.float64(-4.67999999999999), np.float64(-0.5700000000000005), np.float64(2.16), np.float64(2.5199999999999996), np.float64(2.3099999999999996), np.float64(1.8199999999999996), np.float64(1.7799999999999998), np.float64(2.63), np.float64(2.15), np.float64(3.6500000000000004), np.float64(2.08), np.float64(2.38), np.float64(2.1499999999999995), np.float64(1.68), np.float64(-3.179999999999999), np.float64(2.0599999999999996), np.float64(3.6500000000000004), np.float64(1.0), np.float64(2.21), np.float64(1.95), np.float64(3.37), np.float64(1.97), np.float64(2.19), np.float64(2.69), np.float64(2.66), np.float64(1.4599999999999997), np.float64(1.73), np.float64(1.71), np.float64(2.7799999999999994), np.float64(3.11), np.float64(1.9), np.float64(1.25), np.float64(1.73), np.float64(1.73), np.float64(2.3499999999999996), np.float64(1.73), np.float64(1.25), np.float64(1.4), np.float64(1.73), np.float64(1.95), np.float64(3.3899999999999997), np.float64(1.97), np.float64(3.3899999999999997), np.float64(2.65), np.float64(1.0699999999999998), np.float64(2.91), np.float64(2.21), np.float64(2.67), np.float64(2.12), np.float64(1.68), np.float64(2.45), np.float64(2.38), np.float64(0.8699999999999999), np.float64(0.47999999999999976), np.float64(-2.2799999999999914), np.float64(1.73), np.float64(2.4399999999999995), np.float64(2.21), np.float64(1.25), np.float64(2.45), np.float64(2.45), np.float64(1.25), np.float64(1.2699999999999991), np.float64(2.3899999999999997), np.float64(2.41), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.97), np.float64(1.88), np.float64(0.5299999999999996), np.float64(1.14), np.float64(3.17), np.float64(2.21), np.float64(1.97), np.float64(3.41), np.float64(2.4299999999999997), np.float64(3.16), np.float64(3.63), np.float64(2.6899999999999995), np.float64(3.870000000000001), np.float64(2.8899999999999997), np.float64(3.17), np.float64(3.6500000000000004), np.float64(-8.739999999999949), np.float64(2.6399999999999997), np.float64(2.6399999999999997), np.float64(2.9299999999999997), np.float64(3.63), np.float64(3.17), np.float64(3.0699999999999994), np.float64(-0.23000000000000154), np.float64(1.18), np.float64(2.69), np.float64(2.92), np.float64(2.2), np.float64(3.13), np.float64(2.33), np.float64(1.0), np.float64(1.73), np.float64(1.73), np.float64(3.8900000000000006), np.float64(1.3299999999999998), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(1.97), np.float64(3.41), np.float64(2.16), np.float64(3.4), np.float64(3.37), np.float64(1.49), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.4299999999999997), np.float64(1.9), np.float64(2.9299999999999997), np.float64(3.58), np.float64(2.8899999999999997), np.float64(1.97), np.float64(2.8899999999999997), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.5799999999999998), np.float64(3.4099999999999997), np.float64(2.9), np.float64(1.0), np.float64(3.26), np.float64(1.73), np.float64(2.69), np.float64(2.58), np.float64(1.4999999999999998), np.float64(2.19), np.float64(2.21), np.float64(2.2), np.float64(2.21), np.float64(1.0), np.float64(2.9299999999999997), np.float64(-0.6599999999999941), np.float64(2.92), np.float64(3.6500000000000004), np.float64(0.9399999999999997), np.float64(0.8499999999999999), np.float64(1.4699999999999998), np.float64(1.25), np.float64(2.65), np.float64(0.5899999999999999), np.float64(2.45), np.float64(1.25), np.float64(3.4000000000000004), np.float64(2.21), np.float64(1.97), np.float64(0.43999999999999995), np.float64(1.25), np.float64(1.0), np.float64(3.3899999999999997), np.float64(2.7399999999999998), np.float64(3.880000000000001), np.float64(3.87), np.float64(2.21), np.float64(1.95), np.float64(2.21), np.float64(1.7), np.float64(2.4), np.float64(2.4299999999999997), np.float64(2.69), np.float64(1.8099999999999998), np.float64(2.37), np.float64(1.96), np.float64(1.73), np.float64(1.89), np.float64(3.15), np.float64(3.6500000000000004), np.float64(2.21), np.float64(1.25), np.float64(2.6899999999999995), np.float64(2.17), np.float64(3.17), np.float64(3.13), np.float64(-17.40999999999998), np.float64(1.97), np.float64(3.17), np.float64(-23.64000000000049), np.float64(2.6799999999999997), np.float64(2.8899999999999997), np.float64(0.7), np.float64(1.97), np.float64(1.92), np.float64(0.9499999999999997), np.float64(1.429999999999999), np.float64(1.25), np.float64(3.17), np.float64(1.73), np.float64(1.25), np.float64(3.6500000000000004), np.float64(1.49), np.float64(-0.11999999999999633), np.float64(0.6700000000000004), np.float64(3.41), np.float64(0.96), np.float64(1.73), np.float64(2.45), np.float64(1.93), np.float64(3.3899999999999997), np.float64(2.21), np.float64(3.17), np.float64(2.71), np.float64(1.25), np.float64(1.0), np.float64(1.25), np.float64(1.25), np.float64(-13.619999999999845), np.float64(1.5599999999999998), np.float64(2.62), np.float64(2.45), np.float64(3.38), np.float64(2.67), np.float64(3.3699999999999997), np.float64(-0.8300000000000001), np.float64(0.2899999999999989), np.float64(1.5099999999999998), np.float64(2.21), np.float64(2.62), np.float64(1.31), np.float64(2.7699999999999996), np.float64(2.19), np.float64(3.25), np.float64(1.8199999999999998), np.float64(-1.2599999999999998), np.float64(2.92), np.float64(2.87), np.float64(2.21), np.float64(1.9699999999999998), np.float64(3.34), np.float64(3.3899999999999997), np.float64(2.69), np.float64(2.0999999999999996), np.float64(2.45), np.float64(-10.29999999999991), np.float64(2.69), np.float64(1.73), np.float64(1.9699999999999998), np.float64(3.16), np.float64(0.48), np.float64(2.08), np.float64(1.71), np.float64(1.0), np.float64(2.69), np.float64(2.44), np.float64(2.83), np.float64(1.97), np.float64(2.21), np.float64(1.95), np.float64(3.3899999999999997), np.float64(3.3499999999999996), np.float64(1.97), np.float64(2.9), np.float64(1.25), np.float64(2.37), np.float64(3.13), np.float64(2.45), np.float64(2.45), np.float64(2.4299999999999997), np.float64(3.16), np.float64(0.21999999999999997), np.float64(2.21), np.float64(2.69), np.float64(1.73), np.float64(1.6199999999999999), np.float64(-7.22999999999997), np.float64(1.0), np.float64(-0.010000000000002007), np.float64(-0.44999999999999973), np.float64(-0.8400000000000016), np.float64(-3.5599999999999765), np.float64(1.49), np.float64(1.8899999999999992), np.float64(-0.35999999999998833), np.float64(1.92), np.float64(1.73), np.float64(1.96), np.float64(0.7799999999999991), np.float64(1.2899999999999996), np.float64(2.5599999999999996), np.float64(1.73), np.float64(0.7499999999999996), np.float64(1.41), np.float64(-0.27), np.float64(2.91), np.float64(3.6399999999999997), np.float64(-0.36000000000000054), np.float64(0.6499999999999997), np.float64(2.21), np.float64(1.52), np.float64(1.97), np.float64(1.47), np.float64(1.0), np.float64(1.64), np.float64(2.21), np.float64(2.45), np.float64(1.97), np.float64(2.9199999999999995), np.float64(2.17), np.float64(3.17), np.float64(1.2699999999999998), np.float64(2.45), np.float64(1.0), np.float64(3.1399999999999997), np.float64(3.15), np.float64(0.9099999999999997), np.float64(2.21), np.float64(1.95), np.float64(3.11), np.float64(2.7699999999999996), np.float64(3.17), np.float64(2.91), np.float64(2.45), np.float64(1.94), np.float64(2.19), np.float64(2.21), np.float64(2.65), np.float64(3.15), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.45), np.float64(3.17), np.float64(2.21), np.float64(1.73), np.float64(3.87), np.float64(3.12), np.float64(2.4000000000000004), np.float64(2.12), np.float64(3.41), np.float64(2.45), np.float64(2.4), np.float64(1.73), np.float64(1.4499999999999997), np.float64(2.21), np.float64(2.92), np.float64(2.67), np.float64(2.19), np.float64(2.45), np.float64(2.4299999999999997), np.float64(-0.05000000000000138), np.float64(1.73), np.float64(1.73), np.float64(2.6799999999999997), np.float64(-0.3199999999999945), np.float64(1.25), np.float64(1.23), np.float64(1.1299999999999997), np.float64(3.17), np.float64(2.21), np.float64(3.25), np.float64(2.4), np.float64(3.63), np.float64(2.86), np.float64(3.0300000000000002), np.float64(1.47), np.float64(1.49), np.float64(2.69), np.float64(1.71), np.float64(1.64), np.float64(2.45), np.float64(1.45), np.float64(3.41), np.float64(2.4), np.float64(1.43), np.float64(0.9299999999999999), np.float64(2.9299999999999997), np.float64(2.28), np.float64(1.73), np.float64(2.67), np.float64(1.7999999999999998), np.float64(2.9299999999999997), np.float64(2.3499999999999996), np.float64(1.71), np.float64(2.4899999999999998), np.float64(1.97), np.float64(2.69), np.float64(2.6100000000000003), np.float64(1.92), np.float64(1.9299999999999997), np.float64(2.9299999999999997), np.float64(3.63), np.float64(1.25), np.float64(2.3899999999999997), np.float64(1.97), np.float64(1.25), np.float64(0.5399999999999996), np.float64(1.73), np.float64(-2.1799999999999873), np.float64(1.94), np.float64(1.69), np.float64(2.69), np.float64(2.3899999999999997), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(3.17), np.float64(-0.5700000000000003), np.float64(2.41), np.float64(3.4), np.float64(0.7), np.float64(1.8699999999999999), np.float64(1.96), np.float64(1.2), np.float64(1.73), np.float64(1.73), np.float64(2.0999999999999996), np.float64(2.36), np.float64(1.25), np.float64(2.59), np.float64(1.25), np.float64(2.41), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.71), np.float64(2.69), np.float64(2.69), np.float64(2.65), np.float64(-3.439999999999947), np.float64(1.95), np.float64(2.17), np.float64(0.24), np.float64(2.25), np.float64(3.5700000000000003), np.float64(1.5999999999999999), np.float64(1.66), np.float64(1.71), np.float64(1.49), np.float64(2.69), np.float64(1.2), np.float64(1.89), np.float64(2.45), np.float64(1.49), np.float64(1.38), np.float64(1.49), np.float64(1.95), np.float64(3.41), np.float64(3.17), np.float64(1.97), np.float64(2.92), np.float64(1.71), np.float64(3.41), np.float64(1.64), np.float64(2.66), np.float64(1.97), np.float64(1.97), np.float64(2.16), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.21), np.float64(3.87), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.9), np.float64(2.21), np.float64(2.69), np.float64(2.67), np.float64(2.69), np.float64(2.69), np.float64(-0.7999999999999998), np.float64(1.2599999999999998), np.float64(2.28), np.float64(3.4), np.float64(2.4299999999999997), np.float64(-0.3100000000000005), np.float64(2.69), np.float64(2.69), np.float64(-0.8999999999999995), np.float64(0.5499999999999996), np.float64(1.97), np.float64(2.6599999999999997), np.float64(1.47), np.float64(2.45), np.float64(2.4399999999999995), np.float64(2.21), np.float64(2.21), np.float64(1.73), np.float64(3.17), np.float64(1.4699999999999998), np.float64(2.69), np.float64(2.1499999999999995), np.float64(1.5899999999999999), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.7), np.float64(2.21), np.float64(1.73), np.float64(2.69), np.float64(2.34), np.float64(1.25), np.float64(1.49), np.float64(3.38), np.float64(3.16), np.float64(3.55), np.float64(-0.009999999999986464), np.float64(3.3899999999999997), np.float64(2.17), np.float64(2.69), np.float64(3.15), np.float64(1.25), np.float64(2.19), np.float64(-6.709999999999901), np.float64(2.67), np.float64(1.9599999999999997), np.float64(1.25), np.float64(1.94), np.float64(2.4), np.float64(1.88), np.float64(2.21), np.float64(2.45), np.float64(2.69), np.float64(2.91), np.float64(1.23), np.float64(-4.769999999999973), np.float64(-4.8699999999999894), np.float64(2.4299999999999997), np.float64(3.17), np.float64(2.21), np.float64(3.630000000000001), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.45), np.float64(0.0999999999999992), np.float64(2.69), np.float64(-0.6700000000000002), np.float64(1.73), np.float64(3.6500000000000004), np.float64(2.5999999999999996), np.float64(1.49), np.float64(2.9), np.float64(2.12), np.float64(1.8599999999999999), np.float64(2.09), np.float64(1.95), np.float64(1.71), np.float64(0.5799999999999996), np.float64(2.79), np.float64(1.92), np.float64(0.72), np.float64(1.49), np.float64(-3.4299999999999864), np.float64(-3.6599999999999904), np.float64(2.9299999999999997), np.float64(2.54), np.float64(1.97), np.float64(1.41), np.float64(1.97), np.float64(2.69), np.float64(1.0), np.float64(2.91), np.float64(2.21), np.float64(2.21), np.float64(2.17), np.float64(2.67), np.float64(1.73), np.float64(2.4299999999999997), np.float64(1.8199999999999998), np.float64(2.17), np.float64(2.88), np.float64(1.9599999999999997), np.float64(2.2), np.float64(2.45), np.float64(2.45), np.float64(2.44), np.float64(1.0899999999999994), np.float64(3.01), np.float64(3.17), np.float64(2.1399999999999997), np.float64(2.9299999999999997), np.float64(1.47), np.float64(2.1799999999999997), np.float64(2.45), np.float64(3.6500000000000004), np.float64(2.21), np.float64(2.15), np.float64(1.25), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.6799999999999997), np.float64(2.9299999999999997), np.float64(0.9299999999999999), np.float64(1.73), np.float64(1.44), np.float64(2.45), np.float64(1.25), np.float64(1.97), np.float64(2.69), np.float64(3.08), np.float64(2.19), np.float64(3.6500000000000004), np.float64(2.13), np.float64(2.12), np.float64(2.9), np.float64(1.97), np.float64(1.16), np.float64(2.4299999999999997), np.float64(2.69), np.float64(2.69), np.float64(-3.0599999999999907), np.float64(1.3399999999999999), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.8599999999999999), np.float64(1.49), np.float64(2.45), np.float64(3.17), np.float64(2.67), np.float64(1.25), np.float64(3.17), np.float64(2.4299999999999997), np.float64(2.04), np.float64(2.9), np.float64(-0.1500000000000008), np.float64(-12.539999999999914), np.float64(0.5399999999999998), np.float64(2.19), np.float64(2.45), np.float64(2.92), np.float64(2.21), np.float64(3.1399999999999997), np.float64(1.5699999999999998), np.float64(1.25), np.float64(2.45), np.float64(-0.010000000000001785), np.float64(1.73), np.float64(3.17), np.float64(1.95), np.float64(2.45), np.float64(2.21), np.float64(1.73), np.float64(3.62), np.float64(2.19), np.float64(1.48), np.float64(2.21), np.float64(3.3899999999999997), np.float64(1.97), np.float64(1.0299999999999996), np.float64(2.69), np.float64(2.8899999999999997), np.float64(1.7699999999999998), np.float64(2.76), np.float64(2.91), np.float64(1.71), np.float64(1.95), np.float64(2.01), np.float64(3.17), np.float64(2.8899999999999997), np.float64(0.4599999999999995), np.float64(1.97), np.float64(2.26), np.float64(3.17), np.float64(1.97), np.float64(1.97), np.float64(1.49), np.float64(3.41), np.float64(3.4), np.float64(3.13), np.float64(2.9399999999999995), np.float64(2.45), np.float64(1.23), np.float64(2.21), np.float64(2.45), np.float64(2.45), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.5799999999999998), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.13), np.float64(2.21), np.float64(3.17), np.float64(1.23), np.float64(3.6500000000000004), np.float64(0.99), np.float64(2.4099999999999997), np.float64(3.8900000000000006), np.float64(3.4), np.float64(3.1399999999999997), np.float64(2.69), np.float64(2.69), np.float64(1.73), np.float64(2.69), np.float64(3.63), np.float64(1.97), np.float64(0.5799999999999998), np.float64(2.58), np.float64(2.65), np.float64(2.42), np.float64(1.71), np.float64(2.45), np.float64(2.21), np.float64(3.29), np.float64(2.45), np.float64(2.67), np.float64(1.93), np.float64(2.21), np.float64(1.49), np.float64(-2.3499999999999908), np.float64(1.0), np.float64(1.97), np.float64(2.87), np.float64(2.69), np.float64(3.3899999999999997), np.float64(2.67), np.float64(3.41), np.float64(-12.139999999999866), np.float64(2.9299999999999997), np.float64(1.68), np.float64(1.73), np.float64(2.91), np.float64(2.38), np.float64(-2.0), np.float64(2.67), np.float64(2.41), np.float64(1.9999999999999998), np.float64(1.93), np.float64(1.73), np.float64(1.5399999999999998), np.float64(3.13), np.float64(2.21), np.float64(1.64), np.float64(3.04), np.float64(2.69), np.float64(1.93), np.float64(2.1499999999999995), np.float64(2.67), np.float64(1.0), np.float64(3.3899999999999997), np.float64(2.6399999999999997), np.float64(1.3399999999999999), np.float64(2.4299999999999997), np.float64(1.48), np.float64(2.13), np.float64(1.73), np.float64(0.06999999999999962), np.float64(2.69), np.float64(-7.4499999999999496), np.float64(-11.579999999999984), np.float64(0.9999999999999998), np.float64(2.69), np.float64(1.73), np.float64(1.25), np.float64(3.16), np.float64(1.73), np.float64(-0.24), np.float64(1.49), np.float64(-0.5799999999999994), np.float64(1.73), np.float64(2.21), np.float64(2.8), np.float64(2.3299999999999996), np.float64(2.9299999999999997), np.float64(2.69), np.float64(0.6299999999999999), np.float64(1.73), np.float64(3.15), np.float64(1.9999999999999996), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.25), np.float64(2.21), np.float64(2.19), np.float64(1.41), np.float64(3.6500000000000004), np.float64(2.88), np.float64(1.25), np.float64(2.21), np.float64(1.73), np.float64(2.69), np.float64(1.8499999999999999), np.float64(2.9), np.float64(2.17), np.float64(0.9399999999999995), np.float64(2.62), np.float64(0.6399999999999999), np.float64(1.71), np.float64(2.19), np.float64(1.7), np.float64(1.97), np.float64(1.92), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.1799999999999997), np.float64(3.62), np.float64(-17.169999999999895), np.float64(2.45), np.float64(1.0), np.float64(-2.2399999999999682), np.float64(1.97), np.float64(1.69), np.float64(2.42), np.float64(3.38), np.float64(2.16), np.float64(2.41), np.float64(2.38), np.float64(1.0999999999999994), np.float64(2.4299999999999997), np.float64(1.47), np.float64(3.63), np.float64(1.2799999999999998), np.float64(2.21), np.float64(2.58), np.float64(3.4), np.float64(1.44), np.float64(1.97), np.float64(1.42), np.float64(2.25), np.float64(2.7299999999999995), np.float64(3.41), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(1.95), np.float64(1.19), np.float64(2.6799999999999997), np.float64(1.97), np.float64(1.25), np.float64(2.6799999999999997), np.float64(1.73), np.float64(3.3499999999999996), np.float64(1.73), np.float64(3.3899999999999997), np.float64(3.37), np.float64(1.72), np.float64(2.2), np.float64(1.68), np.float64(1.73), np.float64(1.25), np.float64(2.19), np.float64(1.73), np.float64(2.92), np.float64(1.71), np.float64(1.6199999999999999), np.float64(3.17), np.float64(1.97), np.float64(2.8899999999999997), np.float64(3.16), np.float64(1.95), np.float64(1.73), np.float64(1.5799999999999998), np.float64(2.9), np.float64(2.8899999999999997), np.float64(1.49), np.float64(2.45), np.float64(2.92), np.float64(-24.260000000000943), np.float64(1.4399999999999997), np.float64(1.73), np.float64(1.1099999999999999), np.float64(1.73), np.float64(2.51), np.float64(2.62), np.float64(1.9999999999999998), np.float64(1.49), np.float64(1.0), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.13), np.float64(2.21), np.float64(1.73), np.float64(2.19), np.float64(2.9299999999999997), np.float64(1.8399999999999996), np.float64(1.14), np.float64(2.9299999999999997), np.float64(-0.9800000000000004), np.float64(0.6499999999999986), np.float64(1.49), np.float64(3.87), np.float64(2.6999999999999993), np.float64(3.8900000000000006), np.float64(1.49), np.float64(2.92), np.float64(2.8899999999999997), np.float64(1.49), np.float64(2.21), np.float64(1.14), np.float64(1.73), np.float64(2.21), np.float64(2.41), np.float64(2.42), np.float64(1.97), np.float64(2.17), np.float64(1.64), np.float64(2.5999999999999996), np.float64(2.44), np.float64(2.04), np.float64(2.67), np.float64(3.15), np.float64(1.49), np.float64(1.7099999999999997), np.float64(1.2), np.float64(2.21), np.float64(2.16), np.float64(3.41), np.float64(2.8499999999999996), np.float64(2.3899999999999997), np.float64(3.17), np.float64(2.44), np.float64(3.2700000000000014), np.float64(1.5899999999999999), np.float64(2.4299999999999997), np.float64(3.6399999999999997), np.float64(1.25), np.float64(1.49), np.float64(1.97), np.float64(0.6799999999999995), np.float64(3.01), np.float64(2.6799999999999997), np.float64(1.73), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.92), np.float64(2.44), np.float64(3.37), np.float64(1.73), np.float64(2.45), np.float64(3.6500000000000004), np.float64(2.62), np.float64(3.15), np.float64(2.45), np.float64(1.97), np.float64(1.49), np.float64(2.21), np.float64(1.25), np.float64(1.49), np.float64(1.73), np.float64(1.97), np.float64(3.33), np.float64(2.67), np.float64(2.9299999999999997), np.float64(1.39), np.float64(3.2699999999999996), np.float64(1.17), np.float64(1.4), np.float64(2.51), np.float64(2.45), np.float64(1.95), np.float64(1.6599999999999997), np.float64(1.7599999999999996), np.float64(1.0), np.float64(1.97), np.float64(1.72), np.float64(2.45), np.float64(1.24), np.float64(1.73), np.float64(2.69), np.float64(2.69), np.float64(2.69), np.float64(2.21), np.float64(3.15), np.float64(-0.39999999999999547), np.float64(2.69), np.float64(2.2), np.float64(0.5899999999999996), np.float64(3.4), np.float64(1.71), np.float64(-0.7800000000000002), np.float64(2.69), np.float64(1.95), np.float64(1.73), np.float64(1.97), np.float64(2.42), np.float64(1.95), np.float64(1.97), np.float64(2.21), np.float64(1.25), np.float64(1.5999999999999999), np.float64(3.09), np.float64(1.97), np.float64(2.0999999999999996), np.float64(1.25), np.float64(1.97), np.float64(2.2299999999999995), np.float64(1.49), np.float64(2.91), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(2.8), np.float64(1.48), np.float64(3.17), np.float64(2.4299999999999997), np.float64(1.97), np.float64(2.69), np.float64(2.45), np.float64(3.8900000000000006), np.float64(1.8599999999999999), np.float64(1.71), np.float64(1.25), np.float64(1.49), np.float64(2.69), np.float64(1.2), np.float64(2.38), np.float64(3.4), np.float64(2.4299999999999997), np.float64(2.19), np.float64(2.19), np.float64(3.3899999999999997), np.float64(1.93), np.float64(1.71), np.float64(2.21), np.float64(2.69), np.float64(1.73), np.float64(3.6500000000000004), np.float64(1.73), np.float64(1.72), np.float64(2.45), np.float64(2.45), np.float64(1.97), np.float64(3.41), np.float64(1.2899999999999998), np.float64(1.0), np.float64(0.48), np.float64(1.97), np.float64(2.41), np.float64(2.19), np.float64(0.16999999999999904), np.float64(2.45), np.float64(2.69), np.float64(1.72), np.float64(2.67), np.float64(-0.010000000000001563), np.float64(3.16), np.float64(2.92), np.float64(2.58), np.float64(3.33), np.float64(1.97), np.float64(1.0), np.float64(0.9299999999999997), np.float64(2.69), np.float64(3.3899999999999997), np.float64(0.8199999999999998), np.float64(3.15), np.float64(3.3899999999999997), np.float64(1.25), np.float64(3.17), np.float64(3.3899999999999997), np.float64(0.72), np.float64(3.17), np.float64(1.25), np.float64(1.0), np.float64(1.73), np.float64(1.73), np.float64(2.45), np.float64(3.17), np.float64(2.38), np.float64(2.67), np.float64(2.6799999999999997), np.float64(2.59), np.float64(2.45), np.float64(2.41), np.float64(1.47), np.float64(3.2199999999999998), np.float64(3.1199999999999997), np.float64(2.63), np.float64(1.97), np.float64(1.47), np.float64(2.45), np.float64(2.4699999999999998), np.float64(0.24), np.float64(3.17), np.float64(3.039999999999999), np.float64(1.0), np.float64(1.0799999999999998), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.9299999999999997), np.float64(1.97), np.float64(1.49), np.float64(2.9299999999999997), np.float64(1.0), np.float64(3.5999999999999996), np.float64(3.8900000000000006), np.float64(2.6799999999999997), np.float64(2.9299999999999997), np.float64(2.1499999999999995), np.float64(2.21), np.float64(2.07), np.float64(2.63), np.float64(2.91), np.float64(2.69), np.float64(2.9), np.float64(1.49), np.float64(2.4299999999999997), np.float64(1.71), np.float64(1.1099999999999999), np.float64(1.66), np.float64(1.71), np.float64(1.71), np.float64(2.4299999999999997), np.float64(1.25), np.float64(2.5999999999999996), np.float64(2.6799999999999997), np.float64(2.3899999999999997), np.float64(2.69), np.float64(2.91), np.float64(1.73), np.float64(1.94), np.float64(-13.059999999999885), np.float64(2.5), np.float64(-3.8699999999999877), np.float64(1.73), np.float64(2.2399999999999993), np.float64(2.01), np.float64(1.95), np.float64(2.21), np.float64(1.49), np.float64(1.47), np.float64(2.21), np.float64(1.6099999999999999), np.float64(1.95), np.float64(2.45), np.float64(1.73), np.float64(1.0), np.float64(2.84), np.float64(0.9699999999999995), np.float64(1.25), np.float64(1.3699999999999999), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.73), np.float64(-0.04000000000000159), np.float64(2.4299999999999997), np.float64(3.16), np.float64(1.97), np.float64(2.41), np.float64(2.9299999999999997), np.float64(1.42), np.float64(2.67), np.float64(3.2099999999999995), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.73), np.float64(2.91), np.float64(0.9599999999999991), np.float64(2.19), np.float64(2.45), np.float64(2.19), np.float64(2.69), np.float64(2.21), np.float64(2.45), np.float64(3.41), np.float64(1.25), np.float64(1.95), np.float64(2.21), np.float64(3.17), np.float64(0.0799999999999983), np.float64(1.44), np.float64(2.45), np.float64(1.14), np.float64(-1.4199999999999928), np.float64(2.75), np.float64(2.19), np.float64(-0.17000000000000037), np.float64(2.09), np.float64(1.6099999999999999), np.float64(2.8899999999999997), np.float64(3.12), np.float64(2.41), np.float64(1.49), np.float64(1.73), np.float64(1.95), np.float64(3.17), np.float64(1.6699999999999997), np.float64(3.1399999999999997), np.float64(2.44), np.float64(0.19999999999999996), np.float64(2.62), np.float64(1.49), np.float64(0.8699999999999999), np.float64(1.49), np.float64(2.45), np.float64(1.25), np.float64(2.6399999999999997), np.float64(2.61), np.float64(2.2), np.float64(1.2), np.float64(1.47), np.float64(3.63), np.float64(1.71), np.float64(3.17), np.float64(2.16), np.float64(2.69), np.float64(1.97), np.float64(2.21), np.float64(2.45), np.float64(2.6799999999999997), np.float64(1.47), np.float64(1.18), np.float64(2.88), np.float64(2.21), np.float64(1.73), np.float64(1.25), np.float64(3.13), np.float64(2.9299999999999997), np.float64(1.7199999999999993), np.float64(1.49), np.float64(1.25), np.float64(2.45), np.float64(1.73), np.float64(1.49), np.float64(-10.989999999999956), np.float64(2.69), np.float64(2.69), np.float64(0.3699999999999999), np.float64(3.11), np.float64(2.1799999999999997), np.float64(2.45), np.float64(2.45), np.float64(3.37), np.float64(0.33999999999999897), np.float64(3.17), np.float64(2.45), np.float64(1.68), np.float64(1.68), np.float64(-1.5599999999999943), np.float64(1.16), np.float64(2.69), np.float64(2.8099999999999996), np.float64(1.71), np.float64(1.64), np.float64(1.47), np.float64(-7.249999999999947), np.float64(1.71), np.float64(1.0), np.float64(1.94), np.float64(2.91), np.float64(2.19), np.float64(1.97), np.float64(1.97), np.float64(1.97), np.float64(1.25), np.float64(1.49), np.float64(-1.4699999999999935), np.float64(2.21), np.float64(2.21), np.float64(1.0), np.float64(1.49), np.float64(2.45), np.float64(1.95), np.float64(1.49), np.float64(3.15), np.float64(3.63), np.float64(1.89), np.float64(1.73), np.float64(2.45), np.float64(1.39), np.float64(2.17), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.4299999999999997), np.float64(3.6400000000000006), np.float64(1.97), np.float64(2.69), np.float64(1.2), np.float64(1.97), np.float64(1.5099999999999998), np.float64(3.4), np.float64(1.97), np.float64(2.69), np.float64(0.48), np.float64(1.69), np.float64(2.21), np.float64(1.0), np.float64(0.9999999999999996), np.float64(2.21), np.float64(2.67), np.float64(3.13), np.float64(-0.5999999999999981), np.float64(2.19), np.float64(2.9299999999999997), np.float64(1.64), np.float64(1.89), np.float64(1.25), np.float64(2.67), np.float64(2.4), np.float64(1.73), np.float64(2.2), np.float64(1.25), np.float64(1.49), np.float64(-0.15999999999999992), np.float64(1.97), np.float64(3.15), np.float64(2.45), np.float64(2.1799999999999997), np.float64(1.73), np.float64(1.9099999999999997), np.float64(2.67), np.float64(3.630000000000001), np.float64(2.45), np.float64(0.7799999999999994), np.float64(1.97), np.float64(3.62), np.float64(0.30999999999999983), np.float64(1.73), np.float64(1.41), np.float64(2.21), np.float64(3.17), np.float64(2.58), np.float64(1.73), np.float64(3.41), np.float64(1.47), np.float64(2.6799999999999997), np.float64(1.0199999999999998), np.float64(0.2799999999999996), np.float64(2.9299999999999997), np.float64(2.88), np.float64(2.44), np.float64(1.49), np.float64(2.9299999999999997), np.float64(3.17), np.float64(2.4399999999999995), np.float64(2.69), np.float64(2.1799999999999997), np.float64(2.9299999999999997), np.float64(3.7600000000000033), np.float64(2.9), np.float64(3.04), np.float64(3.4), np.float64(1.72), np.float64(1.47), np.float64(2.4299999999999997), np.float64(1.6999999999999997), np.float64(1.97), np.float64(3.17), np.float64(1.97), np.float64(1.47), np.float64(2.4499999999999997), np.float64(2.69), np.float64(1.95), np.float64(2.45), np.float64(1.16), np.float64(2.17), np.float64(2.57), np.float64(3.6500000000000004), np.float64(3.6500000000000004), np.float64(3.15), np.float64(2.45), np.float64(2.45), np.float64(3.6399999999999997), np.float64(2.91), np.float64(2.44), np.float64(3.41), np.float64(1.9499999999999997), np.float64(2.9299999999999997), np.float64(1.7299999999999998), np.float64(2.69), np.float64(2.21), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.91), np.float64(2.91), np.float64(0.9999999999999989), np.float64(3.2699999999999996), np.float64(3.87), np.float64(2.21), np.float64(1.49), np.float64(2.2), np.float64(2.21), np.float64(1.5999999999999999), np.float64(1.97), np.float64(2.09), np.float64(2.21), np.float64(1.8699999999999999), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.2), np.float64(1.7199999999999998), np.float64(2.45), np.float64(2.69), np.float64(1.25), np.float64(2.45), np.float64(1.49), np.float64(2.65), np.float64(3.08), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.13), np.float64(3.8500000000000005), np.float64(2.69), np.float64(3.3099999999999996), np.float64(1.73), np.float64(1.4499999999999997), np.float64(2.45), np.float64(2.3099999999999996), np.float64(1.73), np.float64(2.83), np.float64(2.69), np.float64(2.3099999999999996), np.float64(1.43), np.float64(-0.46000000000000063), np.float64(1.25), np.float64(2.44), np.float64(1.67), np.float64(3.63), np.float64(1.73), np.float64(3.3), np.float64(2.44), np.float64(1.0), np.float64(-2.159999999999994), np.float64(3.3899999999999997), np.float64(2.09), np.float64(2.69), np.float64(2.45), np.float64(3.41), np.float64(1.25), np.float64(2.6899999999999995), np.float64(2.67), np.float64(1.25), np.float64(2.9299999999999997), np.float64(0.6099999999999999), np.float64(3.6100000000000003), np.float64(2.3), np.float64(2.45), np.float64(2.36), np.float64(2.4299999999999997), np.float64(1.96), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.0), np.float64(2.54), np.float64(0.72), np.float64(2.03), np.float64(1.18), np.float64(1.88), np.float64(3.16), np.float64(2.45), np.float64(1.72), np.float64(2.63), np.float64(1.95), np.float64(2.69), np.float64(2.8499999999999996), np.float64(0.17999999999999972), np.float64(3.41), np.float64(2.69), np.float64(1.73), np.float64(1.97), np.float64(1.7), np.float64(-27.140000000000285), np.float64(1.3900000000000001), np.float64(1.97), np.float64(2.21), np.float64(2.33), np.float64(1.93), np.float64(1.25), np.float64(2.69), np.float64(2.55), np.float64(2.1800000000000006), np.float64(3.63), np.float64(3.41), np.float64(2.9299999999999997), np.float64(3.09), np.float64(1.25), np.float64(1.7), np.float64(3.17), np.float64(2.21), np.float64(2.37), np.float64(3.6899999999999995), np.float64(2.69), np.float64(1.73), np.float64(0.9299999999999995), np.float64(2.21), np.float64(1.93), np.float64(-1.1699999999999946), np.float64(3.8900000000000006), np.float64(1.73), np.float64(2.45), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.67), np.float64(2.42), np.float64(1.73), np.float64(1.73), np.float64(0.5399999999999996), np.float64(2.44), np.float64(3.8900000000000006), np.float64(2.21), np.float64(1.9), np.float64(1.49), np.float64(1.49), np.float64(2.21), np.float64(2.19), np.float64(3.17), np.float64(2.21), np.float64(3.6500000000000004), np.float64(1.18), np.float64(2.17), np.float64(2.1399999999999997), np.float64(1.97), np.float64(2.6799999999999997), np.float64(-0.12000000000000033), np.float64(2.4299999999999997), np.float64(2.66), np.float64(1.3399999999999996), np.float64(1.0), np.float64(1.97), np.float64(2.19), np.float64(2.45), np.float64(2.69), np.float64(2.3899999999999997), np.float64(2.21), np.float64(2.67), np.float64(1.49), np.float64(3.16), np.float64(2.7199999999999998), np.float64(2.45), np.float64(2.21), np.float64(1.72), np.float64(3.59), np.float64(1.95), np.float64(3.41), np.float64(2.9299999999999997), np.float64(2.32), np.float64(1.25), np.float64(1.73), np.float64(2.21), np.float64(2.4299999999999997), np.float64(-4.859999999999984), np.float64(1.71), np.float64(3.32), np.float64(2.8), np.float64(2.41), np.float64(1.25), np.float64(2.67), np.float64(3.63), np.float64(2.4299999999999997), np.float64(1.49), np.float64(1.97), np.float64(1.0), np.float64(2.41), np.float64(2.21), np.float64(2.13), np.float64(2.65), np.float64(2.36), np.float64(3.17), np.float64(1.97), np.float64(2.88), np.float64(2.8899999999999997), np.float64(0.7399999999999989), np.float64(2.67), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.45), np.float64(1.0799999999999998), np.float64(2.8899999999999997), np.float64(1.73), np.float64(1.44), np.float64(2.1999999999999997), np.float64(1.8699999999999999), np.float64(1.0), np.float64(2.45), np.float64(2.45), np.float64(3.13), np.float64(1.5899999999999996), np.float64(1.48), np.float64(1.97), np.float64(2.9299999999999997), np.float64(3.5999999999999996), np.float64(3.1799999999999997), np.float64(2.1799999999999997), np.float64(1.0), np.float64(2.6799999999999997), np.float64(3.3899999999999997), np.float64(2.67), np.float64(1.14), np.float64(3.17), np.float64(2.69), np.float64(2.9), np.float64(2.45), np.float64(3.6500000000000004), np.float64(2.3599999999999994), np.float64(3.6500000000000004), np.float64(1.1399999999999997), np.float64(2.21), np.float64(1.95), np.float64(3.17), np.float64(0.7), np.float64(2.4299999999999997), np.float64(1.4), np.float64(2.16), np.float64(1.97), np.float64(2.21), np.float64(3.15), np.float64(1.97), np.float64(2.69), np.float64(2.21), np.float64(2.67), np.float64(2.69), np.float64(1.25), np.float64(2.69), np.float64(3.33), np.float64(2.9299999999999997), np.float64(2.87), np.float64(3.41), np.float64(2.45), np.float64(2.21), np.float64(3.13), np.float64(2.21), np.float64(1.68), np.float64(1.1199999999999999), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.45), np.float64(1.73), np.float64(2.9299999999999997), np.float64(-1.2799999999999994), np.float64(2.09), np.float64(2.21), np.float64(2.15), np.float64(3.15), np.float64(1.97), np.float64(1.73), np.float64(1.95), np.float64(2.45), np.float64(2.8899999999999997), np.float64(2.45), np.float64(3.16), np.float64(3.8900000000000006), np.float64(3.15), np.float64(2.21), np.float64(3.17), np.float64(2.21), np.float64(3.8900000000000006), np.float64(2.45), np.float64(2.92), np.float64(3.17), np.float64(2.69), np.float64(2.57), np.float64(3.41), np.float64(2.19), np.float64(2.3899999999999997), np.float64(1.95), np.float64(1.92), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.13), np.float64(3.17), np.float64(2.69), np.float64(1.73), np.float64(3.11), np.float64(2.9299999999999997), np.float64(3.6500000000000004), np.float64(1.97), np.float64(1.24), np.float64(1.49), np.float64(2.19), np.float64(3.41), np.float64(2.67), np.float64(3.0599999999999996), np.float64(1.95), np.float64(1.73), np.float64(2.6799999999999997), np.float64(1.2), np.float64(3.3499999999999996), np.float64(3.13), np.float64(1.95), np.float64(1.73), np.float64(2.45), np.float64(2.5599999999999996), np.float64(2.44), np.float64(1.49), np.float64(1.49), np.float64(1.73), np.float64(1.18), np.float64(2.69), np.float64(1.95), np.float64(1.49), np.float64(3.6399999999999997), np.float64(1.25), np.float64(2.1399999999999997), np.float64(2.45), np.float64(3.6399999999999997), np.float64(1.6199999999999999), np.float64(3.59), np.float64(3.41), np.float64(1.14), np.float64(2.19), np.float64(1.73), np.float64(2.67), np.float64(2.9299999999999997), np.float64(3.63), np.float64(2.69), np.float64(2.45), np.float64(3.41), np.float64(2.21), np.float64(2.91), np.float64(2.41), np.float64(1.97), np.float64(2.6400000000000006), np.float64(1.49), np.float64(1.97), np.float64(2.4000000000000004), np.float64(-16.019999999999815), np.float64(1.8399999999999999), np.float64(-0.9699999999999918), np.float64(2.4299999999999997), np.float64(1.97), np.float64(1.6999999999999997), np.float64(1.97), np.float64(2.45), np.float64(3.17), np.float64(2.6799999999999997), np.float64(3.41), np.float64(2.36), np.float64(0.9399999999999993), np.float64(1.0), np.float64(1.0), np.float64(1.73), np.float64(2.17), np.float64(2.21), np.float64(2.21), np.float64(0.96), np.float64(2.4299999999999997), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.65), np.float64(0.94), np.float64(1.97), np.float64(1.5599999999999998), np.float64(1.64), np.float64(2.45), np.float64(2.1799999999999997), np.float64(2.67), np.float64(2.45), np.float64(2.19), np.float64(2.59), np.float64(2.21), np.float64(1.97), np.float64(1.71), np.float64(2.19), np.float64(2.69), np.float64(3.63), np.float64(0.9199999999999999), np.float64(2.45), np.float64(3.62), np.float64(1.49), np.float64(1.49), np.float64(1.66), np.float64(1.25), np.float64(1.73), np.float64(3.63), np.float64(2.65), np.float64(2.45), np.float64(2.41), np.float64(2.21), np.float64(3.17), np.float64(1.73), np.float64(2.21), np.float64(3.37), np.float64(1.73), np.float64(1.7), np.float64(1.97), np.float64(2.84), np.float64(1.49), np.float64(2.45), np.float64(2.76), np.float64(2.19), np.float64(1.97), np.float64(1.95), np.float64(1.49), np.float64(2.21), np.float64(1.73), np.float64(2.21), np.float64(1.68), np.float64(2.0199999999999996), np.float64(2.19), np.float64(1.49), np.float64(3.41), np.float64(1.73), np.float64(2.21), np.float64(2.45), np.float64(3.41), np.float64(2.69), np.float64(1.25), np.float64(2.9), np.float64(0.8400000000000012), np.float64(3.5700000000000003), np.float64(2.65), np.float64(-0.4200000000000004), np.float64(2.69), np.float64(2.45), np.float64(2.21), np.float64(2.9), np.float64(2.21), np.float64(2.21), np.float64(3.87), np.float64(2.88), np.float64(2.67), np.float64(-0.7599999999999998), np.float64(1.49), np.float64(3.16), np.float64(2.21), np.float64(2.15), np.float64(0.0), np.float64(3.6500000000000004), np.float64(1.73), np.float64(2.4299999999999997), np.float64(1.0), np.float64(3.63), np.float64(0.4299999999999995), np.float64(1.8599999999999999), np.float64(2.1399999999999997), np.float64(1.73), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.9), np.float64(1.73), np.float64(1.9499999999999995), np.float64(3.6000000000000005), np.float64(2.4299999999999997), np.float64(1.7799999999999998), np.float64(3.6500000000000004), np.float64(1.96), np.float64(1.49), np.float64(2.41), np.float64(2.45), np.float64(1.49), np.float64(1.97), np.float64(1.0), np.float64(1.41), np.float64(1.47), np.float64(2.45), np.float64(2.21), np.float64(1.2599999999999998), np.float64(2.21), np.float64(1.8699999999999999), np.float64(1.66), np.float64(2.21), np.float64(2.5999999999999996), np.float64(2.21), np.float64(1.49), np.float64(0.25999999999999956), np.float64(2.67), np.float64(3.6500000000000004), np.float64(2.65), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.67), np.float64(2.11), np.float64(2.45), np.float64(1.97), np.float64(1.73), np.float64(2.19), np.float64(3.33), np.float64(0.8599999999999999), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.49), np.float64(3.6000000000000005), np.float64(1.93), np.float64(2.3499999999999996), np.float64(1.49), np.float64(2.65), np.float64(2.3499999999999996), np.float64(-0.5400000000000011), np.float64(1.25), np.float64(2.4299999999999997), np.float64(1.1899999999999997), np.float64(2.69), np.float64(3.41), np.float64(3.6500000000000004), np.float64(1.71), np.float64(3.16), np.float64(2.62), np.float64(2.4000000000000004), np.float64(0.9699999999999998), np.float64(2.42), np.float64(1.7499999999999998), np.float64(1.97), np.float64(2.17), np.float64(2.17), np.float64(2.3899999999999997), np.float64(3.41), np.float64(3.62), np.float64(2.21), np.float64(3.41), np.float64(0.8999999999999999), np.float64(1.25), np.float64(2.45), np.float64(1.73), np.float64(2.17), np.float64(1.71), np.float64(2.6599999999999997), np.float64(2.1999999999999997), np.float64(2.9299999999999997), np.float64(1.97), np.float64(1.73), np.float64(2.0099999999999993), np.float64(3.17), np.float64(1.91), np.float64(2.6799999999999997), np.float64(2.69), np.float64(1.5799999999999998), np.float64(2.75), np.float64(2.4799999999999995), np.float64(3.17), np.float64(2.42), np.float64(3.33), np.float64(2.69), np.float64(1.25), np.float64(2.9299999999999997), np.float64(1.69), np.float64(2.4299999999999997), np.float64(1.48), np.float64(1.93), np.float64(2.2), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.97), np.float64(1.73), np.float64(2.1399999999999997), np.float64(1.95), np.float64(2.0799999999999996), np.float64(1.49), np.float64(1.73), np.float64(2.41), np.float64(1.73), np.float64(1.49), np.float64(1.97), np.float64(2.42), np.float64(0.94), np.float64(2.67), np.float64(1.0), np.float64(2.21), np.float64(2.92), np.float64(3.41), np.float64(1.95), np.float64(2.21), np.float64(3.17), np.float64(1.25), np.float64(1.44), np.float64(2.62), np.float64(3.3899999999999997), np.float64(-0.6200000000000012), np.float64(1.97), np.float64(1.2999999999999987), np.float64(1.2799999999999991), np.float64(1.0), np.float64(1.95), np.float64(3.15), np.float64(2.19), np.float64(2.67), np.float64(0.8299999999999992), np.float64(2.41), np.float64(3.54), np.float64(0.9199999999999999), np.float64(-1.75), np.float64(2.21), np.float64(2.9299999999999997), np.float64(3.3), np.float64(3.1399999999999997), np.float64(1.8699999999999999), np.float64(3.41), np.float64(1.97), np.float64(2.69), np.float64(1.15), np.float64(2.9), np.float64(3.17), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.17), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.91), np.float64(2.45), np.float64(-8.349999999999918), np.float64(1.0), np.float64(0.44000000000000195), np.float64(2.69), np.float64(2.29), np.float64(3.8900000000000006), np.float64(2.44), np.float64(2.45), np.float64(2.34), np.float64(1.95), np.float64(1.7899999999999994), np.float64(2.4399999999999995), np.float64(2.19), np.float64(2.69), np.float64(0.16999999999999993), np.float64(2.69), np.float64(1.0999999999999999), np.float64(2.0999999999999996), np.float64(2.83), np.float64(2.21), np.float64(1.73), np.float64(1.97), np.float64(2.21), np.float64(3.63), np.float64(1.49), np.float64(1.25), np.float64(1.49), np.float64(1.47), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.73), np.float64(3.4), np.float64(0.96), np.float64(1.49), np.float64(2.4299999999999997), np.float64(2.13), np.float64(2.21), np.float64(1.73), np.float64(3.17), np.float64(2.4299999999999997), np.float64(1.25), np.float64(2.6799999999999997), np.float64(3.3499999999999996), np.float64(1.5999999999999999), np.float64(2.69), np.float64(2.4299999999999997), np.float64(2.69), np.float64(3.15), np.float64(2.9299999999999997), np.float64(0.24), np.float64(1.0), np.float64(2.69), np.float64(1.6099999999999999), np.float64(2.67), np.float64(2.45), np.float64(1.97), np.float64(2.32), np.float64(1.25), np.float64(1.0), np.float64(2.8), np.float64(2.4299999999999997), np.float64(2.69), np.float64(1.97), np.float64(2.4299999999999997), np.float64(2.4499999999999997), np.float64(3.88), np.float64(3.38), np.float64(1.49), np.float64(2.69), np.float64(2.45), np.float64(3.880000000000001), np.float64(2.65), np.float64(2.66), np.float64(2.91), np.float64(0.7599999999999996), np.float64(1.24), np.float64(1.49), np.float64(1.69), np.float64(2.21), np.float64(1.71), np.float64(2.91), np.float64(1.8599999999999999), np.float64(2.21), np.float64(1.4299999999999995), np.float64(2.87), np.float64(2.4299999999999997), np.float64(3.1399999999999997), np.float64(1.97), np.float64(2.69), np.float64(2.45), np.float64(2.91), np.float64(2.45), np.float64(1.49), np.float64(1.0), np.float64(2.91), np.float64(2.45), np.float64(0.6399999999999997), np.float64(2.61), np.float64(1.97), np.float64(2.69), np.float64(1.73), np.float64(2.38), np.float64(1.97), np.float64(3.1399999999999997), np.float64(2.19), np.float64(3.6500000000000004), np.float64(1.73), np.float64(3.15), np.float64(2.21), np.float64(2.69), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.44), np.float64(1.73), np.float64(1.25), np.float64(2.21), np.float64(1.48), np.float64(3.15), np.float64(1.1699999999999988), np.float64(1.25), np.float64(1.39), np.float64(2.17), np.float64(2.88), np.float64(3.3899999999999997), np.float64(1.8499999999999999), np.float64(1.1099999999999999), np.float64(3.17), np.float64(3.41), np.float64(2.1799999999999997), np.float64(2.19), np.float64(1.7399999999999998), np.float64(-1.7699999999999951), np.float64(1.97), np.float64(3.17), np.float64(1.97), np.float64(1.73), np.float64(2.45), np.float64(1.3199999999999998), np.float64(1.0), np.float64(2.21), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.97), np.float64(2.63), np.float64(2.4299999999999997), np.float64(2.08), np.float64(1.97), np.float64(3.8900000000000006), np.float64(1.97), np.float64(3.17), np.float64(1.49), np.float64(1.97), np.float64(2.42), np.float64(2.9299999999999997), np.float64(3.8900000000000006), np.float64(2.92), np.float64(1.25), np.float64(2.4299999999999997), np.float64(2.79), np.float64(1.97), np.float64(2.91), np.float64(1.48), np.float64(2.19), np.float64(3.87), np.float64(2.69), np.float64(1.97), np.float64(1.97), np.float64(1.97), np.float64(2.44), np.float64(1.25), np.float64(1.73), np.float64(2.65), np.float64(1.49), np.float64(2.6799999999999997), np.float64(3.3899999999999997), np.float64(2.45), np.float64(2.45), np.float64(1.8599999999999999), np.float64(2.3699999999999997), np.float64(2.4), np.float64(1.73), np.float64(1.97), np.float64(2.69), np.float64(2.1399999999999997), np.float64(3.17), np.float64(2.67), np.float64(2.41), np.float64(2.21), np.float64(0.96), np.float64(2.12), np.float64(2.41), np.float64(2.87), np.float64(1.73), np.float64(2.21), np.float64(2.21), np.float64(1.71), np.float64(1.73), np.float64(1.97), np.float64(2.69), np.float64(1.73), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.67), np.float64(2.19), np.float64(1.71), np.float64(2.21), np.float64(2.67), np.float64(3.6500000000000004), np.float64(2.75), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(3.05), np.float64(3.8900000000000006), np.float64(2.6799999999999997), np.float64(1.23), np.float64(3.63), np.float64(2.69), np.float64(2.69), np.float64(1.68), np.float64(1.63), np.float64(2.67), np.float64(3.63), np.float64(1.69), np.float64(0.5499999999999994), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.19), np.float64(2.5), np.float64(3.17), np.float64(0.8799999999999994), np.float64(1.97), np.float64(2.1799999999999997), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.91), np.float64(2.21), np.float64(2.21), np.float64(3.6500000000000004), np.float64(2.21), np.float64(2.45), np.float64(2.45), np.float64(3.39), np.float64(1.49), np.float64(2.45), np.float64(1.64), np.float64(2.7699999999999996), np.float64(3.41), np.float64(0.99), np.float64(1.95), np.float64(2.69), np.float64(0.2699999999999998), np.float64(1.73), np.float64(1.4), np.float64(2.92), np.float64(2.4799999999999995), np.float64(2.19), np.float64(1.97), np.float64(1.2), np.float64(1.49), np.float64(2.69), np.float64(2.4299999999999997), np.float64(1.8699999999999999), np.float64(2.45), np.float64(1.25), np.float64(2.3899999999999997), np.float64(1.66), np.float64(1.96), np.float64(3.6500000000000004), np.float64(3.37), np.float64(1.97), np.float64(0.98), np.float64(3.0999999999999996), np.float64(0.47), np.float64(1.44), np.float64(1.97), np.float64(2.21), np.float64(1.73), np.float64(2.67), np.float64(1.97), np.float64(0.3699999999999999), np.float64(1.25), np.float64(1.97), np.float64(-1.7199999999999998), np.float64(1.73), np.float64(3.41), np.float64(2.45), np.float64(2.03), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.21), np.float64(1.73), np.float64(2.21), np.float64(1.71), np.float64(-0.08999999999999653), np.float64(2.12), np.float64(2.4299999999999997), np.float64(2.69), np.float64(1.96), np.float64(2.21), np.float64(1.9), np.float64(1.73), np.float64(2.45), np.float64(3.15), np.float64(3.34), np.float64(1.49), np.float64(3.17), np.float64(1.25), np.float64(3.870000000000001), np.float64(2.4299999999999997), np.float64(1.0899999999999999), np.float64(2.91), np.float64(1.97), np.float64(2.69), np.float64(2.69), np.float64(2.0599999999999996), np.float64(1.49), np.float64(3.15), np.float64(1.73), np.float64(3.17), np.float64(2.69), np.float64(3.16), np.float64(1.97), np.float64(3.17), np.float64(2.8199999999999994), np.float64(1.49), np.float64(2.45), np.float64(2.9299999999999997), np.float64(0.24999999999999956), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.45), np.float64(1.95), np.float64(2.21), np.float64(3.41), np.float64(1.95), np.float64(3.16), np.float64(3.0599999999999996), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.41), np.float64(1.49), np.float64(2.45), np.float64(2.19), np.float64(2.45), np.float64(3.8900000000000006), np.float64(2.69), np.float64(2.42), np.float64(2.16), np.float64(2.87), np.float64(2.19), np.float64(0.6499999999999999), np.float64(1.4699999999999998), np.float64(1.46), np.float64(1.0), np.float64(2.44), np.float64(1.97), np.float64(1.25), np.float64(2.45), np.float64(1.25), np.float64(2.7), np.float64(3.39), np.float64(3.6899999999999995), np.float64(2.71), np.float64(1.25), np.float64(0.1299999999999999), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.84), np.float64(1.8199999999999998), np.float64(2.9299999999999997), np.float64(3.4), np.float64(2.44), np.float64(3.6500000000000004), np.float64(2.6799999999999997), np.float64(2.19), np.float64(3.17), np.float64(1.0), np.float64(3.17), np.float64(3.4), np.float64(0.6699999999999999), np.float64(2.69), np.float64(2.45), np.float64(1.71), np.float64(1.49), np.float64(2.21), np.float64(1.49), np.float64(2.19), np.float64(3.41), np.float64(3.41), np.float64(2.92), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.6899999999999995), np.float64(2.45), np.float64(2.21), np.float64(1.14), np.float64(2.21), np.float64(2.69), np.float64(3.15), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(1.49), np.float64(2.0599999999999996), np.float64(2.2), np.float64(1.97), np.float64(1.97), np.float64(2.45), np.float64(2.62), np.float64(3.8600000000000003), np.float64(2.61), np.float64(2.4299999999999997), np.float64(1.71), np.float64(2.88), np.float64(2.08), np.float64(1.97), np.float64(-17.900000000000077), np.float64(1.05), np.float64(2.0999999999999996), np.float64(0.8099999999999996), np.float64(2.55), np.float64(3.17), np.float64(1.49), np.float64(1.49), np.float64(2.17), np.float64(1.92), np.float64(1.1099999999999997), np.float64(2.45), np.float64(2.36), np.float64(2.21), np.float64(2.45), np.float64(2.91), np.float64(2.63), np.float64(2.5199999999999996), np.float64(3.0999999999999996), np.float64(1.7999999999999998), np.float64(1.66), np.float64(2.4699999999999998), np.float64(1.97), np.float64(3.4), np.float64(1.94), np.float64(2.69), np.float64(1.97), np.float64(3.41), np.float64(2.19), np.float64(1.73), np.float64(2.21), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.67), np.float64(1.73), np.float64(2.69), np.float64(2.9299999999999997), np.float64(1.92), np.float64(2.9299999999999997), np.float64(0.44999999999999973), np.float64(3.3899999999999997), np.float64(2.45), np.float64(2.21), np.float64(1.97), np.float64(1.97), np.float64(1.0), np.float64(3.15), np.float64(1.97), np.float64(2.87), np.float64(1.97), np.float64(2.21), np.float64(1.95), np.float64(3.0999999999999996), np.float64(2.21), np.float64(3.63), np.float64(1.73), np.float64(3.41), np.float64(2.21), np.float64(1.1899999999999995), np.float64(2.08), np.float64(0.8899999999999999), np.float64(1.73), np.float64(2.21), np.float64(1.71), np.float64(1.91), np.float64(2.3899999999999997), np.float64(2.65), np.float64(2.11), np.float64(3.8900000000000006), np.float64(2.9299999999999997), np.float64(3.58), np.float64(3.8900000000000006), np.float64(2.4299999999999997), np.float64(3.17), np.float64(3.41), np.float64(3.15), np.float64(1.73), np.float64(3.41), np.float64(3.3899999999999997), np.float64(1.96), np.float64(2.9299999999999997), np.float64(1.73), np.float64(3.8), np.float64(1.0), np.float64(2.19), np.float64(2.8499999999999996), np.float64(3.5999999999999996), np.float64(1.5999999999999999), np.float64(2.66), np.float64(3.17), np.float64(2.21), np.float64(2.44), np.float64(2.67), np.float64(3.3899999999999997), np.float64(2.69), np.float64(2.2), np.float64(2.21), np.float64(1.0199999999999994), np.float64(1.97), np.float64(2.19), np.float64(2.21), np.float64(1.97), np.float64(2.45), np.float64(1.73), np.float64(2.2), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.91), np.float64(3.41), np.float64(1.49), np.float64(1.6199999999999997), np.float64(2.19), np.float64(2.6799999999999997), np.float64(2.9299999999999997), np.float64(1.95), np.float64(1.600000000000001), np.float64(2.21), np.float64(3.17), np.float64(1.25), np.float64(1.49), np.float64(2.11), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.67), np.float64(2.42), np.float64(2.13), np.float64(2.62), np.float64(2.45), np.float64(1.9), np.float64(2.6799999999999997), np.float64(2.8899999999999997), np.float64(0.44999999999999996), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.97), np.float64(1.6099999999999997), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.4299999999999997), np.float64(0.2399999999999991), np.float64(1.92), np.float64(0.3799999999999999), np.float64(2.9), np.float64(1.73), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.4), np.float64(2.2699999999999996), np.float64(2.19), np.float64(2.9299999999999997), np.float64(2.78), np.float64(2.67), np.float64(1.97), np.float64(2.45), np.float64(2.21), np.float64(2.38), np.float64(3.15), np.float64(1.97), np.float64(1.25), np.float64(2.67), np.float64(1.92), np.float64(2.91), np.float64(-1.0999999999999979), np.float64(2.21), np.float64(2.21), np.float64(-0.22999999999999687), np.float64(2.69), np.float64(-0.7999999999999963), np.float64(1.25), np.float64(1.49), np.float64(1.9499999999999997), np.float64(2.69), np.float64(1.72), np.float64(3.6500000000000004), np.float64(2.2399999999999998), np.float64(2.4299999999999997), np.float64(-0.0400000000000007), np.float64(3.17), np.float64(2.51), np.float64(1.49), np.float64(1.3599999999999999), np.float64(2.2), np.float64(2.0199999999999996), np.float64(1.93), np.float64(2.6599999999999993), np.float64(1.95), np.float64(2.67), np.float64(2.19), np.float64(2.67), np.float64(3.17), np.float64(2.9299999999999997), np.float64(3.41), np.float64(2.9299999999999997), np.float64(2.5), np.float64(2.45), np.float64(1.94), np.float64(0.24), np.float64(2.62), np.float64(1.0), np.float64(3.41), np.float64(2.91), np.float64(2.19), np.float64(2.45), np.float64(2.45), np.float64(1.49), np.float64(1.25), np.float64(2.21), np.float64(2.21), np.float64(2.19), np.float64(2.34), np.float64(3.41), np.float64(1.49), np.float64(1.49), np.float64(2.6799999999999997), np.float64(2.45), np.float64(1.72), np.float64(3.17), np.float64(-19.440000000000342), np.float64(2.07), np.float64(1.34), np.float64(2.2), np.float64(0.8999999999999997), np.float64(0.48), np.float64(2.59), np.float64(2.82), np.float64(0.10999999999999965), np.float64(2.67), np.float64(2.45), np.float64(0.6799999999999999), np.float64(1.71), np.float64(2.21), np.float64(2.44), np.float64(1.66), np.float64(0.48), np.float64(1.49), np.float64(2.9), np.float64(1.73), np.float64(1.49), np.float64(2.1699999999999995), np.float64(1.95), np.float64(1.25), np.float64(2.45), np.float64(3.13), np.float64(2.5599999999999996), np.float64(1.25), np.float64(3.59), np.float64(2.45), np.float64(2.4299999999999997), np.float64(1.73), np.float64(1.93), np.float64(-0.5599999999999918), np.float64(2.5999999999999996), np.float64(1.3699999999999999), np.float64(1.0), np.float64(2.86), np.float64(1.73), np.float64(1.25), np.float64(1.49), np.float64(1.47), np.float64(2.01), np.float64(2.63), np.float64(2.9299999999999997), np.float64(1.68), np.float64(1.25), np.float64(3.16), np.float64(1.25), np.float64(2.2), np.float64(-1.9799999999999995), np.float64(2.92), np.float64(1.73), np.float64(1.25), np.float64(1.42), np.float64(1.73), np.float64(3.63), np.float64(2.16), np.float64(1.97), np.float64(1.73), np.float64(2.8899999999999997), np.float64(1.73), np.float64(1.95), np.float64(3.17), np.float64(1.97), np.float64(2.67), np.float64(2.69), np.float64(-5.059999999999977), np.float64(1.25), np.float64(1.47), np.float64(1.73), np.float64(1.7199999999999998), np.float64(1.4999999999999998), np.float64(2.9399999999999995), np.float64(2.01), np.float64(2.21), np.float64(2.87), np.float64(1.97), np.float64(2.67), np.float64(2.91), np.float64(3.4), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(2.45), np.float64(3.35), np.float64(2.45), np.float64(1.49), np.float64(2.67), np.float64(2.16), np.float64(2.45), np.float64(2.21), np.float64(2.6399999999999997), np.float64(2.3), np.float64(1.97), np.float64(2.19), np.float64(1.4), np.float64(1.73), np.float64(1.73), np.float64(1.95), np.float64(2.38), np.float64(2.34), np.float64(2.69), np.float64(3.3899999999999997), np.float64(1.93), np.float64(1.0), np.float64(1.49), np.float64(2.69), np.float64(2.21), np.float64(3.63), np.float64(3.8600000000000003), np.float64(1.25), np.float64(2.45), np.float64(2.45), np.float64(1.95), np.float64(2.19), np.float64(3.41), np.float64(1.97), np.float64(2.4), np.float64(1.97), np.float64(1.71), np.float64(3.17), np.float64(1.45), np.float64(2.21), np.float64(2.45), np.float64(2.45), np.float64(1.71), np.float64(2.21), np.float64(2.67), np.float64(2.66), np.float64(1.97), np.float64(2.44), np.float64(1.89), np.float64(1.6899999999999997), np.float64(1.49), np.float64(2.19), np.float64(1.49), np.float64(2.69), np.float64(1.47), np.float64(2.5199999999999996), np.float64(3.13), np.float64(2.45), np.float64(1.25), np.float64(2.21), np.float64(2.67), np.float64(1.95), np.float64(2.21), np.float64(2.0999999999999996), np.float64(2.69), np.float64(2.3899999999999997), np.float64(2.6799999999999997), np.float64(2.41), np.float64(3.3899999999999997), np.float64(1.73), np.float64(2.65), np.float64(1.73), np.float64(2.9), np.float64(2.58), np.float64(2.21), np.float64(1.97), np.float64(2.9399999999999995), np.float64(1.97), np.float64(2.15), np.float64(2.45), np.float64(3.07), np.float64(3.15), np.float64(1.92), np.float64(2.04), np.float64(2.41), np.float64(3.16), np.float64(2.69), np.float64(2.67), np.float64(2.45), np.float64(1.25), np.float64(2.21), np.float64(2.1399999999999997), np.float64(2.8899999999999997), np.float64(2.44), np.float64(1.0), np.float64(1.73), np.float64(1.25), np.float64(2.19), np.float64(2.8899999999999997), np.float64(1.3899999999999997), np.float64(2.41), np.float64(1.25), np.float64(1.44), np.float64(1.97), np.float64(1.97), np.float64(3.6500000000000004), np.float64(2.67), np.float64(-21.96000000000029), np.float64(3.17), np.float64(1.67), np.float64(2.9299999999999997), np.float64(1.25), np.float64(-0.3100000000000003), np.float64(1.49), np.float64(2.69), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.0), np.float64(2.9299999999999997), np.float64(2.67), np.float64(2.1799999999999997), np.float64(1.73), np.float64(2.7500000000000053), np.float64(2.91), np.float64(1.73), np.float64(1.49), np.float64(3.15), np.float64(1.73), np.float64(2.21), np.float64(0.03999999999999937), np.float64(2.45), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.69), np.float64(3.17), np.float64(1.92), np.float64(2.45), np.float64(1.73), np.float64(1.9), np.float64(2.38), np.float64(3.6500000000000004), np.float64(1.73), np.float64(2.21), np.float64(1.25), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(1.3699999999999999), np.float64(1.96), np.float64(1.95), np.float64(2.13), np.float64(2.21), np.float64(3.41), np.float64(2.9299999999999997), np.float64(3.15), np.float64(3.17), np.float64(1.97), np.float64(2.69), np.float64(2.8699999999999997), np.float64(2.37), np.float64(1.97), np.float64(2.69), np.float64(-1.0799999999999939), np.float64(1.71), np.float64(2.9299999999999997), np.float64(0.20000000000000195), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.91), np.float64(1.93), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.0), np.float64(3.17), np.float64(1.0), np.float64(1.97), np.float64(1.97), np.float64(1.73), np.float64(2.12), np.float64(2.13), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.67), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.6799999999999997), np.float64(1.8499999999999999), np.float64(2.69), np.float64(3.41), np.float64(3.41), np.float64(1.49), np.float64(2.3199999999999994), np.float64(2.69), np.float64(-0.24000000000000044), np.float64(2.42), np.float64(2.67), np.float64(3.05), np.float64(3.15), np.float64(1.69), np.float64(1.42), np.float64(1.47), np.float64(2.42), np.float64(3.17), np.float64(2.08), np.float64(2.17), np.float64(2.45), np.float64(2.45), np.float64(-4.7999999999999785), np.float64(2.03), np.float64(1.17), np.float64(-26.730000000000437), np.float64(2.1199999999999997), np.float64(2.69), np.float64(0.7799999999999996), np.float64(1.69), np.float64(1.25), np.float64(3.15), np.float64(1.49), np.float64(-1.5199999999999996), np.float64(1.73), np.float64(2.45), np.float64(1.71), np.float64(1.73), np.float64(2.2399999999999998), np.float64(2.69), np.float64(1.97), np.float64(2.4299999999999997), np.float64(1.96), np.float64(2.87), np.float64(3.8500000000000005), np.float64(2.45), np.float64(2.91), np.float64(1.64), np.float64(2.19), np.float64(1.47), np.float64(3.15), np.float64(3.8900000000000006), np.float64(2.15), np.float64(2.41), np.float64(1.25), np.float64(1.47), np.float64(2.45), np.float64(1.0), np.float64(2.0699999999999994), np.float64(1.0), np.float64(1.96), np.float64(0.17999999999999994), np.float64(2.84), np.float64(3.17), np.float64(2.19), np.float64(3.6500000000000004), np.float64(1.2), np.float64(2.91), np.float64(1.16), np.float64(3.6500000000000004), np.float64(2.15), np.float64(2.63), np.float64(1.49), np.float64(1.97), np.float64(2.44), np.float64(2.21), np.float64(2.65), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.6799999999999997), np.float64(2.9299999999999997), np.float64(2.91), np.float64(3.3), np.float64(1.71), np.float64(2.19), np.float64(2.69), np.float64(1.72), np.float64(3.17), np.float64(2.65), np.float64(1.49), np.float64(2.45), np.float64(2.69), np.float64(1.91), np.float64(1.89), np.float64(1.25), np.float64(2.65), np.float64(2.21), np.float64(1.89), np.float64(1.25), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(3.16), np.float64(2.67), np.float64(3.17), np.float64(2.45), np.float64(1.25), np.float64(3.41), np.float64(3.41), np.float64(1.63), np.float64(3.6100000000000003), np.float64(3.17), np.float64(2.21), np.float64(2.53), np.float64(2.69), np.float64(3.17), np.float64(2.21), np.float64(2.69), np.float64(2.69), np.float64(3.87), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.67), np.float64(1.95), np.float64(3.41), np.float64(2.21), np.float64(2.69), np.float64(1.97), np.float64(1.25), np.float64(1.97), np.float64(1.0), np.float64(2.61), np.float64(1.49), np.float64(3.3899999999999997), np.float64(1.73), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.21), np.float64(1.49), np.float64(1.3199999999999998), np.float64(2.17), np.float64(1.97), np.float64(1.73), np.float64(2.69), np.float64(2.19), np.float64(2.21), np.float64(3.63), np.float64(1.71), np.float64(2.92), np.float64(0.72), np.float64(1.6199999999999999), np.float64(2.44), np.float64(2.69), np.float64(3.4099999999999997), np.float64(2.69), np.float64(2.4899999999999998), np.float64(1.73), np.float64(1.25), np.float64(2.0199999999999996), np.float64(1.73), np.float64(1.73), np.float64(2.69), np.float64(1.25), np.float64(2.3099999999999996), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.21), np.float64(0.7), np.float64(1.97), np.float64(3.62), np.float64(1.97), np.float64(2.16), np.float64(1.9899999999999998), np.float64(1.71), np.float64(2.64), np.float64(3.41), np.float64(2.16), np.float64(1.73), np.float64(1.97), np.float64(1.49), np.float64(2.91), np.float64(1.49), np.float64(1.0), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.4699999999999998), np.float64(1.97), np.float64(3.63), np.float64(1.73), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.97), np.float64(3.63), np.float64(1.25), np.float64(2.69), np.float64(1.73), np.float64(1.49), np.float64(3.41), np.float64(1.0), np.float64(2.59), np.float64(1.97), np.float64(2.12), np.float64(1.25), np.float64(2.38), np.float64(1.73), np.float64(1.97), np.float64(3.17), np.float64(3.0999999999999996), np.float64(1.18), np.float64(1.97), np.float64(1.94), np.float64(3.17), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.91), np.float64(1.97), np.float64(1.97), np.float64(1.97), np.float64(2.69), np.float64(1.25), np.float64(2.21), np.float64(2.69), np.float64(1.73), np.float64(1.97), np.float64(2.15), np.float64(1.47), np.float64(3.3899999999999997), np.float64(2.17), np.float64(2.63), np.float64(3.8900000000000006), np.float64(2.21), np.float64(1.72), np.float64(2.69), np.float64(2.21), np.float64(3.3899999999999997), np.float64(2.9799999999999995), np.float64(2.67), np.float64(2.87), np.float64(3.17), np.float64(0.72), np.float64(3.1399999999999997), np.float64(3.6500000000000004), np.float64(2.91), np.float64(1.49), np.float64(2.2399999999999998), np.float64(2.69), np.float64(2.21), np.float64(2.2), np.float64(2.2), np.float64(1.25), np.float64(1.88), np.float64(2.01), np.float64(2.45), np.float64(1.49), np.float64(2.21), np.float64(1.2099999999999995), np.float64(3.17), np.float64(1.49), np.float64(2.19), np.float64(2.7299999999999995), np.float64(2.2699999999999996), np.float64(2.69), np.float64(2.69), np.float64(2.84), np.float64(2.9299999999999997), np.float64(2.38), np.float64(2.9), np.float64(3.3899999999999997), np.float64(3.17), np.float64(2.69), np.float64(1.0), np.float64(3.17), np.float64(2.1799999999999997), np.float64(2.69), np.float64(1.73), np.float64(3.17), np.float64(2.21), np.float64(2.75), np.float64(3.8900000000000006), np.float64(2.21), np.float64(1.25), np.float64(2.9299999999999997), np.float64(3.15), np.float64(1.73), np.float64(1.97), np.float64(2.69), np.float64(1.97), np.float64(1.73), np.float64(2.21), np.float64(2.3999999999999995), np.float64(0.16999999999999993), np.float64(1.97), np.float64(2.69), np.float64(2.91), np.float64(3.6500000000000004), np.float64(2.21), np.float64(1.23), np.float64(1.97), np.float64(-20.280000000000097), np.float64(2.25), np.float64(1.73), np.float64(1.6399999999999988), np.float64(1.73), np.float64(1.25), np.float64(2.63), np.float64(1.0), np.float64(2.21), np.float64(1.0), np.float64(0.39999999999999836), np.float64(1.97), np.float64(3.6500000000000004), np.float64(1.64), np.float64(3.15), np.float64(1.97), np.float64(2.21), np.float64(2.87), np.float64(1.25), np.float64(1.97), np.float64(2.45), np.float64(1.97), np.float64(2.69), np.float64(2.21), np.float64(3.17), np.float64(2.91), np.float64(1.73), np.float64(2.21), np.float64(2.66), np.float64(2.44), np.float64(2.45), np.float64(3.17), np.float64(2.69), np.float64(3.17), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.93), np.float64(2.19), np.float64(2.9299999999999997), np.float64(2.67), np.float64(0.45999999999999996), np.float64(1.6199999999999999), np.float64(3.17), np.float64(2.45), np.float64(2.65), np.float64(1.73), np.float64(3.63), np.float64(1.25), np.float64(2.69), np.float64(1.73), np.float64(2.9299999999999997), np.float64(-11.69999999999991), np.float64(2.9299999999999997), np.float64(3.33), np.float64(0.9199999999999999), np.float64(-0.0600000000000005), np.float64(2.08), np.float64(1.49), np.float64(2.44), np.float64(2.9299999999999997), np.float64(2.69), np.float64(1.73), np.float64(2.69), np.float64(2.62), np.float64(3.019999999999999), np.float64(2.11), np.float64(1.49), np.float64(2.11), np.float64(-0.37000000000000055), np.float64(3.41), np.float64(2.45), np.float64(2.8099999999999996), np.float64(3.41), np.float64(1.97), np.float64(3.41), np.float64(0.43999999999999995), np.float64(1.97), np.float64(3.2299999999999995), np.float64(3.17), np.float64(2.86), np.float64(2.4299999999999997), np.float64(2.45), np.float64(1.49), np.float64(2.9499999999999997), np.float64(1.49), np.float64(2.69), np.float64(1.95), np.float64(2.21), np.float64(0.19999999999999996), np.float64(2.69), np.float64(2.9299999999999997), np.float64(-2.859999999999986), np.float64(0.5999999999999996), np.float64(1.67), np.float64(2.21), np.float64(0.7399999999999998), np.float64(2.1999999999999997), np.float64(1.25), np.float64(2.21), np.float64(1.49), np.float64(0.69), np.float64(2.8099999999999996), np.float64(1.25), np.float64(1.0), np.float64(2.21), np.float64(2.69), np.float64(1.2), np.float64(1.97), np.float64(2.91), np.float64(1.93), np.float64(1.73), np.float64(2.11), np.float64(2.3999999999999995), np.float64(1.95), np.float64(1.9199999999999997), np.float64(2.1199999999999997), np.float64(1.97), np.float64(1.16), np.float64(2.69), np.float64(1.16), np.float64(1.66), np.float64(1.0), np.float64(2.69), np.float64(2.69), np.float64(2.21), np.float64(2.76), np.float64(1.8299999999999998), np.float64(3.87), np.float64(2.61), np.float64(1.73), np.float64(3.15), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.95), np.float64(2.45), np.float64(2.91), np.float64(0.94), np.float64(1.0499999999999996), np.float64(-0.33000000000000007), np.float64(1.9), np.float64(2.75), np.float64(1.95), np.float64(3.4), np.float64(1.49), np.float64(1.25), np.float64(2.12), np.float64(1.97), np.float64(2.45), np.float64(2.69), np.float64(1.44), np.float64(3.41), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(2.69), np.float64(1.0), np.float64(3.8900000000000006), np.float64(1.97), np.float64(3.36), np.float64(1.97), np.float64(2.21), np.float64(1.5599999999999998), np.float64(0.3999999999999999), np.float64(2.0199999999999996), np.float64(1.97), np.float64(1.49), np.float64(2.67), np.float64(1.0299999999999998), np.float64(2.69), np.float64(2.21), np.float64(2.45), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.17), np.float64(1.71), np.float64(1.16), np.float64(2.2), np.float64(1.25), np.float64(2.67), np.float64(1.97), np.float64(2.92), np.float64(3.17), np.float64(-0.30000000000000004), np.float64(2.19), np.float64(1.16), np.float64(3.41), np.float64(2.45), np.float64(3.41), np.float64(3.37), np.float64(1.66), np.float64(2.21), np.float64(1.25), np.float64(3.3), np.float64(2.4099999999999997), np.float64(2.16), np.float64(1.73), np.float64(0.71), np.float64(1.67), np.float64(1.25), np.float64(1.97), np.float64(0.19999999999999996), np.float64(1.48), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.25), np.float64(3.6500000000000004), np.float64(3.41), np.float64(2.45), np.float64(2.67), np.float64(2.67), np.float64(2.19), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.21), np.float64(3.17), np.float64(3.6500000000000004), np.float64(1.6199999999999999), np.float64(1.8399999999999999), np.float64(2.41), np.float64(2.9299999999999997), np.float64(2.67), np.float64(1.49), np.float64(1.73), np.float64(2.91), np.float64(3.870000000000001), np.float64(2.4299999999999997), np.float64(1.72), np.float64(1.97), np.float64(2.67), np.float64(1.95), np.float64(3.17), np.float64(3.41), np.float64(2.9299999999999997), np.float64(3.3899999999999997), np.float64(2.4299999999999997), np.float64(1.97), np.float64(1.0), np.float64(2.92), np.float64(2.61), np.float64(3.1399999999999997), np.float64(1.95), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.69), np.float64(1.97), np.float64(1.97), np.float64(2.1399999999999997), np.float64(2.69), np.float64(2.6799999999999997), np.float64(1.97), np.float64(3.1399999999999997), np.float64(3.11), np.float64(1.25), np.float64(1.73), np.float64(2.69), np.float64(3.3899999999999997), np.float64(1.25), np.float64(2.69), np.float64(2.21), np.float64(1.42), np.float64(2.9299999999999997), np.float64(3.15), np.float64(3.15), np.float64(-3.0699999999999834), np.float64(2.4299999999999997), np.float64(3.15), np.float64(1.49), np.float64(2.67), np.float64(3.6500000000000004), np.float64(3.13), np.float64(2.8899999999999997), np.float64(3.6500000000000004), np.float64(3.17), np.float64(2.36), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.4699999999999998), np.float64(3.6500000000000004), np.float64(3.17), np.float64(2.91), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.97), np.float64(3.1399999999999997), np.float64(3.41), np.float64(2.69), np.float64(2.34), np.float64(2.29), np.float64(2.11), np.float64(2.91), np.float64(2.45), np.float64(1.97), np.float64(2.67), np.float64(3.880000000000001), np.float64(2.44), np.float64(3.0999999999999996), np.float64(3.07), np.float64(1.71), np.float64(1.64), np.float64(3.3899999999999997), np.float64(3.4899999999999998), np.float64(2.07), np.float64(2.21), np.float64(2.67), np.float64(2.19), np.float64(1.71), np.float64(3.6500000000000004), np.float64(2.41), np.float64(0.7), np.float64(2.9299999999999997), np.float64(3.41), np.float64(2.45), np.float64(3.41), np.float64(3.17), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(3.6500000000000004), np.float64(2.6799999999999997), np.float64(3.41), np.float64(2.58), np.float64(2.36), np.float64(2.44), np.float64(2.21), np.float64(1.97), np.float64(2.58), np.float64(1.47), np.float64(3.41), np.float64(1.0), np.float64(1.97), np.float64(1.8099999999999998), np.float64(2.21), np.float64(2.45), np.float64(2.19), np.float64(2.9), np.float64(1.73), np.float64(2.45), np.float64(3.41), np.float64(3.17), np.float64(1.0), np.float64(2.67), np.float64(2.2), np.float64(2.45), np.float64(2.69), np.float64(1.73), np.float64(2.19), np.float64(3.17), np.float64(3.88), np.float64(1.0499999999999998), np.float64(3.17), np.float64(2.9299999999999997), np.float64(3.13), np.float64(1.47), np.float64(1.97), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.19), np.float64(1.73), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.1799999999999997), np.float64(3.17), np.float64(2.45), np.float64(1.73), np.float64(1.6099999999999999), np.float64(2.69), np.float64(2.8899999999999997), np.float64(2.21), np.float64(1.47), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.69), np.float64(2.38), np.float64(1.49), np.float64(1.1299999999999997), np.float64(1.97), np.float64(1.0199999999999998), np.float64(3.6500000000000004), np.float64(0.94), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.12), np.float64(2.63), np.float64(1.25), np.float64(0.5899999999999987), np.float64(2.21), np.float64(1.49), np.float64(1.47), np.float64(3.16), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.73), np.float64(1.6699999999999997), np.float64(2.21), np.float64(3.15), np.float64(1.49), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.66), np.float64(2.66), np.float64(0.3599999999999999), np.float64(2.92), np.float64(1.49), np.float64(1.25), np.float64(1.25), np.float64(2.91), np.float64(2.69), np.float64(2.69), np.float64(-12.1899999999999), np.float64(1.8299999999999998), np.float64(2.21), np.float64(1.8399999999999999), np.float64(2.9299999999999997), np.float64(1.0), np.float64(0.3999999999999999), np.float64(2.65), np.float64(3.41), np.float64(0.32000000000000006), np.float64(3.41), np.float64(2.67), np.float64(1.73), np.float64(3.38), np.float64(1.95), np.float64(1.71), np.float64(3.17), np.float64(1.44), np.float64(1.93), np.float64(0.9199999999999999), np.float64(2.45), np.float64(1.73), np.float64(2.9), np.float64(1.3099999999999998), np.float64(2.15), np.float64(1.47), np.float64(2.21), np.float64(1.42), np.float64(2.21), np.float64(2.03), np.float64(1.25), np.float64(2.19), np.float64(1.71), np.float64(3.8500000000000005), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.12), np.float64(2.8499999999999996), np.float64(2.69), np.float64(0.9299999999999999), np.float64(2.69), np.float64(2.21), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.92), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.8), np.float64(3.87), np.float64(2.4), np.float64(2.9299999999999997), np.float64(1.92), np.float64(3.62), np.float64(0.96), np.float64(3.16), np.float64(3.51), np.float64(2.45), np.float64(3.41), np.float64(2.91), np.float64(1.72), np.float64(1.97), np.float64(2.21), np.float64(2.21), np.float64(1.89), np.float64(2.63), np.float64(2.4299999999999997), np.float64(3.4000000000000004), np.float64(2.4299999999999997), np.float64(1.0), np.float64(1.25), np.float64(2.33), np.float64(1.63), np.float64(1.3599999999999999), np.float64(1.71), np.float64(1.49), np.float64(3.6500000000000004), np.float64(2.69), np.float64(2.45), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.25), np.float64(2.21), np.float64(1.49), np.float64(1.73), np.float64(3.16), np.float64(3.6500000000000004), np.float64(1.69), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(3.17), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.15), np.float64(3.6500000000000004), np.float64(2.61), np.float64(1.95), np.float64(2.4299999999999997), np.float64(2.1999999999999997), np.float64(2.69), np.float64(1.71), np.float64(-0.7499999999999967), np.float64(1.25), np.float64(0.48), np.float64(3.17), np.float64(1.97), np.float64(3.17), np.float64(2.2), np.float64(1.73), np.float64(3.8900000000000006), np.float64(2.65), np.float64(1.49), np.float64(2.21), np.float64(3.17), np.float64(1.91), np.float64(2.21), np.float64(3.6500000000000004), np.float64(1.49), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(2.21), np.float64(1.96), np.float64(3.8900000000000006), np.float64(3.17), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.17), np.float64(1.66), np.float64(1.17), np.float64(1.9799999999999995), np.float64(2.21), np.float64(1.97), np.float64(2.45), np.float64(1.23), np.float64(2.8000000000000025), np.float64(1.71), np.float64(2.67), np.float64(1.73), np.float64(1.97), np.float64(2.19), np.float64(2.21), np.float64(2.3899999999999997), np.float64(2.45), np.float64(3.17), np.float64(2.21), np.float64(2.45), np.float64(1.0), np.float64(2.69), np.float64(3.0), np.float64(1.73), np.float64(1.71), np.float64(3.17), np.float64(1.93), np.float64(2.42), np.float64(0.3800000000000001), np.float64(2.91), np.float64(2.19), np.float64(2.11), np.float64(3.17), np.float64(2.88), np.float64(1.93), np.float64(1.95), np.float64(2.9299999999999997), np.float64(1.5499999999999998), np.float64(2.21), np.float64(0.72), np.float64(3.17), np.float64(3.63), np.float64(2.4), np.float64(1.49), np.float64(1.49), np.float64(2.6799999999999997), np.float64(3.0), np.float64(1.25), np.float64(1.67), np.float64(2.69), np.float64(1.97), np.float64(1.73), np.float64(2.45), np.float64(1.25), np.float64(3.6399999999999997), np.float64(1.2099999999999995), np.float64(2.67), np.float64(2.03), np.float64(3.6500000000000004), np.float64(2.67), np.float64(3.4), np.float64(1.25), np.float64(2.16), np.float64(1.25), np.float64(3.15), np.float64(1.71), np.float64(1.49), np.float64(2.45), np.float64(1.44), np.float64(1.2), np.float64(1.73), np.float64(2.17), np.float64(3.63), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.5399999999999998), np.float64(3.6000000000000005), np.float64(2.1799999999999997), np.float64(3.13), np.float64(2.9499999999999997), np.float64(1.73), np.float64(3.17), np.float64(3.6500000000000004), np.float64(2.45), np.float64(3.17), np.float64(1.94), np.float64(2.21), np.float64(1.97), np.float64(1.73), np.float64(2.91), np.float64(1.4), np.float64(2.21), np.float64(1.71), np.float64(1.97), np.float64(1.68), np.float64(1.49), np.float64(1.25), np.float64(3.07), np.float64(1.25), np.float64(2.45), np.float64(2.3899999999999997), np.float64(2.45), np.float64(2.21), np.float64(-5.619999999999938), np.float64(1.73), np.float64(2.55), np.float64(1.73), np.float64(1.49), np.float64(2.45), np.float64(2.66), np.float64(-9.139999999999954), np.float64(2.21), np.float64(1.4399999999999997), np.float64(2.17), np.float64(2.38), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.21), np.float64(2.19), np.float64(2.61), np.float64(1.73), np.float64(-0.7099999999999913), np.float64(2.4299999999999997), np.float64(3.08), np.float64(2.45), np.float64(1.1399999999999997), np.float64(2.87), np.float64(3.4), np.float64(1.49), np.float64(1.49), np.float64(3.17), np.float64(1.73), np.float64(2.91), np.float64(1.97), np.float64(3.4000000000000004), np.float64(2.6799999999999997), np.float64(1.88), np.float64(2.69), np.float64(2.28), np.float64(3.17), np.float64(2.4299999999999997), np.float64(1.42), np.float64(1.95), np.float64(1.73), np.float64(2.21), np.float64(2.45), np.float64(3.6500000000000004), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.9299999999999997), np.float64(3.15), np.float64(2.19), np.float64(3.3899999999999997), np.float64(2.4299999999999997), np.float64(2.4299999999999997), np.float64(1.73), np.float64(1.5699999999999998), np.float64(3.16), np.float64(1.49), np.float64(2.2), np.float64(1.67), np.float64(2.21), np.float64(1.64), np.float64(2.69), np.float64(1.97), np.float64(2.19), np.float64(2.45), np.float64(3.15), np.float64(3.63), np.float64(1.7399999999999993), np.float64(3.3899999999999997), np.float64(1.71), np.float64(2.69), np.float64(2.92), np.float64(1.73), np.float64(2.21), np.float64(2.91), np.float64(2.4299999999999997), np.float64(1.7899999999999998), np.float64(2.21), np.float64(2.21), np.float64(2.69), np.float64(2.45), np.float64(2.4099999999999997), np.float64(2.21), np.float64(2.91), np.float64(1.66), np.float64(2.69), np.float64(1.95), np.float64(3.63), np.float64(2.45), np.float64(1.97), np.float64(1.95), np.float64(1.71), np.float64(1.49), np.float64(2.45), np.float64(3.63), np.float64(1.71), np.float64(1.48), np.float64(1.95), np.float64(3.15), np.float64(2.6799999999999997), np.float64(3.8600000000000003), np.float64(1.25), np.float64(2.4299999999999997), np.float64(-1.2099999999999964), np.float64(2.41), np.float64(3.17), np.float64(1.97), np.float64(2.15), np.float64(2.69), np.float64(0.96), np.float64(2.69), np.float64(2.19), np.float64(2.6799999999999997), np.float64(3.41), np.float64(0.94), np.float64(2.38), np.float64(1.45), np.float64(1.95), np.float64(1.97), np.float64(1.65), np.float64(1.97), np.float64(2.8099999999999996), np.float64(2.69), np.float64(3.41), np.float64(3.3899999999999997), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(-1.8299999999999788), np.float64(1.49), np.float64(3.17), np.float64(2.44), np.float64(2.91), np.float64(2.17), np.float64(1.71), np.float64(1.42), np.float64(2.38), np.float64(1.49), np.float64(3.6500000000000004), np.float64(1.49), np.float64(1.73), np.float64(1.25), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.2), np.float64(3.41), np.float64(1.97), np.float64(3.41), np.float64(2.84), np.float64(3.37), np.float64(2.19), np.float64(3.41), np.float64(3.6500000000000004), np.float64(1.73), np.float64(3.6500000000000004), np.float64(2.45), np.float64(1.47), np.float64(2.44), np.float64(1.25), np.float64(2.69), np.float64(1.95), np.float64(1.49), np.float64(3.41), np.float64(1.71), np.float64(2.69), np.float64(1.71), np.float64(2.41), np.float64(2.45), np.float64(2.45), np.float64(2.21), np.float64(1.97), np.float64(2.38), np.float64(1.73), np.float64(2.45), np.float64(2.91), np.float64(2.41), np.float64(1.0), np.float64(2.19), np.float64(0.72), np.float64(1.9), np.float64(1.49), np.float64(1.73), np.float64(1.73), np.float64(2.9299999999999997), np.float64(3.41), np.float64(1.49), np.float64(1.49), np.float64(2.19), np.float64(3.3899999999999997), np.float64(2.21), np.float64(1.97), np.float64(0.640000000000001), np.float64(2.4299999999999997), np.float64(0.72), np.float64(1.5999999999999999), np.float64(3.41), np.float64(1.25), np.float64(2.45), np.float64(2.45), np.float64(2.45), np.float64(2.6799999999999997), np.float64(3.16), np.float64(3.12), np.float64(1.25), np.float64(1.93), np.float64(2.69), np.float64(1.44), np.float64(2.91), np.float64(1.25), np.float64(3.41), np.float64(3.6399999999999997), np.float64(2.19), np.float64(2.21), np.float64(3.3899999999999997), np.float64(1.9), np.float64(1.49), np.float64(3.6500000000000004), np.float64(2.21), np.float64(2.5999999999999996), np.float64(1.49), np.float64(3.11), np.float64(2.42), np.float64(2.45), np.float64(2.92), np.float64(3.17), np.float64(2.41), np.float64(2.4299999999999997), np.float64(0.72), np.float64(1.0), np.float64(2.21), np.float64(-23.9400000000003), np.float64(1.49), np.float64(1.47), np.float64(2.4299999999999997), np.float64(2.59), np.float64(3.17), np.float64(1.95), np.float64(2.12), np.float64(2.67), np.float64(0.9500000000000015), np.float64(2.19), np.float64(2.1799999999999997), np.float64(1.25), np.float64(3.6400000000000006), np.float64(-1.4299999999999997), np.float64(1.49), np.float64(3.17), np.float64(3.59), np.float64(1.97), np.float64(1.68), np.float64(0.5799999999999998), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.41), np.float64(3.0599999999999996), np.float64(1.6199999999999999), np.float64(1.66), np.float64(1.25), np.float64(2.36), np.float64(2.21), np.float64(1.1899999999999995), np.float64(2.9299999999999997), np.float64(3.17), np.float64(2.69), np.float64(1.49), np.float64(2.62), np.float64(2.45), np.float64(1.73), np.float64(2.8899999999999997), np.float64(3.37), np.float64(0.11999999999999988), np.float64(2.8499999999999996), np.float64(2.9299999999999997), np.float64(2.69), np.float64(1.73), np.float64(1.97), np.float64(1.7), np.float64(2.21), np.float64(1.97), np.float64(2.45), np.float64(0.24), np.float64(1.97), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.69), np.float64(2.45), np.float64(1.49), np.float64(3.3899999999999997), np.float64(3.63), np.float64(-9.539999999999951), np.float64(3.39), np.float64(3.08), np.float64(3.8900000000000006), np.float64(1.97), np.float64(2.45), np.float64(2.69), np.float64(0.9099999999999995), np.float64(3.630000000000001), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.25), np.float64(1.73), np.float64(1.97), np.float64(2.9), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.71), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.6799999999999997), np.float64(3.41), np.float64(1.73), np.float64(1.64), np.float64(2.1399999999999997), np.float64(2.69), np.float64(1.42), np.float64(2.87), np.float64(2.21), np.float64(3.15), np.float64(1.25), np.float64(2.91), np.float64(1.9), np.float64(2.19), np.float64(2.6100000000000003), np.float64(1.95), np.float64(1.49), np.float64(2.6799999999999997), np.float64(1.88), np.float64(2.21), np.float64(1.49), np.float64(1.71), np.float64(2.1399999999999997), np.float64(2.45), np.float64(2.46), np.float64(2.21), np.float64(1.0), np.float64(1.66), np.float64(1.72), np.float64(2.91), np.float64(1.49), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.45), np.float64(2.1799999999999997), np.float64(1.47), np.float64(1.25), np.float64(2.45), np.float64(2.45), np.float64(-2.0999999999999943), np.float64(0.6799999999999999), np.float64(2.45), np.float64(2.24), np.float64(2.91), np.float64(2.69), np.float64(2.69), np.float64(3.38), np.float64(1.73), np.float64(3.6500000000000004), np.float64(3.16), np.float64(1.49), np.float64(-1.0200000000000005), np.float64(1.73), np.float64(3.870000000000001), np.float64(1.68), np.float64(1.25), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(3.17), np.float64(1.92), np.float64(1.0), np.float64(1.4), np.float64(1.25), np.float64(1.0), np.float64(0.6799999999999999), np.float64(1.93), np.float64(1.39), np.float64(1.49), np.float64(1.95), np.float64(1.0), np.float64(2.8799999999999994), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.67), np.float64(1.97), np.float64(1.0), np.float64(-0.13999999999999457), np.float64(2.91), np.float64(1.6199999999999997), np.float64(2.61), np.float64(3.41), np.float64(2.42), np.float64(2.45), np.float64(1.68), np.float64(1.44), np.float64(2.58), np.float64(1.96), np.float64(1.97), np.float64(1.49), np.float64(2.21), np.float64(3.370000000000001), np.float64(3.41), np.float64(2.45), np.float64(2.69), np.float64(1.73), np.float64(1.97), np.float64(1.25), np.float64(2.33), np.float64(3.05), np.float64(2.4299999999999997), np.float64(1.25), np.float64(2.21), np.float64(3.6500000000000004), np.float64(3.11), np.float64(1.97), np.float64(2.4299999999999997), np.float64(3.17), np.float64(2.21), np.float64(1.0), np.float64(1.89), np.float64(2.88), np.float64(3.15), np.float64(2.6799999999999997), np.float64(2.4299999999999997), np.float64(2.34), np.float64(2.12), np.float64(1.49), np.float64(1.6099999999999997), np.float64(1.73), np.float64(0.72), np.float64(2.91), np.float64(3.17), np.float64(2.66), np.float64(1.49), np.float64(3.3899999999999997), np.float64(1.67), np.float64(1.95), np.float64(2.3899999999999997), np.float64(3.0), np.float64(2.69), np.float64(2.869999999999999), np.float64(-3.0199999999999765), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.69), np.float64(1.25), np.float64(3.41), np.float64(3.05), np.float64(2.4299999999999997), np.float64(3.17), np.float64(1.49), np.float64(1.49), np.float64(1.73), np.float64(2.45), np.float64(1.41), np.float64(2.69), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.6399999999999997), np.float64(3.8900000000000006), np.float64(2.38), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.58), np.float64(1.97), np.float64(2.45), np.float64(2.6399999999999997), np.float64(3.41), np.float64(2.91), np.float64(2.58), np.float64(3.8400000000000007), np.float64(2.4), np.float64(1.97), np.float64(-1.2299999999999995), np.float64(2.44), np.float64(3.1399999999999997), np.float64(3.6500000000000004), np.float64(2.45), np.float64(2.69), np.float64(2.67), np.float64(1.43), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.73), np.float64(3.07), np.float64(1.49), np.float64(3.12), np.float64(3.17), np.float64(1.49), np.float64(2.6799999999999997), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.65), np.float64(3.41), np.float64(0.6399999999999999), np.float64(3.37), np.float64(1.49), np.float64(1.9799999999999998), np.float64(2.6799999999999997), np.float64(0.10999999999999943), np.float64(2.9299999999999997), np.float64(3.19), np.float64(2.69), np.float64(3.16), np.float64(-0.2100000000000004), np.float64(3.15), np.float64(3.4), np.float64(1.2), np.float64(2.9299999999999997), np.float64(-7.649999999999951), np.float64(2.6799999999999997), np.float64(2.37), np.float64(1.93), np.float64(1.71), np.float64(2.42), np.float64(2.21), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.6799999999999997), np.float64(3.11), np.float64(1.97), np.float64(2.69), np.float64(1.7), np.float64(2.58), np.float64(1.97), np.float64(0.96), np.float64(-0.5000000000000004), np.float64(2.69), np.float64(1.0299999999999996), np.float64(0.3699999999999999), np.float64(2.92), np.float64(1.48), np.float64(2.45), np.float64(1.2099999999999997), np.float64(3.6399999999999997), np.float64(1.3800000000000003), np.float64(2.45), np.float64(2.83), np.float64(0.9599999999999995), np.float64(1.97), np.float64(1.8399999999999999), np.float64(1.49), np.float64(1.49), np.float64(1.97), np.float64(1.63), np.float64(2.3899999999999997), np.float64(1.49), np.float64(1.73), np.float64(3.1399999999999997), np.float64(1.25), np.float64(1.3599999999999999), np.float64(1.18), np.float64(2.21), np.float64(2.86), np.float64(2.6799999999999997), np.float64(1.73), np.float64(1.66), np.float64(1.97), np.float64(1.8599999999999999), np.float64(1.8499999999999994), np.float64(0.7299999999999998), np.float64(1.25), np.float64(1.96), np.float64(3.01), np.float64(2.7599999999999993), np.float64(3.3899999999999997), np.float64(2.45), np.float64(3.17), np.float64(2.21), np.float64(2.92), np.float64(3.41), np.float64(2.19), np.float64(2.4299999999999997), np.float64(2.59), np.float64(3.41), np.float64(2.91), np.float64(2.5399999999999996), np.float64(3.11), np.float64(1.4499999999999997), np.float64(2.5999999999999996), np.float64(2.3899999999999997), np.float64(2.41), np.float64(2.21), np.float64(2.15), np.float64(3.6400000000000006), np.float64(1.49), np.float64(1.95), np.float64(2.21), np.float64(2.01), np.float64(3.41), np.float64(1.97), np.float64(1.25), np.float64(3.41), np.float64(2.6899999999999995), np.float64(1.97), np.float64(1.0), np.float64(3.41), np.float64(1.25), np.float64(2.9), np.float64(3.8900000000000006), np.float64(2.21), np.float64(1.18), np.float64(1.25), np.float64(1.71), np.float64(2.69), np.float64(1.73), np.float64(1.73), np.float64(2.92), np.float64(2.45), np.float64(1.0), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.63), np.float64(2.21), np.float64(1.48), np.float64(1.49), np.float64(2.4299999999999997), np.float64(1.72), np.float64(1.64), np.float64(1.25), np.float64(1.25), np.float64(2.2), np.float64(1.64), np.float64(2.45), np.float64(-0.9500000000000002), np.float64(2.21), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.37), np.float64(-15.179999999999858), np.float64(1.88), np.float64(1.73), np.float64(2.91), np.float64(3.37), np.float64(2.9299999999999997), np.float64(2.3), np.float64(2.9299999999999997), np.float64(3.369999999999999), np.float64(2.21), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.21), np.float64(2.12), np.float64(1.97), np.float64(1.25), np.float64(0.019999999999998908), np.float64(2.21), np.float64(2.42), np.float64(-7.069999999999874), np.float64(1.49), np.float64(0.8099999999999994), np.float64(1.71), np.float64(1.95), np.float64(-0.6199999999999977), np.float64(2.19), np.float64(3.63), np.float64(2.65), np.float64(2.69), np.float64(1.73), np.float64(3.17), np.float64(1.3899999999999997), np.float64(2.4), np.float64(2.45), np.float64(2.9899999999999998), np.float64(1.9999999999999998), np.float64(2.42), np.float64(3.17), np.float64(2.2), np.float64(2.19), np.float64(1.49), np.float64(1.2299999999999998), np.float64(1.47), np.float64(3.1399999999999997), np.float64(2.69), np.float64(2.4299999999999997), np.float64(2.1399999999999997), np.float64(2.21), np.float64(2.8499999999999996), np.float64(2.45), np.float64(1.73), np.float64(-33.370000000000445), np.float64(-15.86999999999983), np.float64(0.9099999999999993), np.float64(1.63), np.float64(1.97), np.float64(1.8799999999999997), np.float64(2.6799999999999997), np.float64(1.95), np.float64(2.69), np.float64(1.71), np.float64(1.73), np.float64(1.97), np.float64(2.6799999999999997), np.float64(2.0999999999999996), np.float64(1.97), np.float64(3.17), np.float64(2.45), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.44), np.float64(2.62), np.float64(3.17), np.float64(2.36), np.float64(3.17), np.float64(1.73), np.float64(2.9299999999999997), np.float64(1.71), np.float64(-1.3899999999999961), np.float64(2.6399999999999997), np.float64(2.19), np.float64(2.45), np.float64(0.24), np.float64(2.12), np.float64(2.9499999999999993), np.float64(2.67), np.float64(1.95), np.float64(0.94), np.float64(2.45), np.float64(2.91), np.float64(1.18), np.float64(2.4299999999999997), np.float64(1.44), np.float64(2.19), np.float64(1.49), np.float64(2.41), np.float64(1.97), np.float64(2.19), np.float64(1.1299999999999997), np.float64(1.0), np.float64(2.19), np.float64(2.45), np.float64(1.0), np.float64(2.88), np.float64(2.69), np.float64(2.21), np.float64(1.97), np.float64(1.73), np.float64(3.0), np.float64(2.69), np.float64(1.0), np.float64(2.69), np.float64(1.0), np.float64(2.2), np.float64(1.72), np.float64(2.67), np.float64(3.17), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.49), np.float64(1.97), np.float64(2.21), np.float64(1.25), np.float64(0.96), np.float64(1.97), np.float64(3.4), np.float64(2.45), np.float64(3.17), np.float64(3.13), np.float64(2.12), np.float64(1.68), np.float64(1.97), np.float64(3.38), np.float64(2.17), np.float64(1.71), np.float64(3.39), np.float64(2.6799999999999997), np.float64(2.45), np.float64(1.7199999999999993), np.float64(1.72), np.float64(1.49), np.float64(1.97), np.float64(2.45), np.float64(1.25), np.float64(3.4), np.float64(1.73), np.float64(2.62), np.float64(0.7999999999999998), np.float64(2.92), np.float64(2.21), np.float64(3.4), np.float64(1.49), np.float64(3.17), np.float64(2.69), np.float64(3.17), np.float64(2.69), np.float64(0.48), np.float64(-0.5700000000000005), np.float64(2.9), np.float64(3.17), np.float64(2.45), np.float64(2.9299999999999997), np.float64(0.94), np.float64(1.89), np.float64(2.9299999999999997), np.float64(2.45), np.float64(3.15), np.float64(3.37), np.float64(2.21), np.float64(2.45), np.float64(2.8899999999999997), np.float64(2.45), np.float64(2.0199999999999996), np.float64(2.69), np.float64(1.97), np.float64(3.07), np.float64(1.69), np.float64(3.870000000000001), np.float64(3.3499999999999996), np.float64(2.69), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.68), np.float64(2.9299999999999997), np.float64(1.0999999999999999), np.float64(2.84), np.float64(2.21), np.float64(3.41), np.float64(3.6500000000000004), np.float64(2.44), np.float64(2.41), np.float64(3.17), np.float64(3.3899999999999997), np.float64(1.6099999999999999), np.float64(1.0), np.float64(1.95), np.float64(2.15), np.float64(1.49), np.float64(1.93), np.float64(1.6999999999999997), np.float64(3.6500000000000004), np.float64(1.95), np.float64(1.97), np.float64(2.19), np.float64(3.41), np.float64(2.45), np.float64(2.9299999999999997), np.float64(0.1999999999999993), np.float64(2.44), np.float64(1.91), np.float64(3.41), np.float64(2.21), np.float64(3.6500000000000004), np.float64(2.69), np.float64(1.44), np.float64(0.0), np.float64(1.49), np.float64(2.21), np.float64(1.97), np.float64(2.66), np.float64(1.97), np.float64(2.21), np.float64(2.45), np.float64(2.16), np.float64(1.96), np.float64(1.97), np.float64(3.17), np.float64(2.6799999999999997), np.float64(1.49), np.float64(3.6500000000000004), np.float64(1.97), np.float64(2.44), np.float64(2.69), np.float64(3.16), np.float64(2.69), np.float64(2.45), np.float64(1.97), np.float64(1.97), np.float64(2.21), np.float64(2.57), np.float64(3.17), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.5499999999999998), np.float64(2.21), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.69), np.float64(-3.4999999999999876), np.float64(1.49), np.float64(1.71), np.float64(-21.02000000000033), np.float64(-1.2499999999999991), np.float64(1.25), np.float64(1.9099999999999997), np.float64(1.73), np.float64(1.49), np.float64(1.68), np.float64(0.72), np.float64(2.6799999999999997), np.float64(1.8199999999999998), np.float64(2.45), np.float64(1.71), np.float64(1.96), np.float64(2.05), np.float64(2.92), np.float64(1.0), np.float64(1.73), np.float64(2.92), np.float64(-32.96000000000024), np.float64(2.69), np.float64(2.21), np.float64(-3.6199999999999948), np.float64(2.45), np.float64(1.97), np.float64(2.2), np.float64(2.21), np.float64(3.12), np.float64(1.49), np.float64(1.49), np.float64(2.19), np.float64(2.9), np.float64(1.6399999999999997), np.float64(1.97), np.float64(0.94), np.float64(1.8399999999999999), np.float64(2.45), np.float64(1.47), np.float64(1.9999999999999991), np.float64(2.44), np.float64(3.17), np.float64(1.5799999999999998), np.float64(1.73), np.float64(-1.6899999999999933), np.float64(2.9299999999999997), np.float64(1.0899999999999999), np.float64(2.7499999999999996), np.float64(2.9299999999999997), np.float64(1.4), np.float64(2.45), np.float64(0.94), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.21), np.float64(2.2), np.float64(1.49), np.float64(1.97), np.float64(3.08), np.float64(2.21), np.float64(2.45), np.float64(2.4000000000000004), np.float64(2.13), np.float64(3.4), np.float64(1.97), np.float64(2.21), np.float64(3.17), np.float64(2.21), np.float64(1.93), np.float64(2.19), np.float64(2.45), np.float64(1.44), np.float64(2.92), np.float64(2.82), np.float64(2.8899999999999997), np.float64(2.45), np.float64(2.69), np.float64(1.48), np.float64(2.45), np.float64(1.97), np.float64(2.2), np.float64(3.41), np.float64(1.88), np.float64(1.97), np.float64(3.16), np.float64(2.6399999999999997), np.float64(2.69), np.float64(1.49), np.float64(3.08), np.float64(3.17), np.float64(2.4299999999999997), np.float64(1.96), np.float64(2.45), np.float64(1.49), np.float64(2.41), np.float64(3.63), np.float64(1.95), np.float64(2.67), np.float64(1.69), np.float64(2.9299999999999997), np.float64(2.67), np.float64(1.25), np.float64(3.17), np.float64(0.9799999999999993), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.47), np.float64(1.0), np.float64(3.17), np.float64(2.69), np.float64(2.1799999999999997), np.float64(2.05), np.float64(2.21), np.float64(1.97), np.float64(1.97), np.float64(2.63), np.float64(3.38), np.float64(2.45), np.float64(2.21), np.float64(2.19), np.float64(2.45), np.float64(1.95), np.float64(2.19), np.float64(2.19), np.float64(2.19), np.float64(-0.5100000000000005), np.float64(1.97), np.float64(2.21), np.float64(3.17), np.float64(2.6799999999999997), np.float64(1.49), np.float64(3.17), np.float64(2.65), np.float64(1.97), np.float64(2.8099999999999996), np.float64(1.73), np.float64(1.97), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(2.4299999999999997), np.float64(2.19), np.float64(1.3799999999999997), np.float64(-0.2200000000000002), np.float64(1.45), np.float64(2.9299999999999997), np.float64(3.6500000000000004), np.float64(2.59), np.float64(2.21), np.float64(1.91), np.float64(2.66), np.float64(2.61), np.float64(1.0), np.float64(2.81), np.float64(1.73), np.float64(1.97), np.float64(1.49), np.float64(3.6500000000000004), np.float64(2.21), np.float64(3.63), np.float64(1.71), np.float64(1.4499999999999993), np.float64(1.0), np.float64(1.49), np.float64(1.72), np.float64(2.45), np.float64(3.4), np.float64(-22.170000000000705), np.float64(0.3499999999999992), np.float64(2.12), np.float64(2.8899999999999997), np.float64(0.6299999999999998), np.float64(1.49), np.float64(1.0), np.float64(-0.9000000000000004), np.float64(2.7199999999999998), np.float64(1.25), np.float64(1.49), np.float64(1.9699999999999998), np.float64(2.87), np.float64(1.25), np.float64(2.58), np.float64(3.1899999999999995), np.float64(-0.36999999999999966), np.float64(1.97), np.float64(2.41), np.float64(2.2), np.float64(1.39), np.float64(3.28), np.float64(3.46), np.float64(2.59), np.float64(1.6099999999999999), np.float64(0.24), np.float64(1.6099999999999999), np.float64(2.16), np.float64(2.33), np.float64(2.21), np.float64(3.1399999999999997), np.float64(3.6500000000000004), np.float64(1.97), np.float64(2.69), np.float64(2.21), np.float64(2.67), np.float64(1.97), np.float64(1.65), np.float64(2.69), np.float64(0.96), np.float64(2.45), np.float64(0.72), np.float64(3.87), np.float64(3.15), np.float64(1.73), np.float64(1.44), np.float64(2.45), np.float64(1.97), np.float64(2.67), np.float64(3.17), np.float64(1.4), np.float64(1.0), np.float64(1.49), np.float64(3.41), np.float64(3.46), np.float64(3.41), np.float64(2.21), np.float64(2.69), np.float64(2.45), np.float64(1.73), np.float64(2.8899999999999997), np.float64(2.45), np.float64(-0.2799999999999998), np.float64(2.19), np.float64(2.65), np.float64(3.6500000000000004), np.float64(1.49), np.float64(1.73), np.float64(1.73), np.float64(3.17), np.float64(1.49), np.float64(3.6399999999999997), np.float64(1.66), np.float64(1.71), np.float64(2.67), np.float64(1.95), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.21), np.float64(0.1399999999999999), np.float64(3.1399999999999997), np.float64(3.3899999999999997), np.float64(1.93), np.float64(0.6599999999999999), np.float64(1.73), np.float64(1.73), np.float64(1.97), np.float64(1.42), np.float64(1.97), np.float64(1.47), np.float64(2.17), np.float64(1.73), np.float64(2.21), np.float64(1.48), np.float64(3.17), np.float64(0.94), np.float64(1.97), np.float64(0.7), np.float64(1.97), np.float64(1.9), np.float64(2.91), np.float64(-0.4800000000000004), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.0), np.float64(2.67), np.float64(3.0599999999999996), np.float64(2.19), np.float64(1.7299999999999998), np.float64(2.13), np.float64(1.49), np.float64(2.21), np.float64(1.97), np.float64(3.6399999999999997), np.float64(1.0), np.float64(-0.3500000000000001), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.4299999999999997), np.float64(3.38), np.float64(-17.45999999999994), np.float64(2.990000000000001), np.float64(1.42), np.float64(1.95), np.float64(3.17), np.float64(1.97), np.float64(0.8899999999999999), np.float64(1.73), np.float64(2.21), np.float64(2.5799999999999996), np.float64(1.49), np.float64(2.8699999999999997), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.67), np.float64(1.49), np.float64(2.45), np.float64(2.66), np.float64(3.4), np.float64(1.97), np.float64(2.67), np.float64(2.66), np.float64(2.1599999999999997), np.float64(1.97), np.float64(1.0), np.float64(2.17), np.float64(1.42), np.float64(1.49), np.float64(3.3699999999999997), np.float64(2.44), np.float64(2.38), np.float64(1.73), np.float64(2.4699999999999998), np.float64(1.73), np.float64(-3.6999999999999913), np.float64(1.73), np.float64(1.9299999999999997), np.float64(2.21), np.float64(1.25), np.float64(1.25), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.97), np.float64(1.49), np.float64(-0.14000000000000012), np.float64(2.9299999999999997), np.float64(2.41), np.float64(3.17), np.float64(2.45), np.float64(2.8), np.float64(-24.08000000000043), np.float64(-0.11000000000000054), np.float64(-2.7299999999999818), np.float64(2.91), np.float64(1.49), np.float64(1.49), np.float64(1.73), np.float64(1.4), np.float64(2.5199999999999996), np.float64(3.3899999999999997), np.float64(2.45), np.float64(2.17), np.float64(3.15), np.float64(1.2199999999999998), np.float64(3.63), np.float64(2.4299999999999997), np.float64(3.41), np.float64(2.91), np.float64(1.49), np.float64(2.45), np.float64(2.9299999999999997), np.float64(3.41), np.float64(1.88), np.float64(2.9299999999999997), np.float64(2.66), np.float64(1.0), np.float64(2.92), np.float64(2.21), np.float64(2.65), np.float64(2.21), np.float64(1.49), np.float64(1.93), np.float64(2.44), np.float64(2.69), np.float64(1.0099999999999998), np.float64(2.42), np.float64(1.73), np.float64(3.8400000000000007), np.float64(2.45), np.float64(2.69), np.float64(2.36), np.float64(2.62), np.float64(1.8099999999999998), np.float64(1.0), np.float64(2.4299999999999997), np.float64(1.71), np.float64(2.6799999999999997), np.float64(1.73), np.float64(1.49), np.float64(2.69), np.float64(2.69), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.84), np.float64(2.41), np.float64(1.73), np.float64(1.71), np.float64(1.6199999999999997), np.float64(2.4299999999999997), np.float64(1.95), np.float64(3.13), np.float64(0.7299999999999993), np.float64(3.15), np.float64(1.95), np.float64(1.25), np.float64(3.8900000000000006), np.float64(3.17), np.float64(0.38000000000000034), np.float64(3.17), np.float64(1.9), np.float64(1.49), np.float64(1.71), np.float64(3.17), np.float64(3.41), np.float64(0.7399999999999993), np.float64(1.95), np.float64(2.91), np.float64(2.9299999999999997), np.float64(1.94), np.float64(1.97), np.float64(1.49), np.float64(2.4899999999999998), np.float64(2.45), np.float64(2.44), np.float64(2.19), np.float64(2.45), np.float64(-20.36000000000019), np.float64(1.5899999999999999), np.float64(2.63), np.float64(2.7399999999999993), np.float64(2.26), np.float64(2.5999999999999996), np.float64(-0.04999999999999982), np.float64(2.84), np.float64(2.84), np.float64(2.69), np.float64(2.45), np.float64(2.21), np.float64(1.18), np.float64(2.45), np.float64(2.69), np.float64(2.42), np.float64(2.6799999999999997), np.float64(2.69), np.float64(1.8199999999999998), np.float64(-2.799999999999992), np.float64(1.25), np.float64(2.45), np.float64(1.73), np.float64(1.49), np.float64(2.69), np.float64(3.41), np.float64(2.44), np.float64(0.9199999999999999), np.float64(1.42), np.float64(1.6199999999999999), np.float64(2.45), np.float64(1.49), np.float64(1.73), np.float64(1.49), np.float64(2.69), np.float64(2.21), np.float64(2.67), np.float64(2.6399999999999997), np.float64(2.45), np.float64(1.16), np.float64(2.37), np.float64(1.25), np.float64(2.9299999999999997), np.float64(1.68), np.float64(1.2199999999999998), np.float64(3.15), np.float64(2.01), np.float64(3.41), np.float64(1.93), np.float64(2.91), np.float64(2.45), np.float64(1.95), np.float64(2.37), np.float64(1.0), np.float64(2.12), np.float64(3.3899999999999997), np.float64(3.3899999999999997), np.float64(2.21), np.float64(1.71), np.float64(3.6399999999999997), np.float64(2.45), np.float64(1.64), np.float64(2.45), np.float64(2.9299999999999997), np.float64(3.41), np.float64(2.19), np.float64(1.96), np.float64(1.25), np.float64(3.4), np.float64(2.45), np.float64(2.19), np.float64(2.69), np.float64(0.95), np.float64(3.6500000000000004), np.float64(3.17), np.float64(2.69), np.float64(2.9299999999999997), np.float64(2.19), np.float64(2.12), np.float64(2.69), np.float64(3.87), np.float64(2.4299999999999997), np.float64(1.18), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.21), np.float64(2.19), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.45), np.float64(1.0), np.float64(3.38), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.91), np.float64(2.9299999999999997), np.float64(3.63), np.float64(1.95), np.float64(2.9299999999999997), np.float64(1.93), np.float64(3.15), np.float64(1.93), np.float64(1.49), np.float64(2.32), np.float64(1.49), np.float64(1.73), np.float64(2.21), np.float64(-5.249999999999911), np.float64(2.9299999999999997), np.float64(2.4399999999999995), np.float64(1.6199999999999999), np.float64(1.97), np.float64(3.5200000000000005), np.float64(2.1799999999999997), np.float64(0.11999999999999922), np.float64(1.2299999999999993), np.float64(0.96), np.float64(1.0), np.float64(2.4299999999999997), np.float64(1.0), np.float64(1.73), np.float64(1.17), np.float64(2.65), np.float64(2.67), np.float64(2.76), np.float64(1.49), np.float64(1.97), np.float64(2.4299999999999997), np.float64(2.67), np.float64(2.6599999999999997), np.float64(0.8600000000000005), np.float64(2.65), np.float64(1.49), np.float64(2.21), np.float64(2.91), np.float64(3.15), np.float64(1.2699999999999998), np.float64(2.67), np.float64(1.96), np.float64(2.67), np.float64(0.6699999999999997), np.float64(1.97), np.float64(1.97), np.float64(3.17), np.float64(1.97), np.float64(1.97), np.float64(1.7699999999999996), np.float64(3.17), np.float64(3.63), np.float64(2.62), np.float64(2.21), np.float64(2.4299999999999997), np.float64(2.69), np.float64(2.3899999999999997), np.float64(3.4), np.float64(1.69), np.float64(2.44), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.83), np.float64(3.5999999999999996), np.float64(0.24), np.float64(1.25), np.float64(1.25), np.float64(2.21), np.float64(0.9899999999999995), np.float64(3.1399999999999997), np.float64(3.4), np.float64(2.12), np.float64(2.65), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.37), np.float64(2.45), np.float64(-1.2299999999999933), np.float64(0.98), np.float64(1.0), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.38), np.float64(2.3499999999999996), np.float64(3.8100000000000005), np.float64(1.0), np.float64(1.39), np.float64(1.71), np.float64(2.21), np.float64(1.49), np.float64(2.69), np.float64(2.69), np.float64(1.49), np.float64(1.5599999999999998), np.float64(3.62), np.float64(2.69), np.float64(3.13), np.float64(3.83), np.float64(2.4299999999999997), np.float64(1.47), np.float64(1.97), np.float64(1.25), np.float64(2.21), np.float64(2.5799999999999996), np.float64(2.69), np.float64(3.17), np.float64(3.8900000000000006), np.float64(2.69), np.float64(1.49), np.float64(1.49), np.float64(3.7700000000000005), np.float64(1.97), np.float64(1.25), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.69), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(3.3899999999999997), np.float64(2.19), np.float64(1.49), np.float64(2.45), np.float64(1.1199999999999999), np.float64(3.3899999999999997), np.float64(-22.070000000000526), np.float64(1.8699999999999999), np.float64(2.69), np.float64(1.7899999999999991), np.float64(1.38), np.float64(1.0), np.float64(2.12), np.float64(1.25), np.float64(2.92), np.float64(2.5699999999999994), np.float64(2.21), np.float64(1.97), np.float64(2.21), np.float64(1.97), np.float64(3.17), np.float64(1.67), np.float64(1.25), np.float64(1.97), np.float64(2.66), np.float64(2.21), np.float64(3.88), np.float64(2.9099999999999997), np.float64(1.97), np.float64(0.1599999999999997), np.float64(2.4299999999999997), np.float64(2.9299999999999997), np.float64(3.17), np.float64(3.8900000000000006), np.float64(2.3899999999999997), np.float64(2.69), np.float64(2.21), np.float64(2.01), np.float64(1.25), np.float64(1.73), np.float64(1.73), np.float64(1.95), np.float64(3.6399999999999997), np.float64(2.21), np.float64(1.73), np.float64(3.41), np.float64(2.21), np.float64(3.17), np.float64(1.4), np.float64(2.03), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.0999999999999996), np.float64(1.45), np.float64(2.65), np.float64(3.16), np.float64(1.49), np.float64(2.67), np.float64(2.21), np.float64(1.97), np.float64(3.63), np.float64(2.38), np.float64(1.6799999999999997), np.float64(2.16), np.float64(-0.31000000000000005), np.float64(2.8899999999999997), np.float64(1.49), np.float64(1.66), np.float64(2.8899999999999997), np.float64(1.73), np.float64(1.97), np.float64(1.97), np.float64(1.49), np.float64(2.45), np.float64(2.92), np.float64(3.3899999999999997), np.float64(1.49), np.float64(2.17), np.float64(1.97), np.float64(1.49), np.float64(1.65), np.float64(1.6199999999999999), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.7099999999999997), np.float64(3.6399999999999997), np.float64(2.45), np.float64(2.21), np.float64(1.97), np.float64(3.34), np.float64(0.7399999999999998), np.float64(1.41), np.float64(3.1399999999999997), np.float64(2.15), np.float64(2.69), np.float64(1.49), np.float64(2.6799999999999997), np.float64(2.92), np.float64(1.49), np.float64(3.17), np.float64(1.6299999999999997), np.float64(2.9299999999999997), np.float64(-0.43999999999999995), np.float64(1.25), np.float64(1.68), np.float64(3.15), np.float64(3.6099999999999994), np.float64(2.9299999999999997), np.float64(-1.1100000000000012), np.float64(-0.5899999999999956), np.float64(2.67), np.float64(1.25), np.float64(2.41), np.float64(2.62), np.float64(1.97), np.float64(2.91), np.float64(1.97), np.float64(3.17), np.float64(1.5099999999999998), np.float64(1.49), np.float64(3.16), np.float64(2.84), np.float64(1.25), np.float64(2.4299999999999997), np.float64(1.0399999999999998), np.float64(-0.5700000000000001), np.float64(2.42), np.float64(-14.519999999999833), np.float64(2.2), np.float64(2.19), np.float64(2.9299999999999997), np.float64(1.73), np.float64(3.15), np.float64(2.08), np.float64(2.45), np.float64(2.79), np.float64(2.69), np.float64(2.69), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.67), np.float64(1.7899999999999998), np.float64(2.21), np.float64(2.45), np.float64(1.93), np.float64(1.97), np.float64(3.13), np.float64(2.69), np.float64(1.73), np.float64(2.8499999999999996), np.float64(1.6999999999999997), np.float64(2.21), np.float64(2.8099999999999996), np.float64(3.41), np.float64(1.25), np.float64(2.6799999999999997), np.float64(2.6799999999999997), np.float64(2.21), np.float64(1.49), np.float64(3.63), np.float64(2.92), np.float64(2.45), np.float64(2.66), np.float64(1.5499999999999998), np.float64(2.45), np.float64(2.92), np.float64(1.2399999999999998), np.float64(0.99), np.float64(2.9299999999999997), np.float64(1.25), np.float64(3.41), np.float64(1.97), np.float64(1.49), np.float64(0.24), np.float64(3.39), np.float64(1.49), np.float64(1.97), np.float64(1.49), np.float64(1.8499999999999999), np.float64(1.71), np.float64(2.21), np.float64(2.6799999999999997), np.float64(2.88), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.21), np.float64(3.3899999999999997), np.float64(2.69), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.0999999999999996), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.67), np.float64(1.49), np.float64(2.4299999999999997), np.float64(1.0299999999999994), np.float64(2.45), np.float64(1.73), np.float64(1.73), np.float64(2.1399999999999997), np.float64(3.37), np.float64(2.4299999999999997), np.float64(3.41), np.float64(1.97), np.float64(2.21), np.float64(2.69), np.float64(2.45), np.float64(-0.13000000000000012), np.float64(3.4), np.float64(2.2), np.float64(1.6199999999999999), np.float64(3.13), np.float64(2.21), np.float64(1.2499999999999993), np.float64(2.05), np.float64(2.32), np.float64(1.73), np.float64(2.45), np.float64(2.45), np.float64(1.97), np.float64(1.49), np.float64(-5.48999999999994), np.float64(2.8), np.float64(2.84), np.float64(1.73), np.float64(3.36), np.float64(2.65), np.float64(2.9299999999999997), np.float64(1.25), np.float64(1.95), np.float64(2.69), np.float64(1.1099999999999999), np.float64(1.6899999999999995), np.float64(2.4), np.float64(1.25), np.float64(1.97), np.float64(1.8599999999999999), np.float64(1.97), np.float64(1.97), np.float64(-0.3700000000000001), np.float64(1.71), np.float64(3.1399999999999997), np.float64(2.11), np.float64(1.47), np.float64(2.59), np.float64(2.67), np.float64(2.44), np.float64(1.0), np.float64(3.41), np.float64(2.91), np.float64(2.69), np.float64(1.2), np.float64(2.91), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.92), np.float64(2.69), np.float64(2.67), np.float64(0.04999999999999982), np.float64(0.6599999999999999), np.float64(3.1399999999999997), np.float64(2.19), np.float64(2.45), np.float64(1.97), np.float64(1.0), np.float64(3.13), np.float64(2.41), np.float64(1.97), np.float64(-16.519999999999996), np.float64(0.5299999999999998), np.float64(2.2699999999999996), np.float64(1.4699999999999998), np.float64(2.45), np.float64(2.91), np.float64(2.57), np.float64(3.17), np.float64(1.97), np.float64(1.66), np.float64(1.49), np.float64(0.33999999999999875), np.float64(2.4299999999999997), np.float64(3.62), np.float64(0.96), np.float64(1.4), np.float64(1.93), np.float64(1.73), np.float64(2.44), np.float64(1.48), np.float64(1.44), np.float64(2.45), np.float64(3.6500000000000004), np.float64(2.91), np.float64(1.97), np.float64(1.95), np.float64(3.8900000000000006), np.float64(1.97), np.float64(1.73), np.float64(1.7699999999999994), np.float64(1.5299999999999998), np.float64(2.19), np.float64(3.17), np.float64(3.6100000000000003), np.float64(2.5199999999999996), np.float64(2.21), np.float64(2.45), np.float64(1.96), np.float64(2.9299999999999997), np.float64(1.97), np.float64(1.2), np.float64(1.25), np.float64(2.3499999999999996), np.float64(1.49), np.float64(2.45), np.float64(2.45), np.float64(2.9299999999999997), np.float64(3.13), np.float64(2.55), np.float64(1.91), np.float64(2.45), np.float64(2.07), np.float64(1.97), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.91), np.float64(1.25), np.float64(2.6299999999999994), np.float64(3.15), np.float64(1.49), np.float64(2.6799999999999997), np.float64(2.69), np.float64(3.6500000000000004), np.float64(3.6500000000000004), np.float64(3.15), np.float64(2.1399999999999997), np.float64(2.9299999999999997), np.float64(3.34), np.float64(2.91), np.float64(2.3899999999999997), np.float64(2.9299999999999997), np.float64(2.69), np.float64(1.49), np.float64(2.41), np.float64(1.9), np.float64(3.6500000000000004), np.float64(3.17), np.float64(1.4), np.float64(2.67), np.float64(1.97), np.float64(3.17), np.float64(2.8499999999999996), np.float64(1.2), np.float64(1.56), np.float64(-0.15000000000000013), np.float64(1.49), np.float64(0.09999999999999987), np.float64(1.46), np.float64(1.64), np.float64(1.0), np.float64(2.45), np.float64(1.1199999999999999), np.float64(3.41), np.float64(1.71), np.float64(2.45), np.float64(2.19), np.float64(1.49), np.float64(1.73), np.float64(1.49), np.float64(1.71), np.float64(2.13), np.float64(1.49), np.float64(2.69), np.float64(2.13), np.float64(1.25), np.float64(2.67), np.float64(2.69), np.float64(3.8900000000000006), np.float64(2.21), np.float64(1.25), np.float64(1.95), np.float64(2.53), np.float64(1.47), np.float64(2.2), np.float64(2.6799999999999997), np.float64(2.12), np.float64(2.21), np.float64(1.49), np.float64(2.21), np.float64(2.21), np.float64(2.17), np.float64(3.17), np.float64(1.73), np.float64(1.49), np.float64(2.67), np.float64(1.97), np.float64(2.21), np.float64(1.0), np.float64(1.71), np.float64(1.43), np.float64(1.4), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.1399999999999997), np.float64(3.1399999999999997), np.float64(3.17), np.float64(1.42), np.float64(1.93), np.float64(3.17), np.float64(2.19), np.float64(2.4299999999999997), np.float64(2.19), np.float64(1.49), np.float64(2.88), np.float64(3.15), np.float64(1.3499999999999999), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(3.17), np.float64(2.5599999999999996), np.float64(2.9299999999999997), np.float64(2.19), np.float64(2.4), np.float64(3.6500000000000004), np.float64(1.97), np.float64(1.73), np.float64(1.97), np.float64(1.25), np.float64(0.5199999999999998), np.float64(1.44), np.float64(2.41), np.float64(2.91), np.float64(3.15), np.float64(3.63), np.float64(2.45), np.float64(2.19), np.float64(2.91), np.float64(2.59), np.float64(1.97), np.float64(2.45), np.float64(0.20999999999999996), np.float64(2.69), np.float64(1.49), np.float64(1.69), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.21), np.float64(3.6500000000000004), np.float64(1.47), np.float64(2.19), np.float64(2.45), np.float64(1.97), np.float64(1.0), np.float64(2.69), np.float64(3.17), np.float64(3.41), np.float64(3.62), np.float64(1.25), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.47), np.float64(2.21), np.float64(2.92), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.73), np.float64(2.8899999999999997), np.float64(3.17), np.float64(3.88), np.float64(1.97), np.float64(3.62), np.float64(3.8900000000000006), np.float64(3.17), np.float64(2.69), np.float64(3.13), np.float64(2.21), np.float64(2.1399999999999997), np.float64(2.21), np.float64(1.25), np.float64(1.25), np.float64(2.4299999999999997), np.float64(2.37), np.float64(1.25), np.float64(1.73), np.float64(0.96), np.float64(1.64), np.float64(3.07), np.float64(2.69), np.float64(3.1399999999999997), np.float64(2.21), np.float64(2.45), np.float64(2.1799999999999997), np.float64(1.49), np.float64(1.72), np.float64(3.6500000000000004), np.float64(1.73), np.float64(1.2799999999999994), np.float64(2.9299999999999997), np.float64(3.62), np.float64(2.21), np.float64(1.95), np.float64(0.95), np.float64(1.95), np.float64(1.7099999999999997), np.float64(1.0), np.float64(3.05), np.float64(1.91), np.float64(1.97), np.float64(3.4), np.float64(2.69), np.float64(2.17), np.float64(2.45), np.float64(2.45), np.float64(3.6500000000000004), np.float64(1.8199999999999998), np.float64(2.69), np.float64(2.44), np.float64(1.0), np.float64(2.21), np.float64(2.69), np.float64(2.4000000000000004), np.float64(1.73), np.float64(2.21), np.float64(1.97), np.float64(3.17), np.float64(0.9699999999999999), np.float64(3.17), np.float64(3.15), np.float64(-0.4000000000000028), np.float64(1.25), np.float64(2.69), np.float64(2.88), np.float64(1.97), np.float64(2.38), np.float64(1.72), np.float64(3.17), np.float64(2.45), np.float64(0.8999999999999997), np.float64(2.69), np.float64(2.1399999999999997), np.float64(3.6500000000000004), np.float64(2.21), np.float64(1.69), np.float64(2.21), np.float64(2.9299999999999997), np.float64(3.41), np.float64(3.15), np.float64(-0.050000000000000044), np.float64(2.69), np.float64(2.45), np.float64(2.59), np.float64(2.45), np.float64(2.45), np.float64(2.4299999999999997), np.float64(2.45), np.float64(3.1399999999999997), np.float64(2.17), np.float64(-1.3199999999999958), np.float64(1.25), np.float64(3.3999999999999995), np.float64(2.45), np.float64(1.0), np.float64(2.45), np.float64(2.6799999999999997), np.float64(2.21), np.float64(0.9799999999999999), np.float64(2.2), np.float64(2.67), np.float64(1.47), np.float64(1.97), np.float64(1.71), np.float64(3.6400000000000006), np.float64(1.71), np.float64(2.21), np.float64(1.73), np.float64(1.49), np.float64(2.21), np.float64(1.95), np.float64(1.71), np.float64(1.0), np.float64(2.69), np.float64(2.45), np.float64(3.0999999999999996), np.float64(3.13), np.float64(3.17), np.float64(2.69), np.float64(2.63), np.float64(1.95), np.float64(2.9299999999999997), np.float64(2.9), np.float64(3.87), np.float64(2.45), np.float64(3.15), np.float64(1.49), np.float64(1.58), np.float64(3.87), np.float64(2.69), np.float64(1.49), np.float64(3.03), np.float64(3.880000000000001), np.float64(2.41), np.float64(2.9299999999999997), np.float64(1.4), np.float64(2.5599999999999996), np.float64(1.73), np.float64(2.61), np.float64(2.21), np.float64(1.49), np.float64(2.21), np.float64(1.64), np.float64(3.16), np.float64(1.97), np.float64(2.67), np.float64(2.45), np.float64(1.71), np.float64(1.49), np.float64(3.5300000000000002), np.float64(3.3899999999999997), np.float64(2.19), np.float64(1.71), np.float64(1.47), np.float64(2.21), np.float64(3.16), np.float64(2.9299999999999997), np.float64(2.91), np.float64(3.8500000000000005), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.97), np.float64(1.25), np.float64(2.44), np.float64(2.19), np.float64(3.1399999999999997), np.float64(1.49), np.float64(1.97), np.float64(2.86), np.float64(3.17), np.float64(1.68), np.float64(2.21), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(0.08999999999999986), np.float64(2.65), np.float64(3.62), np.float64(1.97), np.float64(2.2), np.float64(2.58), np.float64(2.9799999999999995), np.float64(2.69), np.float64(2.69), np.float64(2.45), np.float64(1.97), np.float64(0.94), np.float64(2.91), np.float64(1.95), np.float64(1.97), np.float64(1.49), np.float64(3.6500000000000004), np.float64(1.73), np.float64(3.17), np.float64(1.25), np.float64(1.73), np.float64(1.2), np.float64(2.69), np.float64(2.1799999999999997), np.float64(3.37), np.float64(2.69), np.float64(2.19), np.float64(1.97), np.float64(2.3599999999999994), np.float64(3.6500000000000004), np.float64(1.49), np.float64(2.67), np.float64(3.3499999999999996), np.float64(2.66), np.float64(1.5599999999999996), np.float64(1.97), np.float64(1.0099999999999996), np.float64(1.47), np.float64(2.91), np.float64(2.92), np.float64(1.0), np.float64(2.69), np.float64(2.5999999999999996), np.float64(1.25), np.float64(2.67), np.float64(2.21), np.float64(3.630000000000001), np.float64(3.62), np.float64(3.4), np.float64(1.73), np.float64(2.45), np.float64(1.97), np.float64(1.73), np.float64(3.6500000000000004), np.float64(0.0), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(-0.55), np.float64(-0.18000000000000016), np.float64(1.9999999999999998), np.float64(2.9299999999999997), np.float64(1.179999999999999), np.float64(3.6500000000000004), np.float64(2.9299999999999997), np.float64(2.91), np.float64(2.4299999999999997), np.float64(0.43999999999999995), np.float64(1.25), np.float64(2.21), np.float64(-0.2500000000000002), np.float64(3.17), np.float64(2.1699999999999995), np.float64(2.9299999999999997), np.float64(1.0), np.float64(2.67), np.float64(2.8899999999999997), np.float64(2.45), np.float64(1.73), np.float64(2.45), np.float64(1.73), np.float64(3.41), np.float64(1.25), np.float64(2.69), np.float64(3.13), np.float64(1.0), np.float64(2.6399999999999997), np.float64(2.1599999999999997), np.float64(3.01), np.float64(2.21), np.float64(1.49), np.float64(2.67), np.float64(2.66), np.float64(3.15), np.float64(2.12), np.float64(3.0599999999999996), np.float64(2.1399999999999997), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.25), np.float64(1.73), np.float64(2.45), np.float64(1.49), np.float64(3.33), np.float64(3.6400000000000006), np.float64(2.3899999999999997), np.float64(2.67), np.float64(1.96), np.float64(1.97), np.float64(1.89), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.49), np.float64(2.87), np.float64(3.34), np.float64(2.91), np.float64(1.0), np.float64(1.97), np.float64(1.7), np.float64(1.73), np.float64(1.49), np.float64(1.96), np.float64(2.19), np.float64(0.9199999999999999), np.float64(-1.1899999999999986), np.float64(2.69), np.float64(1.97), np.float64(1.1299999999999997), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.73), np.float64(1.97), np.float64(2.65), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(1.49), np.float64(3.17), np.float64(1.73), np.float64(-0.7100000000000017), np.float64(1.47), np.float64(2.37), np.float64(2.19), np.float64(2.21), np.float64(1.97), np.float64(2.69), np.float64(1.5799999999999998), np.float64(3.62), np.float64(2.4299999999999997), np.float64(2.69), np.float64(3.41), np.float64(1.73), np.float64(2.0199999999999996), np.float64(1.97), np.float64(2.05), np.float64(1.25), np.float64(3.3899999999999997), np.float64(1.73), np.float64(3.15), np.float64(3.41), np.float64(2.8499999999999996), np.float64(1.94), np.float64(1.73), np.float64(3.6500000000000004), np.float64(3.88), np.float64(1.4), np.float64(1.73), np.float64(2.17), np.float64(2.69), np.float64(3.17), np.float64(2.45), np.float64(1.97), np.float64(3.17), np.float64(2.45), np.float64(2.41), np.float64(2.21), np.float64(2.9299999999999997), np.float64(1.49), np.float64(2.9), np.float64(2.45), np.float64(3.17), np.float64(1.97), np.float64(0.03999999999999959), np.float64(2.21), np.float64(1.25), np.float64(0.0), np.float64(2.6799999999999997), np.float64(3.6500000000000004), np.float64(2.3099999999999996), np.float64(1.5199999999999998), np.float64(2.65), np.float64(1.25), np.float64(1.97), np.float64(1.23), np.float64(1.73), np.float64(2.45), np.float64(2.21), np.float64(0.71), np.float64(2.45), np.float64(1.49), np.float64(1.25), np.float64(2.42), np.float64(2.91), np.float64(2.9299999999999997), np.float64(2.92), np.float64(2.45), np.float64(1.2), np.float64(2.45), np.float64(1.97), np.float64(3.17), np.float64(2.21), np.float64(1.46), np.float64(2.92), np.float64(1.97), np.float64(2.59), np.float64(3.87), np.float64(3.6500000000000004), np.float64(1.97), np.float64(-11.029999999999836), np.float64(-4.559999999999962), np.float64(1.73), np.float64(0.7399999999999993), np.float64(1.73), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.73), np.float64(3.17), np.float64(1.49), np.float64(2.369999999999999), np.float64(1.4999999999999998), np.float64(3.63), np.float64(3.6500000000000004), np.float64(1.73), np.float64(2.45), np.float64(1.0), np.float64(1.25), np.float64(2.44), np.float64(3.17), np.float64(2.45), np.float64(1.0), np.float64(2.4099999999999997), np.float64(2.45), np.float64(2.17), np.float64(1.73), np.float64(1.0), np.float64(3.41), np.float64(2.69), np.float64(2.67), np.float64(1.49), np.float64(1.49), np.float64(2.21), np.float64(2.45), np.float64(2.21), np.float64(1.49), np.float64(2.21), np.float64(1.25), np.float64(1.49), np.float64(2.67), np.float64(1.73), np.float64(2.19), np.float64(3.17), np.float64(1.67), np.float64(1.73), np.float64(3.15), np.float64(1.73), np.float64(2.69), np.float64(0.96), np.float64(0.96), np.float64(1.73), np.float64(3.15), np.float64(1.97), np.float64(1.91), np.float64(2.67), np.float64(3.4), np.float64(2.45), np.float64(-1.020000000000001), np.float64(3.17), np.float64(3.41), np.float64(2.9299999999999997), np.float64(1.97), np.float64(2.45), np.float64(2.41), np.float64(2.9299999999999997), np.float64(3.63), np.float64(1.66), np.float64(1.73), np.float64(3.1399999999999997), np.float64(1.0), np.float64(3.17), np.float64(2.21), np.float64(2.69), np.float64(3.17), np.float64(1.8399999999999999), np.float64(1.73), np.float64(2.4299999999999997), np.float64(1.73), np.float64(1.9), np.float64(3.63), np.float64(2.92), np.float64(0.9099999999999997), np.float64(1.94), np.float64(-0.26000000000000023), np.float64(2.21), np.float64(0.72), np.float64(1.2799999999999998), np.float64(3.63), np.float64(2.41), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.41), np.float64(1.1199999999999999), np.float64(2.75), np.float64(3.6500000000000004), np.float64(1.73), np.float64(2.69), np.float64(2.13), np.float64(1.91), np.float64(1.97), np.float64(2.21), np.float64(2.2), np.float64(2.9), np.float64(1.49), np.float64(2.45), np.float64(3.17), np.float64(2.42), np.float64(2.21), np.float64(3.11), np.float64(1.73), np.float64(2.69), np.float64(1.95), np.float64(0.42999999999999994), np.float64(1.97), np.float64(2.67), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.21), np.float64(2.5999999999999996), np.float64(3.16), np.float64(-15.16999999999991), np.float64(1.49), np.float64(-0.9100000000000001), np.float64(2.16), np.float64(3.41), np.float64(2.9299999999999997), np.float64(1.16), np.float64(3.3899999999999997), np.float64(1.97), np.float64(2.21), np.float64(3.1399999999999997), np.float64(1.49), np.float64(3.6400000000000006), np.float64(2.79), np.float64(2.1799999999999997), np.float64(3.37), np.float64(2.67), np.float64(2.19), np.float64(1.71), np.float64(1.97), np.float64(2.37), np.float64(2.9299999999999997), np.float64(0.99), np.float64(1.47), np.float64(1.25), np.float64(1.49), np.float64(1.71), np.float64(3.16), np.float64(2.21), np.float64(2.1499999999999995), np.float64(2.19), np.float64(2.69), np.float64(2.19), np.float64(3.41), np.float64(3.41), np.float64(2.4), np.float64(2.69), np.float64(1.73), np.float64(2.69), np.float64(3.15), np.float64(3.38), np.float64(-12.459999999999821), np.float64(3.4), np.float64(1.49), np.float64(2.69), np.float64(2.45), np.float64(2.45), np.float64(2.21), np.float64(1.3699999999999994), np.float64(2.3199999999999994), np.float64(1.25), np.float64(-2.4299999999999864), np.float64(2.41), np.float64(3.0399999999999996), np.float64(2.36), np.float64(3.4), np.float64(2.21), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.41), np.float64(1.73), np.float64(2.45), np.float64(1.0), np.float64(2.0199999999999996), np.float64(1.95), np.float64(1.49), np.float64(2.9299999999999997), np.float64(2.4299999999999997), np.float64(2.42), np.float64(3.05), np.float64(2.69), np.float64(2.67), np.float64(1.97), np.float64(2.45), np.float64(2.2), np.float64(2.13), np.float64(2.6799999999999997), np.float64(3.13), np.float64(2.21), np.float64(3.17), np.float64(2.45), np.float64(1.93), np.float64(3.8900000000000006), np.float64(1.97), np.float64(1.95), np.float64(1.25), np.float64(2.37), np.float64(2.1799999999999997), np.float64(-2.6899999999999995), np.float64(1.0), np.float64(2.45), np.float64(2.92), np.float64(2.6799999999999997), np.float64(0.44999999999999996), np.float64(1.0), np.float64(1.25), np.float64(1.49), np.float64(1.3899999999999995), np.float64(1.97), np.float64(2.9299999999999997), np.float64(1.95), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.65), np.float64(-2.939999999999994), np.float64(2.17), np.float64(1.97), np.float64(-7.509999999999964), np.float64(1.71), np.float64(1.39), np.float64(2.92), np.float64(1.25), np.float64(2.07), np.float64(1.2699999999999998), np.float64(2.87), np.float64(3.15), np.float64(2.55), np.float64(2.69), np.float64(3.17), np.float64(3.17), np.float64(2.21), np.float64(2.86), np.float64(1.73), np.float64(1.97), np.float64(2.69), np.float64(3.17), np.float64(3.17), np.float64(2.88), np.float64(3.870000000000001), np.float64(2.69), np.float64(0.5999999999999999), np.float64(2.41), np.float64(1.95), np.float64(2.45), np.float64(2.9299999999999997), np.float64(2.45), np.float64(2.54), np.float64(2.41), np.float64(1.96), np.float64(1.73), np.float64(1.73), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(2.45), np.float64(1.9099999999999997), np.float64(3.8900000000000006), np.float64(1.49), np.float64(1.71), np.float64(1.49), np.float64(2.78), np.float64(1.97), np.float64(3.15), np.float64(2.4299999999999997), np.float64(2.17), np.float64(2.45), np.float64(1.72), np.float64(2.13), np.float64(3.17), np.float64(3.63), np.float64(3.03), np.float64(3.3899999999999997), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.9299999999999997), np.float64(2.45), np.float64(3.17), np.float64(3.16), np.float64(3.15), np.float64(1.95), np.float64(3.87), np.float64(1.91), np.float64(3.41), np.float64(2.4299999999999997), np.float64(1.49), np.float64(2.45), np.float64(2.45), np.float64(-15.099999999999877), np.float64(2.41), np.float64(2.1399999999999997), np.float64(2.21), np.float64(1.2), np.float64(2.65), np.float64(2.9299999999999997), np.float64(2.1399999999999997), np.float64(2.69), np.float64(0.6599999999999999), np.float64(0.8999999999999999), np.float64(2.45), np.float64(-0.6699999999999993), np.float64(1.73), np.float64(2.38), np.float64(-16.84000000000007), np.float64(-0.7099999999999993), np.float64(2.21), np.float64(2.57), np.float64(-0.6799999999999946), np.float64(2.45), np.float64(1.49), np.float64(1.92), np.float64(3.09), np.float64(2.0199999999999996), np.float64(2.55), np.float64(1.97), np.float64(-0.7800000000000002), np.float64(1.77), np.float64(2.79), np.float64(2.07), np.float64(2.5999999999999996), np.float64(1.73), np.float64(2.21), np.float64(1.71), np.float64(2.67), np.float64(2.21), np.float64(2.45), np.float64(1.49), np.float64(1.97), np.float64(1.97), np.float64(2.69), np.float64(2.21), np.float64(2.79), np.float64(1.97), np.float64(1.73), np.float64(3.6100000000000003), np.float64(1.6499999999999997), np.float64(2.45), np.float64(2.9), np.float64(2.21), np.float64(3.41), np.float64(2.1799999999999997), np.float64(2.19), np.float64(1.97), np.float64(2.69), np.float64(2.88), np.float64(3.16), np.float64(2.21), np.float64(0.6999999999999997), np.float64(2.21), np.float64(2.19), np.float64(1.4899999999999998), np.float64(3.13), np.float64(2.21), np.float64(1.73), np.float64(3.6500000000000004), np.float64(0.06999999999999962), np.float64(2.83), np.float64(2.9), np.float64(2.03), np.float64(1.97), np.float64(3.3899999999999997), np.float64(2.61), np.float64(1.25), np.float64(1.93), np.float64(1.4599999999999997), np.float64(1.0), np.float64(1.97), np.float64(3.17), np.float64(2.69), np.float64(2.69), np.float64(1.97), np.float64(0.99), np.float64(2.9299999999999997), np.float64(2.21), np.float64(2.5999999999999996), np.float64(2.9299999999999997), np.float64(2.69), np.float64(2.3600000000000003), np.float64(2.69), np.float64(1.2899999999999991), np.float64(3.41), np.float64(3.17), np.float64(1.71), np.float64(1.25), np.float64(1.71), np.float64(1.73), np.float64(2.45), np.float64(0.99), np.float64(2.45), np.float64(2.9299999999999997), np.float64(0.6799999999999999), np.float64(1.69), np.float64(3.8900000000000006), np.float64(2.44), np.float64(0.99), np.float64(2.63), np.float64(1.67), np.float64(1.8699999999999999), np.float64(3.16), np.float64(3.17), np.float64(2.67), np.float64(1.25), np.float64(2.16), np.float64(1.7399999999999998), np.float64(2.44), np.float64(1.73), np.float64(2.67), np.float64(1.97), np.float64(2.69), np.float64(3.13), np.float64(1.47), np.float64(2.21), np.float64(3.4), np.float64(2.45), np.float64(1.97), np.float64(1.4), np.float64(2.19), np.float64(3.41), np.float64(1.72), np.float64(-22.960000000000303), np.float64(-11.259999999999913), np.float64(2.45), np.float64(2.79), np.float64(1.5699999999999998), np.float64(0.3300000000000003), np.float64(1.49), np.float64(2.41), np.float64(2.3), np.float64(3.15), np.float64(2.21), np.float64(1.0), np.float64(1.5299999999999998), np.float64(2.91), np.float64(1.73), np.float64(1.97), np.float64(2.62), np.float64(3.6400000000000006), np.float64(2.41), np.float64(1.5899999999999999), np.float64(2.67), np.float64(2.69), np.float64(1.97), np.float64(-8.899999999999954), np.float64(1.68), np.float64(1.97), np.float64(1.0), np.float64(2.92), np.float64(2.19), np.float64(1.97), np.float64(2.15), np.float64(2.45), np.float64(3.09), np.float64(2.91), np.float64(1.25), np.float64(1.0), np.float64(2.41), np.float64(2.45), np.float64(3.09), np.float64(2.9299999999999997), np.float64(2.17), np.float64(2.19), np.float64(1.95), np.float64(1.73), np.float64(2.45), np.float64(3.16), np.float64(2.17), np.float64(2.65), np.float64(1.71), np.float64(2.21), np.float64(2.2), np.float64(1.97), np.float64(3.8900000000000006), np.float64(2.09), np.float64(2.69), np.float64(1.47), np.float64(2.2), np.float64(-2.38999999999999), np.float64(-0.8900000000000006), np.float64(2.12), np.float64(3.17), np.float64(1.97), np.float64(1.97), np.float64(1.25), np.float64(2.9299999999999997), np.float64(2.91), np.float64(2.9299999999999997), np.float64(3.41), np.float64(3.17), np.float64(3.17), np.float64(2.45), np.float64(3.4), np.float64(2.9299999999999997), np.float64(2.21), np.float64(1.8399999999999999), np.float64(2.45), np.float64(3.8900000000000006), np.float64(1.73), np.float64(1.97), np.float64(2.69), np.float64(3.17), np.float64(2.4699999999999998), np.float64(2.19), np.float64(2.84), np.float64(3.4899999999999998), np.float64(3.3899999999999997), np.float64(1.95), np.float64(3.6500000000000004), np.float64(1.4), np.float64(1.2999999999999998), np.float64(3.63), np.float64(2.6799999999999997), np.float64(2.45), np.float64(0.96), np.float64(2.69), np.float64(1.97), np.float64(2.45), np.float64(2.33), np.float64(1.25), np.float64(3.39), np.float64(3.41), np.float64(1.95), np.float64(2.19), np.float64(2.45), np.float64(2.67), np.float64(2.67), np.float64(2.45), np.float64(3.15), np.float64(2.92), np.float64(0.8999999999999999), np.float64(1.49), np.float64(2.69), np.float64(2.69), np.float64(2.45), np.float64(3.17), np.float64(3.88), np.float64(2.19), np.float64(2.45), np.float64(2.1799999999999997), np.float64(1.97), np.float64(3.5599999999999996), np.float64(3.17), np.float64(2.19), np.float64(1.42), np.float64(3.1399999999999997), np.float64(2.69), np.float64(2.67), np.float64(2.21), np.float64(1.73), np.float64(2.19), np.float64(1.97), np.float64(1.73), np.float64(1.92), np.float64(3.16), np.float64(1.95), np.float64(2.92), np.float64(1.5499999999999998), np.float64(2.69), np.float64(1.49), np.float64(2.21), np.float64(2.4299999999999997), np.float64(3.1399999999999997), np.float64(2.2), np.float64(2.2), np.float64(2.41), np.float64(2.19), np.float64(2.45), np.float64(1.49), np.float64(1.97), np.float64(2.45), np.float64(2.9299999999999997), np.float64(1.6099999999999999), np.float64(2.69), np.float64(1.97), np.float64(2.0199999999999996), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.16), np.float64(2.69), np.float64(2.21), np.float64(3.8500000000000005), np.float64(1.97), np.float64(0.2699999999999998), np.float64(1.96), np.float64(2.1799999999999997), np.float64(2.92), np.float64(0.24999999999999978), np.float64(1.47), np.float64(2.69), np.float64(1.73), np.float64(2.6399999999999997), np.float64(3.17), np.float64(2.45), np.float64(2.4299999999999997), np.float64(1.25), np.float64(2.21), np.float64(2.12), np.float64(2.91), np.float64(2.08), np.float64(2.6799999999999997), np.float64(2.45), np.float64(1.94), np.float64(3.4), np.float64(1.49), np.float64(2.67), np.float64(2.21), np.float64(2.69), np.float64(2.1799999999999997), np.float64(2.9299999999999997), np.float64(2.69), np.float64(3.17), np.float64(1.3499999999999999), np.float64(1.49), np.float64(1.9), np.float64(1.95), np.float64(2.45), np.float64(3.15), np.float64(2.45), np.float64(2.21), np.float64(3.6500000000000004), np.float64(2.28), np.float64(2.45), np.float64(1.97), np.float64(2.45), np.float64(2.69), np.float64(2.21), np.float64(1.71), np.float64(3.17), np.float64(2.21), np.float64(2.4299999999999997), np.float64(1.47), np.float64(-0.1100000000000001), np.float64(-1.729999999999979), np.float64(3.31), np.float64(-13.149999999999844), np.float64(2.7699999999999996), np.float64(2.9699999999999998), np.float64(2.11), np.float64(1.1399999999999995), np.float64(2.3999999999999995), np.float64(2.16), np.float64(2.16), np.float64(1.49), np.float64(1.97), np.float64(3.5700000000000003), np.float64(2.2), np.float64(1.19), np.float64(1.97), np.float64(2.4499999999999997), np.float64(2.12), np.float64(1.8499999999999999), np.float64(1.97), np.float64(1.71), np.float64(-0.42000000000000015), np.float64(2.44), np.float64(3.09), np.float64(1.0), np.float64(0.8799999999999998), np.float64(1.0), np.float64(2.67), np.float64(1.25), np.float64(3.17), np.float64(2.16), np.float64(1.95), np.float64(2.6799999999999997), np.float64(2.17), np.float64(2.21), np.float64(2.69), np.float64(0.69), np.float64(1.49), np.float64(3.39), np.float64(1.7799999999999998), np.float64(2.9299999999999997), np.float64(2.65), np.float64(2.6399999999999997), np.float64(2.09), np.float64(1.73), np.float64(2.45), np.float64(1.97), np.float64(2.9299999999999997), np.float64(2.4699999999999998), np.float64(3.17), np.float64(1.25), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.0), np.float64(3.88), np.float64(1.0), np.float64(3.17), np.float64(2.45), np.float64(3.8500000000000005), np.float64(3.13), np.float64(3.63), np.float64(3.6500000000000004), np.float64(3.6500000000000004), np.float64(2.67), np.float64(2.69), np.float64(1.49), np.float64(2.21), np.float64(3.6399999999999997), np.float64(1.25), np.float64(2.0999999999999996), np.float64(1.14), np.float64(1.73), np.float64(1.73), np.float64(2.45), np.float64(1.49), np.float64(2.19), np.float64(2.19), np.float64(1.64), np.float64(3.88), np.float64(2.19), np.float64(2.4299999999999997), np.float64(2.45), np.float64(2.79), np.float64(1.1199999999999999), np.float64(1.8399999999999999), np.float64(2.69), np.float64(2.61), np.float64(0.9399999999999997), np.float64(2.67), np.float64(2.9299999999999997), np.float64(-0.4200000000000004), np.float64(3.17), np.float64(2.69), np.float64(1.25), np.float64(2.45), np.float64(2.3999999999999995), np.float64(2.21), np.float64(1.73), np.float64(2.6799999999999997), np.float64(0.5899999999999992), np.float64(2.69), np.float64(2.17), np.float64(2.66), np.float64(2.69), np.float64(2.62), np.float64(2.21), np.float64(1.49), np.float64(1.97), np.float64(1.7199999999999993), np.float64(0.96), np.float64(1.9), np.float64(1.95), np.float64(2.2), np.float64(2.9299999999999997), np.float64(2.21), np.float64(3.41), np.float64(2.9299999999999997), np.float64(1.73), np.float64(1.49)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "goal = {\n",
        "    (1,7): 100\n",
        "}\n",
        "\n",
        "obs = {\n",
        "    (1,1):-50,\n",
        "    (4,3):-50,\n",
        "    (2,4):-50\n",
        "}\n",
        "\n",
        "env = GridWorld(obs=obs, goal=goal, rows=9, cols=9, episode_steps=1000)\n",
        "\n",
        "agent = Agent()\n",
        "trained_dict, rewards, losses = run_training(env, agent, num_episodes=10000)\n",
        "print(rewards)\n",
        "plot_training(rewards, losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA31opzJJDko",
        "outputId": "6a2c8a14-48e4-4815-d3d6-80a85ce8cee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting episode  0\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  1\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  2\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  3\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  4\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  5\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  6\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  7\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  8\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  9\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  10\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  11\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  12\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  13\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  14\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  15\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  16\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  17\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  18\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  19\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  20\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  21\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  22\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  23\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  24\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  25\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  26\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  27\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  28\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  29\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  30\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  31\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  32\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  33\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  34\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  35\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  36\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  37\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  38\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  39\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  40\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  41\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  42\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  43\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  44\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  45\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  46\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  47\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  48\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  49\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  50\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  51\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  52\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  53\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  54\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  55\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  56\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  57\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  58\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  59\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  60\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  61\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  62\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  63\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  64\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  65\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  66\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  67\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  68\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  69\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  70\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  71\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  72\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  73\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  74\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  75\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  76\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  77\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  78\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  79\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  80\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  81\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  82\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  83\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  84\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  85\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  86\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  87\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  88\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  89\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  90\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  91\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  92\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  93\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  94\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  95\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  96\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  97\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  98\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  99\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  100\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  101\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  102\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  103\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  104\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  105\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  106\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  107\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  108\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  109\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  110\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  111\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  112\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  113\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  114\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  115\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  116\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  117\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  118\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  119\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  120\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  121\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  122\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  123\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  124\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  125\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  126\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  127\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  128\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  129\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  130\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  131\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  132\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  133\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  134\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  135\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  136\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  137\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  138\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  139\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  140\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  141\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  142\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  143\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  144\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  145\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  146\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  147\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  148\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  149\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  150\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  151\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  152\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  153\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  154\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  155\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  156\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  157\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  158\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  159\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  160\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  161\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  162\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  163\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  164\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  165\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  166\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  167\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  168\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  169\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  170\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  171\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  172\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  173\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  174\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  175\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  176\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  177\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  178\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  179\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  180\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  181\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  182\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  183\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  184\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  185\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  186\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  187\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  188\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  189\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  190\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  191\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  192\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  193\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  194\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  195\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  196\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  197\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  198\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  199\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  200\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  201\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  202\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  203\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  204\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  205\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  206\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  207\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  208\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  209\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  210\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  211\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  212\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  213\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  214\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  215\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  216\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  217\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  218\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  219\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  220\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  221\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  222\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  223\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  224\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  225\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  226\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  227\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  228\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  229\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  230\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  231\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  232\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  233\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  234\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  235\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  236\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  237\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  238\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  239\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  240\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  241\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  242\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  243\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  244\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  245\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  246\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  247\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  248\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  249\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  250\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  251\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  252\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  253\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  254\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  255\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  256\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  257\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  258\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  259\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  260\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  261\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  262\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  263\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  264\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  265\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  266\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  267\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  268\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  269\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  270\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  271\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  272\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  273\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  274\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  275\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  276\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  277\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  278\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  279\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  280\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  281\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  282\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  283\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  284\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  285\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  286\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  287\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  288\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  289\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  290\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  291\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  292\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  293\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  294\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  295\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  296\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  297\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  298\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  299\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  300\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  301\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  302\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  303\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  304\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  305\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  306\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  307\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  308\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  309\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  310\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  311\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  312\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  313\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  314\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  315\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  316\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  317\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  318\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  319\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  320\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  321\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  322\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  323\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  324\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  325\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  326\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  327\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  328\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  329\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  330\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  331\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  332\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  333\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  334\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  335\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  336\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  337\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  338\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  339\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  340\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  341\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  342\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  343\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  344\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  345\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  346\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  347\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  348\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  349\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  350\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  351\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  352\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  353\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  354\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  355\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  356\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  357\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  358\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  359\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  360\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  361\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  362\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  363\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  364\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  365\n",
            "episode complete, reward:  0.88 , failed to solve:  False\n",
            "starting episode  366\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  367\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  368\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  369\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  370\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  371\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  372\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  373\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  374\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  375\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  376\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  377\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  378\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  379\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  380\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  381\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  382\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  383\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  384\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  385\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  386\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  387\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  388\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  389\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  390\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  391\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  392\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  393\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  394\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  395\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  396\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  397\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  398\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  399\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  400\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  401\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  402\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  403\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  404\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  405\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  406\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  407\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  408\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  409\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  410\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  411\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  412\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  413\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  414\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  415\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  416\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  417\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  418\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  419\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  420\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  421\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  422\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  423\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  424\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  425\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  426\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  427\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  428\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  429\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  430\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  431\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  432\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  433\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  434\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  435\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  436\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  437\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  438\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  439\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  440\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  441\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  442\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  443\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  444\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  445\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  446\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  447\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  448\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  449\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  450\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  451\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  452\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  453\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  454\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  455\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  456\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  457\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  458\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  459\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  460\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  461\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  462\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  463\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  464\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  465\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  466\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  467\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  468\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  469\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  470\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  471\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  472\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  473\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  474\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  475\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  476\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  477\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  478\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  479\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  480\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  481\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  482\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  483\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  484\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  485\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  486\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  487\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  488\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  489\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  490\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  491\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  492\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  493\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  494\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  495\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  496\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  497\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  498\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  499\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  500\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  501\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  502\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  503\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  504\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  505\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  506\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  507\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  508\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  509\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  510\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  511\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  512\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  513\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  514\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  515\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  516\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  517\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  518\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  519\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  520\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  521\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  522\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  523\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  524\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  525\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  526\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  527\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  528\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  529\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  530\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  531\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  532\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  533\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  534\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  535\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  536\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  537\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  538\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  539\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  540\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  541\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  542\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  543\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  544\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  545\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  546\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  547\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  548\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  549\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  550\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  551\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  552\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  553\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  554\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  555\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  556\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  557\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  558\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  559\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  560\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  561\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  562\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  563\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  564\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  565\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  566\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  567\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  568\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  569\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  570\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  571\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  572\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  573\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  574\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  575\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  576\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  577\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  578\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  579\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  580\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  581\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  582\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  583\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  584\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  585\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  586\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  587\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  588\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  589\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  590\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  591\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  592\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  593\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  594\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  595\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  596\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  597\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  598\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  599\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  600\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  601\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  602\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  603\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  604\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  605\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  606\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  607\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  608\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  609\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  610\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  611\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  612\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  613\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  614\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  615\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  616\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  617\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  618\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  619\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  620\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  621\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  622\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  623\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  624\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  625\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  626\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  627\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  628\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  629\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  630\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  631\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  632\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  633\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  634\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  635\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  636\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  637\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  638\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  639\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  640\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  641\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  642\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  643\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  644\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  645\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  646\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  647\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  648\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  649\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  650\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  651\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  652\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  653\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  654\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  655\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  656\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  657\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  658\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  659\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  660\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  661\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  662\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  663\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  664\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  665\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  666\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  667\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  668\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  669\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  670\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  671\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  672\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  673\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  674\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  675\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  676\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  677\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  678\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  679\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  680\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  681\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  682\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  683\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  684\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  685\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  686\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  687\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  688\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  689\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  690\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  691\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  692\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  693\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  694\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  695\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  696\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  697\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  698\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  699\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  700\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  701\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  702\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  703\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  704\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  705\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  706\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  707\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  708\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  709\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  710\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  711\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  712\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  713\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  714\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  715\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  716\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  717\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  718\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  719\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  720\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  721\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  722\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  723\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  724\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  725\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  726\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  727\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  728\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  729\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  730\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  731\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  732\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  733\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  734\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  735\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  736\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  737\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  738\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  739\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  740\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  741\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  742\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  743\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  744\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  745\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  746\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  747\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  748\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  749\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  750\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  751\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  752\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  753\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  754\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  755\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  756\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  757\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  758\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  759\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  760\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  761\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  762\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  763\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  764\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  765\n",
            "episode complete, reward:  0.87 , failed to solve:  False\n",
            "starting episode  766\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  767\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  768\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  769\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  770\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  771\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  772\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  773\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  774\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  775\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  776\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  777\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  778\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  779\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  780\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  781\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  782\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  783\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  784\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  785\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  786\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  787\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  788\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  789\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  790\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  791\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  792\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  793\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  794\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  795\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  796\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  797\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  798\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  799\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  800\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  801\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  802\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  803\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  804\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  805\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  806\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  807\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  808\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  809\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  810\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  811\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  812\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  813\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  814\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  815\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  816\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  817\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  818\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  819\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  820\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  821\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  822\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  823\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  824\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  825\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  826\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  827\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  828\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  829\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  830\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  831\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  832\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  833\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  834\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  835\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  836\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  837\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  838\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  839\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  840\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  841\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  842\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  843\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  844\n",
            "episode complete, reward:  0.88 , failed to solve:  False\n",
            "starting episode  845\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  846\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  847\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  848\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  849\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  850\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  851\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  852\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  853\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  854\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  855\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  856\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  857\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  858\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  859\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  860\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  861\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  862\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  863\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  864\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  865\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  866\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  867\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  868\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  869\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  870\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  871\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  872\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  873\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  874\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  875\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  876\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  877\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  878\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  879\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  880\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  881\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  882\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  883\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  884\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  885\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  886\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  887\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  888\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  889\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  890\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  891\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  892\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  893\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  894\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  895\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  896\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  897\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  898\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  899\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  900\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  901\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  902\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  903\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  904\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  905\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  906\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  907\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  908\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  909\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  910\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  911\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  912\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  913\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  914\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  915\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  916\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  917\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  918\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  919\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  920\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  921\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  922\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  923\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  924\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  925\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  926\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  927\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  928\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  929\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  930\n",
            "episode complete, reward:  1.0 , failed to solve:  False\n",
            "starting episode  931\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  932\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  933\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  934\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  935\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  936\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  937\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  938\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  939\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  940\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  941\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  942\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  943\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  944\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  945\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  946\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  947\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  948\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  949\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  950\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  951\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  952\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  953\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  954\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  955\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  956\n",
            "episode complete, reward:  0.89 , failed to solve:  False\n",
            "starting episode  957\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  958\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  959\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  960\n",
            "episode complete, reward:  0.91 , failed to solve:  False\n",
            "starting episode  961\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  962\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  963\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  964\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  965\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  966\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  967\n",
            "episode complete, reward:  0.97 , failed to solve:  False\n",
            "starting episode  968\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  969\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  970\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  971\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  972\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  973\n",
            "episode complete, reward:  0.88 , failed to solve:  False\n",
            "starting episode  974\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  975\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  976\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  977\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  978\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  979\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  980\n",
            "episode complete, reward:  0.99 , failed to solve:  False\n",
            "starting episode  981\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  982\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  983\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  984\n",
            "episode complete, reward:  -0.21000000000000005 , failed to solve:  True\n",
            "starting episode  985\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  986\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  987\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  988\n",
            "episode complete, reward:  0.96 , failed to solve:  False\n",
            "starting episode  989\n",
            "episode complete, reward:  0.92 , failed to solve:  False\n",
            "starting episode  990\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  991\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  992\n",
            "episode complete, reward:  0.0 , failed to solve:  True\n",
            "starting episode  993\n",
            "episode complete, reward:  0.95 , failed to solve:  False\n",
            "starting episode  994\n",
            "episode complete, reward:  0.98 , failed to solve:  False\n",
            "starting episode  995\n",
            "episode complete, reward:  0.94 , failed to solve:  False\n",
            "starting episode  996\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "starting episode  997\n",
            "episode complete, reward:  0.0 , failed to solve:  False\n",
            "starting episode  998\n",
            "episode complete, reward:  0.9 , failed to solve:  False\n",
            "starting episode  999\n",
            "episode complete, reward:  0.9299999999999999 , failed to solve:  False\n",
            "failed to reach goal:  151\n"
          ]
        }
      ],
      "source": [
        "#Evaluate!\n",
        "\n",
        "def eval_dqn(state_dict, env, agent, num_eps, obs_range):\n",
        "    actions = agent.action_space\n",
        "    input_size = (2*obs_range + 1)**2 + 4\n",
        "    num_actions = len(actions)\n",
        "\n",
        "    eval_policy_net = DQN(input_size, num_actions).to(device)\n",
        "    eval_policy_net.load_state_dict(state_dict)\n",
        "    eval_policy_net.eval()\n",
        "    fail_count = 0\n",
        "\n",
        "    for ep in range(num_eps):\n",
        "        print(\"starting episode \", ep)\n",
        "        env.reset_random(6, env.goal_positions[0])\n",
        "        agent.reset((random.randint(1, env.rows-2), random.randint(1, env.cols-2)))\n",
        "        ep_reward = 0.0\n",
        "        fail = False\n",
        "        step = 0\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while(agent.position not in env.goal_positions):\n",
        "                state = encode_local_state(agent.position, env.goal_positions[0], env.grid, obs_range)\n",
        "                state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "                q_vals = eval_policy_net(state_tensor)\n",
        "                action_idx = q_vals.argmax(1).item()\n",
        "\n",
        "                if(agent.position in env.obstacle_positions or step > 20):\n",
        "                  fail=True\n",
        "                  fail_count = fail_count + 1\n",
        "                  break\n",
        "\n",
        "                action = actions[action_idx]\n",
        "                next_pos = agent.move(action, env)\n",
        "                reward = env.get_reward(next_pos)\n",
        "                ep_reward += reward\n",
        "                step += 1\n",
        "\n",
        "\n",
        "        print(\"episode complete, reward: \", ep_reward, \", failed to solve: \", fail)\n",
        "    print(\"failed to reach goal: \", fail_count)\n",
        "\n",
        "\n",
        "\n",
        "eval_dqn(trained_dict, env, agent, 1000, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0_tWqF0RxC5"
      },
      "outputs": [],
      "source": [
        "#visualize an episode!\n",
        "from celluloid import Camera\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_episode(state_dict, env, agent, obs_range, start_pos=(2, 8), goal_pos=(1,7)):\n",
        "    scale = 1\n",
        "    fig, ax = plt.subplots(figsize=(env.cols * scale, env.rows * scale))\n",
        "    camera = Camera(fig)\n",
        "\n",
        "    ax.set_xlim(0, env.cols)\n",
        "    ax.set_ylim(0, env.rows)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xticks(np.arange(0, env.cols + 1, 1))\n",
        "    ax.set_yticks(np.arange(0, env.rows + 1, 1))\n",
        "    ax.invert_yaxis()\n",
        "    ax.grid(True)\n",
        "\n",
        "    obs = env.obstacle_positions\n",
        "    bounds = env.bound_positions\n",
        "    goal = env.goal_positions[0]\n",
        "    anim = Move_anim(ax, camera, obs, goal, bounds, invert=True)\n",
        "\n",
        "    actions = agent.action_space\n",
        "    input_size = (2 * obs_range + 1) ** 2 + 4\n",
        "    num_actions = len(actions)\n",
        "\n",
        "    eval_policy_net = DQN(input_size, num_actions).to(device)\n",
        "    eval_policy_net.load_state_dict(state_dict)\n",
        "    eval_policy_net.eval()\n",
        "\n",
        "    env.reset_random(6, goal_pos)\n",
        "    agent.reset(start_pos)\n",
        "    ep_reward = 0\n",
        "    print(\"Goal\", env.goal_positions[0])\n",
        "    print(\"Agent Position\", agent.position)\n",
        "\n",
        "    while agent.position != env.goal_positions[0]:\n",
        "        state = encode_local_state(agent.position, env.goal_positions[0], env.grid, obs_range)\n",
        "        state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            q_vals = eval_policy_net(state_tensor)\n",
        "            action_idx = q_vals.argmax(1).item()\n",
        "\n",
        "        action = actions[action_idx]\n",
        "        print(action)\n",
        "\n",
        "        # Animate agent movement\n",
        "        r, c = agent.position\n",
        "        if action == \"right\":\n",
        "            anim.right(c+.5, r+.5)\n",
        "        elif action == \"left\":\n",
        "            anim.left(c+.5, r+.5)\n",
        "        elif action == \"up\":\n",
        "            anim.up(c+.5, r+.5)\n",
        "        elif action == \"down\":\n",
        "            anim.down(c+.5, r+.5)\n",
        "\n",
        "        next_pos = agent.move(action, env)\n",
        "        reward = env.get_reward(next_pos)\n",
        "        ep_reward += reward\n",
        "\n",
        "    print(\"Episode complete, reward:\", ep_reward)\n",
        "    animation = camera.animate()\n",
        "    plt.close(fig)\n",
        "    return HTML(animation.to_html5_video())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqPcsD4AFN5r",
        "outputId": "34653fdb-681d-4e81-f4b2-deafc2fea44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.4   1.   -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.4  -0.01 -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.4  -0.01 -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.4  -0.01 -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.4  -0.4  -1.  ]\n",
            " [-1.   -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -1.  ]\n",
            " [-1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.  ]]\n",
            "[[-1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  0  0  0  0  0 -1  1 -1]\n",
            " [-1  0  0  0  0  0 -1  0 -1]\n",
            " [-1  0  0  0  0  0  0  0 -1]\n",
            " [-1  0  0  0  0  0 -1  0 -1]\n",
            " [-1  0  0  0  0  0 -1  0 -1]\n",
            " [-1  0  0  0  0  0 -1 -1 -1]\n",
            " [-1  0  0  0  0  0  0  0 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
            "(np.int64(1), np.int64(7))\n"
          ]
        }
      ],
      "source": [
        "#Test your Random Reset!\n",
        "\n",
        "env = GridWorld(obs=obs, goal=goal, rows=9, cols=9)\n",
        "env.reset_random(6, (1,7))\n",
        "print(env.grid)\n",
        "print(env.map_grid)\n",
        "print(env.goal_positions[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_episode(trained_dict, env, agent, 2, start_pos=(7, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wuwoGzCeBQox",
        "outputId": "ec7daf8e-abf8-45ce-9537-0b7e20a1162c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Goal (np.int64(1), np.int64(7))\n",
            "Agent Position (7, 1)\n",
            "up\n",
            "right\n",
            "right\n",
            "right\n",
            "right\n",
            "up\n",
            "up\n",
            "up\n",
            "right\n",
            "up\n",
            "up\n",
            "right\n",
            "Episode complete, reward: 0.89\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"900\" height=\"900\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAXvRtZGF0AAACrQYF//+p\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMg\n",
              "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
              "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
              "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
              "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTUgc2NlbmVjdXQ9NDAgaW50cmFfcmVm\n",
              "cmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42\n",
              "MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAADfX\n",
              "ZYiEABL//vet34FNwEDta7pXOLTLq5Q0PVH2lKZ4tkgAAAMAAAMAAAMAAIdefBwV1r6NgTIAAAMA\n",
              "AXoAIiAKGAR4AxrU/ZoudvcwENfXKnehyrXTb23QY+fPliGscPZzgENjhnCXmUno4GMs0rpJsLFB\n",
              "ES9Oy4Nwk5d3HfVJcQF8HsLh72qIEp75J5vNcLG29hJwO/NfJLYor6vwaK/AvsTYR0oAhl4BBpp0\n",
              "27jtEs7435pXYNsiV2sNhPfEficr2wNmlf85oc5h3rZCTo8mMZWNKPshf9e9ykHWfhGU4AKTPzXM\n",
              "TMWIdNcRyMhm1tiYlObCeNWRBau13DlJqLezF9k8Er9aK9q9gsCexuqGwGxvetRTS/LA9q1zP7bF\n",
              "YVpJHFlp2bDm4XcFG9DP072iITbO6uVkhWUbTjzEjOsTlcvTMZy4caaFsiYk2LZyMOYzz/LuD/VI\n",
              "AszRei2COW9aFuQmage1Z7T7/KxBEQi0QvrkCfE+1BhiMhB1/C6px7NHf7ZaTIiBAE3qjPx8CFfW\n",
              "oIgVM+8TyusmHuvfvj3oZIm93O8dTEUS6nzL2OMI8JueUDO+H/LZ/Y2k/td7HayWZY+LN6hE4L/v\n",
              "QMk78PKspaJwLETkV0fqu7kR9nwxSqowqG9gw51Ss1ehs/gFaVkqNtujJmWMOoPK5DS4z+slkA+z\n",
              "Le0zvCnzQTVR6Z3I57m8OL8Hzo9GtSDLx6B9kLOvoQRGuutoTD+LKtFzGV2Kk9kpYWsVW2vBlyL6\n",
              "PX1GnrJlLNBO0vDDJQYXGWIfmxjhxgo4QF6MDnzZEo2Nl0oinKh0tbayLlikwyKUrpP2mT0oz7Bp\n",
              "EkuBEaVh2gC+x3AGQ+YIr4eG1j49V4hAktr3jhT/kJltVGgrlVFlDl8t5008olxufD+Cu4CfbEXU\n",
              "Wb7MhjDIivtQc7vEK5HXWbEi5W1e/qSDOwYmmQJk/4Hpsb+foCSeT1OxkLDR2p/eMNnWl+u1qQg2\n",
              "pkXacAvUvcTxDV52m+8Ft0F1qmK5rUGGhJQUSfd7ZpfnRQOEaZIJXOLyEEallXq2JPqOxIiosLR9\n",
              "Rzg0MQR7JZMsoGzMSBjRKG2fgy5F9Hr6jUUI+mMWZV6oJ5fnrWxgRPyhnO63ixQUNOY2wrqN/r7C\n",
              "ghuqnyR2val62bXiOQXl/JyeS30qxdCiXiPAkoRBAijP8E3bfYBP6P09tb9UnbmeBI7GaUIRVF7a\n",
              "vfhUN20j3mtEoM4sZBO0HXxEQo6HBqnDtdbXso7OYxRlolUhS3+iXRJXP0pex8OPniNgLbsGzDq+\n",
              "H2i2YEUbTYNf5SD2xZkQ7M8hqWZ8rat0Wl+uUv70zHI20rAnNv8mlWc8avrNzE564VxuruSwOgSX\n",
              "JxvvzfyoAGZhkiJXZNTF0EJSToMOodlrSu48fs+YSXtbYenLBZXZ6RAKVsxsuWvhBbvhBmmXH/WH\n",
              "fKbPjX2qey0rOi/tLZmNfZwRd/rBZCJmnplIEZ47pa0bZmb5KpHniz6slTLyBT2EKJw9WOXSkiVW\n",
              "cpZ+/ro/xd9Upg4JRuz5ntA09keYHbpOfNFPhgSj0lbQCHHMAiW4Ov7+Q9jj1MvE5WsIqut+9GpY\n",
              "MDD4NqxI2cwfLlsRSH7pYPdaFlWZIIwLKKfrW4BQMSFdO2avqKO15zAkVcVWMuZ/+amqcyBcvM09\n",
              "I+6vHP0OVfy6ehmPcxXpMO+MvJcebIdn2wB0khznox/FSqBWgJTygkkc1fMqEgOzyErhRKyn3Giq\n",
              "KfUJ+JTOtm5ceeYSFxG1x8vtSy9cC4dksroevgELyReZRL7DvxugkdoP8GPvL0pH5a39O/6eRUvn\n",
              "+6GCIC1xxx6MiWkIneyootJCaE4H+0bt93DQ2uw3KXZ0v7pXeKTWD73UNFIRLE9WExuuA1brXYZE\n",
              "tNjxiNIC6G0FGVN09ysf4n4JTFVjwGHFIf3/3QDFXLN3bJL1zO2pmdulNKfM6E31Q0hTVg//vNPM\n",
              "cQ8m83/CJ0kUkHek2P/HQldY3r5l4RELJYqVoru/fVga1r35UVdQHziSog9108cAZui/DGAjgbWd\n",
              "LmT57Zy01x9yOTriNX25xG5WfIaOfv2A1dSmuVhxJv+tZdU6vuvyaa+gMFCjOJ2Up8hAB/omov6c\n",
              "0OCH/9s5r8TaVM+XPxK3QUmcf0uqRbv2fqfPPkSWtWn1yuFftA0aP6yY6VWBZQBNCPZrOKPJTPMs\n",
              "dvojpSP2IbZ3/basyYedK3pySJzIps88HaZC4mx/x0vZYwkTfB3GMZ5yo9SmQDXCvCEFRzKO6MvX\n",
              "sjnTSfH4/i81GgrjekJCukA2TQcW0Ag4ukCRwxW2uvK7u4eRCXZnnmGzXyhuajbxvOY86vAxHi06\n",
              "8eQW/1z93zA6wZy9qtpqK8Gn1IYP6UlpjlGr1Oos8+IldM47su4bdb+mlw0gcUkXLGPvKD4bxMZ2\n",
              "ucVg/Go7CVjNsrkTyVAX8KMbniDz4G8vQ//iBVREqD07JJdq2F6IJKWjqjHKY7QMqBUDIN7qHk2G\n",
              "JOCEYhQkgLtJab1J8cx7Dm2cR2ryccXQMOEr5nvo+328Wgj7nFYNrHITj6Eu+6pzwJKfvf2GFdN9\n",
              "5kUjjSXJEs38Jzyxrdp3ahBTI+lPJOS6U7bf/pCs2HTljjuiRDhDgXqKcK2FMuQADkdJq+ueyXCd\n",
              "r0fWzwAbmlfYI3/kdSxrNoirLDqUwSua5/FIlPQzNARl4tjOJ2Dyr7rGuv4GrPTJNlJIP2T2/iZc\n",
              "ca0SZp1OQtM0Ga2nnM8iEzLF2hacc0DYGMECVtypsnQKqBqPAZUJyZ/OaDx0x8Hs2QHFlAU+1H4z\n",
              "DtDGrauVPS67MlXOkn9lIYMNP/NtEdOJZsTmriP5P6pCNtSShqEFeqh1VRf/UAF0nUxj8Wtmswak\n",
              "4NEAAJW1s4raWcxCBI4d3HOjwaHsx7ZgV4NGSOVZe93V7e6pBMhWpyCaR1f7wk2hqH1tKlG/fP+C\n",
              "33RasdlmPgg6F8QK1v3eNvAaIBshXHehf3K3/PmwJJTXrJRj7f+l+Jkfx/RfFs17///AB270iz/Y\n",
              "B+G2O2kX7wYQAOHu1BAfemw1P3ikBlDwYKOVKztyO7kHr+E89Q7UfMk17dNN/bnLz/TE3VSz2r2v\n",
              "/+8eHLPu02IpCsiss8zTK1gNE/+emEPCelPqlTzX5uVaWkLLNmmiFhyQHeaTT9JsOLMpU2UqH/Yp\n",
              "/rquVdBYXpYyErmXjatyQhCjgd0U7hUu//4jj062GCeVbEmD0ZplawGif/Ufn/zqU+qUiKz7MWxg\n",
              "0tFDtQX/p17f5ghQIMTAOEj9nj//9BXnm5YvAS523raP/5pn8gq3+erP/uX63rTz/FHxgMMJlqDH\n",
              "pLe/h0eOoBnbUGIXwRqup/GCThbg4cbkBelbuAhkhUMrE4UpYJGCqVtqLCb5FFjsuc7/wYDKiOB+\n",
              "/5LG6G11JT4VvdbubNxX6M/KcSziDc5Pf3pnoO5dNA19ah7oD4XpF32ZpBkpRsSaDC2B7P+RWj1g\n",
              "npQ9FuI/7OLSOP/9GLv4jG3fnG8l9Nv8Iz+fl2uxob7YDfe3cTYBjv6+vbSmyp0C1OhP4lmh1ppw\n",
              "6U6Ek+KL3AfTLNUUR8+el6Wtl0TD5iD37p/q8EMJoyWBnfzhn9FhQ8BRhsDDoJv4q8sFz3AfA9V+\n",
              "fcx5tG/l7Qb7qIDluIo2MB7hAcrUYHBbsXk0BrUy6VMsJVBs3zTz4avjE0JqtSdAxczRWxCC+ILy\n",
              "oXtHbbCbZhSgWEZM6kWWBpprDgp0BlLvGmTk6nTP6tHgdAYicaPYOd9054ZJ438ZsDBYqQ6Boknd\n",
              "yX3khOlf9eJ6tX7fNpJ77H3N4QqT90M75KRHGJjrJkM0yyKFDUWb7PPxjvJNQonCIUFfanQtDddl\n",
              "hYNSsZgTdh7WJzFHdt/xTY1gryzgUF0DHxZ8/jq3mN8idBPJg2NwbiWrjXOMZJ5eBHROg3e+dTfw\n",
              "bwjzAElHCfOKClb1/9E5nSYhLWqxyFdUAlBbLIsAJzxiDqZImPuZVaf8KGTjKGcQuNKWaEX+iFPS\n",
              "e9Mn9hNnORwK6YkDZBjRQMykRB1aK2mxRwXmHc113jie+IBwqGZm8CBn1EV4gGxP0JwR9P/34h4e\n",
              "dD3jzn6Zj4AT1t1dDdeydydpqUjdOjZvJKsmFfUI4sbp2mEaNRvMaZurmiv/M5NunmqfwCPOvhRV\n",
              "HMSezSq69vPTt16S6jcObzgxz1QpUpWvj8XlKGABHI2SB4sD45ZgWRvnDBWXZBxQlwxoe6Fwlrda\n",
              "e/8fnsidE1WOn7St2RVFYy6wLK2LS7JrO/ZuWZNnyVEBymph7lyv0JZSMgJdsJ9D5UIHkRHSg+Kw\n",
              "13a/bnGxM8o2SPKK0iPN2zGFfV02gC/rfQC8xfoOQHiHVOEM19gipjHv1XEAUjkzj382kcQ8eCNZ\n",
              "4xzZt98j39kXXUZVuNiLccdKXa/VxAnNyEQmWlFlKbSL6wS7pTnEjeScr4/5yHGzRgFR0pvhlIex\n",
              "/jF9MKzwxiEU+AAEtCIM4AsLkI5m+hfuokmeLjX9dD9TycFDbBRWdOptDIUG4YDv/f/7a8ZQBteX\n",
              "uuXtZPDSMKN5k5BYo2Eut1fKWeFv8sqjuHAzoetcHJ+CkzVNzb3ziqRFeV7CiaOhQCTjjPNHbpaJ\n",
              "L4Zex8wwtLiQa8RHwyObsITcwSGbi8MkKrBN3/9rqi5CFTqSJAK2Cf2RNPCLuygfSllzhmdbEiO0\n",
              "cYdhgRALpjujavdWZ0kSaknwuyt0TCvrYLqBuNvKTPqv+VD+CHUTdA19gPIgVvc7rnHq2u6Q9ZEo\n",
              "93ZPbVnrX2I9W6hdiUUYARnP+KhJg8sBpgzxV7TLB6r7x23Ifg1hhHFxAK7C3fXTD3D0DRVuozSg\n",
              "b9gchDSYoLJyzUvURG6EH7+4BVpIDwXtsubeRYmPeH4DbHJdgltweSXyT+V+Czh48oP3H/+G6ELk\n",
              "qfVIhesNGj06VMtGOhJUR4A1Jnss7hE2TTMf1YWif9IdqJi/94Z2iJCaD3Z8xiHlnx4BsdyLe8Xa\n",
              "Ky7Hs+KgaoO9k9YbjsHr2X2AXzfxDEz9dDA5W6+rMatRbhn65pDI+0FAShkwOBXvGk+4falaChgs\n",
              "epeqFcOxmYeW9LdqQdYC+vLtxhaMlE5rECTy1aqxWes0AFgRK01ddk6Y0/8PYGdBZH3e906QIcC5\n",
              "jo00BroHb9uYaxWuLna4nJdVzqs76TSESDZ7gNaDJ0rlcu4nwAcr7yO7zFsNii2EyI5ItVhGOAOE\n",
              "txe0epC0a8lgv4p3j8qBzaDsE3BsVour394CRdFsSmethXhaK3qrGi+IJyqqtST20DPghThy1+6P\n",
              "BJNs3FlucL7k9m/dI/Bgp/sgyy/n4JF0lOLaPJUVVCosqjdOm/8MLhlAcnE6sxOIosGDPoLT6zU9\n",
              "xUuX3v8BZh+mfXUc1IEUTLcT8oAGWY73gfdvbQuf+YE1YWzipv1Kz8MUOlaGmLrn2l7tec9R0UMO\n",
              "xxVYcbjnhsV8XriAu63ABT8UqsCVUJFZyhKEgqbV/gEJtzZWFmPYNOF8Lq1dov1Guyd91vZMwVBt\n",
              "W0gVGJkR69b0HbrL/cHgFC7BiNb3X1GMOZxm5mZcQLMTpoARb5ZH5oAtzVA73L8pU4o7HwlHYXQ5\n",
              "LHgSK1+b/YDcwYXYLFTlqaNH1mXfFDUjhcEVjD995nBssEp09WOzPhZEbsIW/cS2C3gItdoqRpPw\n",
              "SBn7vTUqmU9DKXw4fdYdcro1e4icE6dSQHe/sVyPQ9KmOPxEWN5B2k44QaW/k2LoxMdtG56wkKpU\n",
              "uBL0MCtpMwYbAjlZyCcR8ZtCTfXUleGz958pKYhDBlbTORV7TbF3e0Cd3M1h6IaUZU10MkriqOf9\n",
              "7yIFeqt/PStTYoSa/FrUi19UH+36JA3Upws/1fvFwJv2hwFSYevFIixDamvXczrD5aeFR5pryv4/\n",
              "aMNUJe/xJjar2V5FuP008nCUkYxPGs2L+CsXOnn6/l/CD/h3sCtocskfrRa4dCMxG1xsPZMNRwDQ\n",
              "c9Tz4ynrTUsLzeNBsiXGO6P7DfDIkJ3UBP14w9/2lVPcxLcPNTD7pGXcatY8wizP1MwusWscW/wn\n",
              "5sbVLAW/twGWpaADwYRQUWjhxB0zxSzuKZMOmDjWELzsVYDtkMFCpfVi+fHwqKwcfnzr8+teHd/j\n",
              "qst995n6oo+8waHpPzN4eBdpWnlR1w7ahT2fWcfgcuUa2/H/U2d57BmrxW3QMZraHp4etokizgYQ\n",
              "Rg1bzU7TV7v+e/esqdZzMJe7AoRyPvm43+FGfs6GDyEoHJ6JQvKLIsd5mE5EproLOX1CVgdbnGvo\n",
              "POKSYom0Ccfw8+R0v4O5DHSoX+ey7CV2dU0t2XHeNzz7+pqNHsyjEzkCs5TGDgJztknmxSOTuCm3\n",
              "Q79ZqGcj675J9tJCYetsLab/WQeCFtSfkOyOLA26Qw8sBXjppZYoQDHcW1THamfRtjQgQy1e0o4F\n",
              "lHUDhKBBFpjnGvBFR4FMYmmDmNM58CDXaXHSLAEmAmJH6RxYPuzls7Yzzco6UD1NCD0sg3aCfaTa\n",
              "o2/1rPiQINVPG19CfeEb9KjUu7lX5mn7/vfRLBTxV6b+r7rt0ZhUTF7N5AzP8qrLBd2FsGKFYxWe\n",
              "qS5xB2LwmlQLlIP5PY/z+lhX4mTVHLx05mAlX4dzfrOWzxi0RsXx5yhR/LOLnWQt4yTayk4BQmT2\n",
              "Sl52MlCaij5qnwQoxCeIrx0cjStDEomA+AbPivzbA2Xmg5KhcZ4Rc+nkRGaBAD1T8eCHJVU+p2xG\n",
              "g85SD6e0A8Z6xNrGj3bWE4Qh6ilTXolzP/6PY6WTJQxIcc088EwdGretU4ByIr/goK4RLqF4+LeB\n",
              "ANmju+OY1kDD5cmRCO5Lpf+OZ/Z7+XPFq6JhWyQAey6b2m1rZkVSf4XbUuyjQOUYJx//GtFnE2RY\n",
              "9SxH8jLvohT/dxrLPyzifAuHxoWI2xXgJ5Cp21IuqdU2XMgyXp6wf16KHNnqSjKgX/KGr1BdFs9o\n",
              "UnJphoYoYl6mzZ3USrSnwpumwnYIzSB+55f5RZDNcrW6NNEkUmM78oKA/8vNoNGHLNC8V2gTOzER\n",
              "bu1TN+vaRIAET269Oi61T3f3a9Cx08sY0wEsq2a6ECSgCQCCsBJ0ZKaTC8e2rHMHIdoxr0KH/i0N\n",
              "+9J6HYs+Awrj+p+Nw0MxmJO2/1RDL2wCspEY51joAE16JzeDbQKoLI4NhNdQKulMri2/YmcEDVb3\n",
              "1qy4H+JbAdI7O166NgzgdEK2fBlU/pIj/RO6YckEX21V73+kush7zqpoMUfEHg69uPvgg7wQtWR4\n",
              "aLcAstObHpVvzPqIxbW8/muh9GFQKKyLARVtPwcwwjHqKpXUWxVlMUjeRWAfnuECf8Ljz2xarpRr\n",
              "wg60j3imOSXSa8T47tz0WGt8tjRtlcdskeHXmZW8EIyz2ukuAzgsQX28mCzcZ2PBjDYwXeAK6qN+\n",
              "2vNGVlGkCqLxO2FGFPBoCSVcNzp6zyvzt3d8Bs8BWTWWFm0Q4gkbG6fyNdbuba6fdiaPhZ3/77FE\n",
              "HYDZNJKFxIFbt72RN5H53kT5aDff8bFjx7wG//imEitrNA/ZhqsirGUQFecuKn8TRBC7WoknkOXD\n",
              "oFNK3LW+0/AHREQxie0ArkoiVE3Am9H2mUEX8fT9vjVAcOuVuvtavknhCp5lqQVpVV/TKaly+yc5\n",
              "UTX9lFpd6oRcFJxVeE7Xsf4WB0dcjGIMFHUUg5/gg9N4LaYPCOjo2N1VFUFZwqxU6RCG+83u2n//\n",
              "1nZH4SZXiiF0VPoIoCMF+5uKUzpSOrzOwYL4wVnb+wKJf+xoBBd0/SJlwZgubeJ5vlSo3eXQRPmX\n",
              "zUeuw+2bbX72QAAVKE+R5TNx+MhJOXOSoNjxqgOmIbIJbejmvoGhcgAAG6Rw4eVOfzyQC21gr7v/\n",
              "/OWvlvSXilCs+/bpuYQAAY9/mWY4Ng8xuMox4AAApK7Zl4dtZdSJnOAADoutv9b5rUXxO7XQAAi+\n",
              "z3mOlr36FBI/9m61zXqkgoHq9290AALyQBeNj49fz9NtNa+IckvKPgP9P4qpP7RKGRASpeOzWUqQ\n",
              "s86UyDR1WGYZg+wPIfb5frXGb4xUWKMKb0TPn3xye7uq5Q9jPSyA2Tu88XPYKoXd94iKS1IUxnB/\n",
              "LWmb/193EYes53ssmayJzZV3bHB6HDh47Guq5Ti2TS3HkweYm4wxzkEd1QA7GcUAD3gfQ67MVcWG\n",
              "q/Suuf8X+J22ZJ0nYEGDLA8KZex4tP/gP6HxMxMBU+VQzxfHUHN/K1O3GTg3dx1sDCk9hDVlHER1\n",
              "dUIF3llJ/qLH1h7UERp11Qw5SK9yHy1Vv3roGBAjQZYHhTL2PXPH7dVQ+JqMHHOy3002fndfqCgV\n",
              "ySj1vHhPHwBwH49BgPfcCLhXQOhLE//+6LZUhSP75Faf/2TbcVz//kcP/Tfx7o19YaUg1kKwG5/D\n",
              "YBaP0ofDinhxhLNtLN89xt+H9ZailcheXUAAC3MF2Db0YvjXZD3FZUGaO3L1WY92APRQNJ7vqlFS\n",
              "XF+QR7oegKOliXtLtWqsbTg9T3zoMoFL3+Q4MEYQh/vMWlPcxGvvKGN9RmsR4I9Co4Ozgs+W40Sl\n",
              "3L6M7B6mEnY2njnJYEPpLUQnMUTK1KRdoHGK5PucStBayVsK3kO+9tHYJ4n3AXtwKPeKYVyJ7xVQ\n",
              "eZ7dlKneCSJYx6T4xiLxgf9IeRD+XWtiiGMpaaUH+3hCxPCHLJCCeAn4fQv0P9CykreTck8Gtsrx\n",
              "VwOvVn/1rMh9VskniHiK8Ahc+VscY7xhtlzSZ3sVOv+7HK6NZqf0ci5R3koSArcS2rMdpUgQgYXS\n",
              "kL1Oid7iCXfCruS90iPzzLlzNKnSDRQ+Kj3ci4Flcy3x1p+y+BkPRR43YwG5dC3/+r06TARclRqA\n",
              "y0sbcVNpCGnshBZOx8s3K48a3BrsT6+tQSvyKl5AvjlYBqgsDN/tco5z/NAcjXYoV57CW3LP242Y\n",
              "eVPCsRIQQPXAg8xkptbn3tnDxqmcrtp97XNOWR3QqXI/tY4517KkvIffsMzL8QX/9pAjxIs+Zatw\n",
              "2lwSQmDK3RwXmOFsEWt8B7l6hcvBoaNyiAKeU699gwwzQaY5soU7Qi6KN/Wh/AM/IsHnyUdDwnIn\n",
              "yWo4iuGSrJATxkFhSzXvVP3G11K6p8jEC2OpYXTapNj5sv/vkdcYbl4cmgugkvqw1pGdT6jiCgFV\n",
              "iCE+2gDcsEFNuHNs4U0kbMoqZqyTYXaUmxJECeUxVRWKYj3AdJeZoSTIxh62qR5V1XkxqzMSWJ4O\n",
              "5KzyI5bxAtjrLjLQ+I2THP9RcCPZquwZxj0O0LIXM/jx1X9bYyy78Et6jANQXEkSsrHvWYmVLusr\n",
              "2X0KP8XM84rvPLE5HA8R5X/eZ9qC/XXYLUwjc0cvSZ5vzSSERpmSTDYw+oLeNEUIapTKv4GCBjSh\n",
              "uhbqJv2GGEqmUfcPmjx6cUzwdcevXj/9+lvnVUxY2gsyh27Siw01XzS0pcRdQK97huT645O/Jc8R\n",
              "9I/hPWe6XsvIy9pQpPCnOF6LM26Z+BNUakgq+npJZ0qzr3OdRujiUqC8fmKvpU49S5M9djMP8Bpa\n",
              "M6o2a8x15kODo4H3LqLepgezJRez8gopyzHeATdiFCDbi/1drcsk5DIz1yolfMKy93qo+oCPVN4V\n",
              "7u4xoKrYT99YKl5m5zwvX118BLVmHQIgsznK4EqCdft0eMAgVsp3rRC4CEbXEvQ3r7uwI5dBUikd\n",
              "aALa3vKhs2yClOI/fac+Pxb0P/yUV6IsxjBiyh3LnaYnknoLHCIwSw3w7CdhmVBkQkmeDoArBFSN\n",
              "IBc89EMBwjVG8V1YbZuc/xBO6Jkpp/9kEYgp3CUe3zENSYBW+q6zkXPdJy7+5Vopl9jNnv8RXNOR\n",
              "jBwSJZ3cwH7a4z0T/vs+zFB2DkP1sw7IDHePr6iHo4+plYKky+2QGRMpKtCR+QD2aBMRRnvJCKVL\n",
              "s4kGxh77vNH77YAjHqGyw+2PfiMOf+2flbWMBMJbu2lu59fNtZ7V9U//S7RuA4x0BJJ4CCYaxVi1\n",
              "gNE/+gdz3eJ/cS6jHonoWU76j3GO2sNlottRB7NWeV1q3mj2jXr4Qoj65bHGDhuEz8zg/zmlO0cD\n",
              "uk+W1uUv9TL7FxILiBL+BZ+fGavANKVhs0CIOskp2HalUmURnML+244DGZ387OxAroL9HXPp0RlO\n",
              "J6zQXzBZ/bieb/tRZjZdUaewA0JYs9432XmJx6zrigeqiAggeW0qQPgiX/uXh1ytU1MYyxdSLbGq\n",
              "ARn1Px68DFLmbK6+b1Er7bx1NAaCzNAXn1+h9XB8slVkVyvGtUQ1Cnz76czDa7XmyDQVnIzzriqg\n",
              "WLHZ1Bd/r/5RKaXUWOeznXeIMA3hcT+Gc/KbfaB2rd00d7+fU/xA/0M7/MyUvvpBV+gj1/zn8e9s\n",
              "pX2AH1iGgNsybdYQx0POkLB2FDAp5zkRvGBYWHP/xoFSrn7uO8DVK0OTaAw89XFYaKhkTLqjMCaT\n",
              "DJfqRglXZBKAJvlzyWNdjwjwCXE1tZKV28CI+bwuQsrwVY2IAYgRCUpyFfYOVvfDZ/sAlI2xjaeM\n",
              "bmgfYljmYbXa6CqlcToE1QzjqCJ/Jyo3QU29Vd2N1teGbHt3eRHvL0HbgScF0d4ctwV82qR6KQNE\n",
              "fxkM+6dpbWAR7eEpErlWUaFWGqNwSWHcObhD8RcJwhUn/MqWSIZ/1Jks0Q5RlBNmoescgGcu/q1D\n",
              "EEJYKSZmgqO8yYwr/ROIBnY/AStZ2IlN5Xj1QBoHDdeWGm/ieC7/7523zUL+Hz0yMRyeH/LzdX2j\n",
              "+A6pAGMaAUZqHoRK6iCTJYfaDyqQbKSjP1+b0YGMuw0+Mu1RK+LIDyWgQC9yDZzC0f6ESRdV0dMg\n",
              "lLvpQxxyqhi1mgfatL+pDutS76iOTNyYUcqg2N9gWMa//zrSNPiDJzqgHvwsw6pYXBM8UXw66OAU\n",
              "KBGPRNRPIw5QOVdP8qVbVlMOfg42TgC506h+5S9pUvtyusirsnsBeIgQErFcwQWLiJpJZxRrfhcK\n",
              "XnWQXv52wP2jB2/H4A5+x3XtIX1mLnYGtyRGYbMsFUib+m6+5CxoW9sjXMyYZo83HZmv75ji8Ydn\n",
              "OrXWyOBV8cAiY7SQ/1eYvNNcMhaptFuVL0lKsSw7L2czUjD8sa40Sr2ZfmcYSOtrgkB057l7DXwS\n",
              "1ksBW7+0RHXVIYchz0X1j9wQzCKLZOYF8Re7KZ60xEZENcPEFMzSicd85IqU7qSB78ILofwbvWTQ\n",
              "iSHrwXBFFlaJEx41zfdLyVhJ6wbPc6tQ4rT2OmGYboWeD5WZInV0AHEhTlZ9EO/KCC0hV/4J8Gae\n",
              "enaw5tqdbMmLAqK5T8KZDrQmpF3YNmSFtKBgeKHsOHamelcPELnOFzRECgQ07k9nGBu66YxYZAQy\n",
              "0g5N/3lqCIMhaB9YfksvAMhZ7vrSFhU7SoDLq0xsYPqUDEWmjCK+ABU2P/fMEmecH0cPCKPMrXS/\n",
              "//5xZfKO73z5zzNHX3ONHap03AnexLZ4Ow5Cs2uI+13AqYmOHpgDGnkAg1LxWhWk1fLzxWzUb6Zw\n",
              "G21jVpJ+WhYZk+S2CA51lbtQYmgSlZ56FVgwR/9PaJCtTHJ9xDkvgGrWdq5qbfTTgcQs/HdzjtuB\n",
              "Bchaxx1vbKzh3NRyoDX9R3f/H0rSZOXOe8ACjU+2b+o0ULIViulAeXoUIeRAre1csEuix0q1WU5Z\n",
              "SQg7as9a+xHqDJNJ7N8aICv9tfAHspu1nNLOiZXJjpUwRw3RJ1VQRxKcN4+8jEeFT6XVJrs83aae\n",
              "sP+Pr3KA8j/hV60SFzLHnZ+Ke8gV0cuYwGjP8UBwCga8j8+97u7VmGKHMrfpxG2zRiO0TeTeNgr6\n",
              "SjvLww92EydPBHfCn/BaRWKa8WgmIcGIuvs73ZydOXjAWwdU44O8tdgPZZDElJpFOesgWEEeas3J\n",
              "hx5WmXU8LqNo1pizWsjHCMU/+nf0E932Bo3BPw0a7iEM4GtPjGXkdYEG4tHhUM67z6KSYU39UB13\n",
              "1bDvmsnlzmrhrrObf6WhjdEXEwXZqxzC9QKEAZm6aLCawEsXtwlc0oJj8VBuZhXxDyJg+oO+9flY\n",
              "CMdT/rPoO1dpZ0toF3W4Gt5yXpeYL18fYGEzDuu2RiycNWSidctUTvUjn3AQqfys1Z6IbC8vLqs4\n",
              "I3C8Hp7Knh6PDvGi6Y3LBeJxWwE6s9EERmTBU2vVHrRD9j5AwH4wWMNI/swaYIN79yq2Ql/pcv8+\n",
              "hghyEGWOo2bSEg1lbOjblcExfW2p6/hX3FLCQwDZmuqAJmfK9PuATUDNTCJM0T7S+48T8yq2IjPw\n",
              "3xPP/YzJtxdnClLp9R1zf+4iv2koBw8mG6R8Tao/TCHlJqKR35Hqzbp0lzlsvv1hTnE+AKzFXx6J\n",
              "0PTk3s9UfgXBwGHIjslGIKlrUI3WjLyZ4O3zjiCg9l03lQ52HRI/KrbHbGIS2EBiRz/d2KBI9Ren\n",
              "wot6dctb/f8DDuCRzIaNHoemFAAPNf9j76sdgBaXtZUJbXwCynyuHYe9kJTrt+ogOcYy0Vynosle\n",
              "D9pT4fgRrWZ+zwQCL1UEM/G0CQU6/Qv/FOCMOLEhW/14B19//9Zzi1hxstqb6iq5FKStrlFjpfam\n",
              "tGJ9m3plxd+9vI7ONLUww2vuwRbPfQI1c1fZf3LtQkdFn94E/77XsG2r7nVerMsYY56dR5UovI5P\n",
              "SFFjG8pPUHNAVncn0enpYvpx/XDl9+g6MLGGz3TBgUtvKs7y8NbdOzKoMcBRekAc57s2BVf+jf92\n",
              "DUj51tolB9veJIUlCI8W6vYF/+k+qmekEyxqelIvwv1jIYqG36aTCvFIixDaBe0uvQqmGwPqNhw+\n",
              "x9uphAu5m3G0Uq0j6Q9Y+eXurZ+sN52njiSQrySV5wGoI6wifxrAMFgDSrKKQztW9ETnTi0t/fN7\n",
              "MbuFDyOO/bqBYPJ5IHeeTpEj3VO+V1V9nvwrB6Chqd5UtXUceGWj+Ln6PAbLGrWPMIsz9TMLrFmL\n",
              "Gz4T82Np96Q4+4smQIXYguuQyoNAu3P70mwCmMI3vEJPn5IA8xHEccKd0tUk01jIYEeC2kVqCYs5\n",
              "rjyl/zdpcmhsvtwIFhPPzE1uXP+e8GEfnCduNK/kzXDiIx8n+ngg78T/KdPtVIRcpy9LXG1Ety0e\n",
              "L5MGAGQc0npB0PaAxWEPWEPPWqC/nqFNC6PUsemKBMS2fGKOYiolRAW6awLV4peD1wcYW8UOEfV5\n",
              "Tadk+PdOba04ARNQNAlbzR+MD895IKH/ckja3VxDa7Xd5hqvIstmuRxSsRUQ5NfH/9zt01P38iTk\n",
              "QlgCOA0cEeVStKN30bjWGMkQNFyNWQxdE2s4DNtYWM47JS2p4bdQqIvD/LvNePeUGQUK58iJrUgC\n",
              "Dv+noi1MaqjFNBvayH/v1zbQ2q3b75h07c/b4l9S0XlfBrQb/MONwHpwNk86AEzv4VVRq1LJikOl\n",
              "07unD9+E9wlUUPVpwxrT5tSKNMg/LIrVE0Gvy8kzz4dt1y+LyxzKEiObnAiE6fweh8J/94Sj1prX\n",
              "IwXtGFynB0mfU7m8sdkFU2OzzgeOoMoMlrXch4YbiTVDs4dBc8VJpPetVd9IxZbVUgYNookE9lSj\n",
              "YHn1Vq0qaqdnHhBMTjt/SU0Z5GhCUeOZ9HZCsB13mAPtA+qJRdGbpG2tLXIZrAbjIyMHwRhfUuAA\n",
              "AAYFlzDHzHRPmdQYU0XDAgI9CYeP9Nsw//jHDJweO+r3ocjWI7REmst+tStkrYYn3k2p3oVdJutw\n",
              "GvzZazT+dXwFXl9rvkUkWCtlzDqVSlk80ItCt5rLmv/J3Ho2PqqgwwSeFO1ehBaRb0KHMQb3440X\n",
              "ETWMxyFARaTVjq8DRQF4Ib+5ugfmgdYRyDKAj2z268S9k2Ws67NZvvR3P3L7+y2TmK8DtPD+qGwB\n",
              "QKSQKqy76NMPsUNt+NpGki5aoVe+f4FeEv57o5D8+mrbcjyEHjfQ3P53WY6rqX0rvF2v29Ax7Xxa\n",
              "iqXhxvEd7ZjfOzNLYroa+iIsEFnJjRAV8rzCyBSgTSucGiW+cRKtWa+ggdpucXwx3+ltUw/GdZG7\n",
              "X9BCoqkHnweJrQ+NPqP3G9yaupwNiYsnsUbJTW7A9u0nAsInw7DoADvm4pwBPjV1c/GXBYulvIPs\n",
              "i3S5IHhm4EUvH6PMawCXUs/tIpCUWOUrYOr249r4qekLS9Vd6Vd2qZB/M5IP84PvM1AE+I6uBbIT\n",
              "pSCnJuxUZMbrF5nC+KdnHcFMcb3lJ4gRhZRoEdeyw1DtDSa/CxqT5uaKt1IyA8ibwgJoWGqFld14\n",
              "NnzkD/B2JL9twX0JUN9o+49kjmxO7UBNwrKGLZXDAaaSKpO7MRYHlpU6tTqw7AUpgbaORUZcAAbf\n",
              "fzRPhrny/4OUK3hR75N8i7Of/AdEEJGERgGlWj5NhnLgiFN5CLjG9NegByGu5jw4dKJEHZUcpY15\n",
              "rtlQPlUx7lf44NrzYXx9O2UTOp/jtvjurYfR1Z/7UmY6TnGkLmXaPyScU8Nq99qS6DIxj/dF7Hzf\n",
              "AxnMApx/zhtQ7prprAf1zDop4hHCHI/67KZAEBPX8fuFTy8p2m5j1LwySL2vJW2ltth5MY9rua3y\n",
              "juUXGeAHHAU/4ddCOu+/2PCitbcITFKoorlU0yYqGcFhhk8qL3OarNCXHtabm1BSmDVfo70//6lR\n",
              "FR3rb28uSYPjbhpmvx5L8sQa1UDL/46tCYx/H5Zfpepp/xgiDlctdf3S5uWyvGmH+A5d9gNLBtFK\n",
              "MgpbMYY5YULbaVm6VHEbZPIa+NP4znAynynXVC/VHUE7ZJAI4CmSccs/7q1KOJZlcfHU5ou6i7Vt\n",
              "TEzVN/+2Een5WmZo2khbeIqnm3apmmA5IEGItm5Tr+ez2D1ulOaNrxAyp6JUMRoTAXXb9jyP4d37\n",
              "A/Pb+fExHZKAkDhF/LgJAt1GxCGytkE9UcNmoUBRUobgbyjIJAT/yKTgMEovMUzoJt8tRyfHJN5Q\n",
              "mmpUlmroK54IQ3cU0kmcn1JAbxlDc2vCyWyWcEyI4iNzLHWZSNC4IGuSJNwCtOinZFSOnl/YdMhf\n",
              "ggzPsMqi2wkS3f0nqc2BTdyKAJQvj7XAB9HGrBGnLcrOTYHhFI3Cl9LFwHHKLKMkaQT+2onLUDpU\n",
              "j8OQOds5Kv9Pr+N+95KGY5dsKJgBiFJXWsd1VAzKxutU6Z9km4vgPB6LVXPzXCjxzVtFuhD7IIyr\n",
              "bu8pXaualL3fCUY44RrSFgEtprKu493s3MU20ntCFJJaOkZQTh2b2w8Jrfa24tcuGuVM/HOKpbKz\n",
              "2HgZ7owx0fFRwILddkN1vjeZQt8ziUYbHgfGhPz6F5DVLH/NDpyg6fRJe99uvUH0Pqp6l0/EG3Vt\n",
              "uUbEAv/pSoRazfoTZ6f6FpoFGAmm5RulOf7/jL6xKpFVWMOT0slIr01zE1XSUk3iOt6k64NkWzXB\n",
              "IrTrT7JIFoUgrYM+/Hi1etrbxnAjzM7CoKlTHj1FAsaJIj6J49e32dX6kijb3dl7aeuawk92ztb3\n",
              "dgkYIXm0zg3rfxD4MAodYyruCbokqvZp+Os+hexDtNXhEuY/ZIG+HyF9UZpGNPxUdvTkR8lQED5L\n",
              "i8C3tT3/2UttfVrwNU2dhEASV14ZsVaRmdOerTy8vYDgGLizZFUm0BiNX+F4AsWEcP2ubFQrf89w\n",
              "up6/5UbKd6z65FStlA563+Dxnv9sHigMhjpwRGpg9s3xdo9hu9u1d+WYWZek+bdNLcBf0q6YQ3f6\n",
              "6LtVWiPjiD86PlTxKYHQAm8L8TFgH2OeZQozglmXHc7BQE2i2TckfwnNuiVHMH7nI1K0L0Qy49Xz\n",
              "s6huvzaeUNHYT4wg32yVlw8K9HDGdcmZTbbSgLOAFhZ7qRW6nAZEvOgmwCHncBxPCicAAxIvJCuE\n",
              "mMcKzOwU7nn1Q72GzGYIWSKrdn5XkrT9DHsWEVw+ON5ND0oZCsF4EkV+vAq4r7ht3M9EWSynL4XV\n",
              "aKZHdTeUs5xPNBZQxK5T77aa6ocWJjm0R/9+70azHb6+ulUWzQePY0JDKwpKhfZtz+b5Sd0Kn+Wl\n",
              "kW/Ufa51uWCpADqpC014UZxLsGPHr5vMsvQy5lM+vkmTlzjev0/fFcPhPRRjTM/uT/O3WsK191pa\n",
              "2ioLX/FAr7cQRGCEdxM+YfvU6lPBsWlUdXzpMqprdSit3PNH+b9IKr74VTeE9IiJHDEohcARyvms\n",
              "Tum5dy7ZBPIRWydAvi2JqUga3OVL2xGcopXJjYl0di4E1vKun6txzg0nKC3mTpVsSt/0t8DqyDvA\n",
              "mL8hyoWTF3Syl6g1e8dtw/bzgVwu2cliDK8riseD7v4SSV+HuzozlZUqV2BED8XAz5NKZ8cvuohy\n",
              "zgYpIJ84tuYyqXjLi0XmCUuS21vzIJThRBHgx8zZJsEmWpjB8r1/r94irBCpJyQOQE6m4kZh3Z0e\n",
              "t4o4MKQAaDZ6UEK2RVjPm0/RgzhKfgfh9ebP6rJHgkcYmxHiymnh8Ge1lIOE8LoGHAQyJrTH1IVA\n",
              "ADxg+QmtNQLz1QH2kT7F5ERIZuw3oWCzipwtLTG7P9zGxqEhm1tokP987J14b4YBpXvp+Zs3ySgg\n",
              "Pmp8Ke6E4kWLPIMfSTUOqsAuXbDPNVOKxFATKeV41sAOFj9BZqCOOTjcjEZpAZIstMeI2XYo46Sz\n",
              "+pulgub5kVJG2i4NldemjzkEV/z0fXFMqie7A42knC+YzMreXhbAMRXwBnZ2xNZUJz3nRywm2PHa\n",
              "sXBhfO/bsNweb7bnM9g/bu7WhKmgEo7Zc0dUiHVbwNbiAiao+5LmbBl4/LPilk8lnU0zyoi4P3Un\n",
              "mgDzH2s40NXFYX8Uie/N/2RSrDJrJ+nQljQH786e6xkJMGaMI9OC4RgZz+WTKGWYEvwFjaJ+x/Tg\n",
              "Uv/K5D8Ff3LhoDvOqFgQrI+yBF1ndE1eSsVOi2DQRKX0TG4qun5BFhb+fdwIGh1aKx+CweI/Y1Nl\n",
              "975UruIoMlVoAZk23lkKbwr77LsnU4CFTu4PQq4LVSM6n/rwHNf2mx5u7XFm/H2MkV2pAajgQkG3\n",
              "Dixq02jKtjidotqyiebgDRuCnNBzRPmJnA6HJDo8Dxx/b59tIg1J4MS3zS2aDoH5k5PNfzexOhvF\n",
              "xHHlfR3eYAV8OaDVGEbt1ogxZ47bsvZ18k0WEXRx/or4AkjsON/vSq5SSHaEQ8mBvAtLq6QVtVBb\n",
              "KgcSpEJ2yJlABR/3RKABnO+lzNVPiXeiFlHE3UYwolen/6qb0jwyfk5zPAlYdKG7zvdxToCq91YR\n",
              "o3aqGjIq0J6h3fuwIabSkSseYR1AJthkJxcVL910jSfBTCFyBz/YU/gQAyvMn0lLAV6paOq7vHQn\n",
              "VNSyqu4A+495FkoV/PA0PETljlS/qtOnH+1wDpDZJmnAMUHPy6x0DhQ9hkmicivYnzrHWjvXysOF\n",
              "vyc7VytP+MYFdXpG+f2TSjiNUyrSUsAOo2Zb2V5pdfdZFmTHPdPSKbsYGPL2dOU1yoITdj65ILdK\n",
              "PpYxhjXVDk1UD9/R/EkBosSLmP5ZnyU0eUrQd0hHVfa4c1uvA3hb6DWjoFTcsKJ+/EyaQq8n0wtw\n",
              "t7jxmlmhKDHXOq0GQKr2ZtDUO4LfTDqoVgJFjuM4A/9kmdMT+SmsQACXRJYxJP//53DbLGDd4mVs\n",
              "SZ/EQyQQrPK5E7OAUspEVSy/3X5QtLoDsX6dXnc8DzSQOj/C8MsOO9rHKOod9JDNrRDE1fv7jU1L\n",
              "KIch+DvXiv9QKppp7jCC58ujABxF0KWtK9B7lQOOlTTJQPBmZLpl41ASx+j8uknkhEzWBaI4usYP\n",
              "jD5vWVn7z31JzQ6HuOQL+Hrnb9L2CVoPca8SpMMUHoIvQzxDxjsMLPcIlX0rqGIeVLbzsLyowapA\n",
              "9wZKS1EDuzOETKyLbD4ayzgkLlXjy+wu4ADEOfEHkXl+PFjAOMwHGSE4bV8QtSdH1xdbGjmxkAzy\n",
              "7tDlkcT7s2RGPCNxh4ljM7aa1faFVWZZzZNfHd3EqxmodUULB0DYIGRHI2/4XfcR7XEpPhF21joo\n",
              "9T7Nd751wkf+Y9+6U8TLMB1Sl9///tqO2nJEhQABLD9//7I/3Ulm1OL+kM+mZhU1EMgjcVL49ygj\n",
              "COrClVoikj+mM14CgBtv8F4t3AdJIGwye/8JimHSjmQLGfmENXMmG2cbaljPssv0Ugwk1/fr7gLU\n",
              "ZR9008LXoanO6A5+QVLR0CBudHBUJIgeHohSierr9Tt3pHfoqJsVSNQfiSTUQnBA/Fgu4S0FVfoq\n",
              "y6m8Zsq5po3T77MYce3qW8jM3vPa3VlxGCB5Wd2IkDX3xDo63bG1tQjML7XG+vUqmfXhbw+xvZ2b\n",
              "Vv4Jn5yDedb/1lkvFiPvRe9z5k4ARb9O/2v5c+u1A4rziA70WaB/UDWmWORok69nh9Rv6/DhP2uN\n",
              "DDTGO1M9ZjiORr5Fa806p5GSWVMfFVd9dw35WQNMz5L/mgetOQuC8fXTCPI5jM53No29o9KD13cG\n",
              "dT0b1pNT2S8fDQJF9eHwlUsfq5lRZ5Ggk/rwVPoScA9SxEDb8UmrdPvUajQPwTNhgfhxmZ6iSZ+j\n",
              "8m4d6iiPXMLXnrq43L3ltrJBYGB8YqjOr6c/H99/i9rpZjB+9qtws7tq20yYwVOqYV436iCcwsUz\n",
              "uzzQymyNCUK+jokqL090ucpAiTVm8xSrHucsmpSfQXK+udj3LmUyk177y1P5VX9+HXpz9ec4SjNZ\n",
              "PEWqHUOymvNKeCJtJx626XbkJwNlivVKjFZgBR/clF8DoFQ4FUROsb2EG9b/jAJZz+W39tL22Qt2\n",
              "pVK3Mv+Xe6ppnqt+mH3a5/Yszv2tMjbpo2//0m8r7RudjA/Q0kDQLvbbhNMV7sloq1k3mVALoBjj\n",
              "D/wVyAr3qK4cuFJOaxCvQULdUsSxQ1h9EBgEuOrGyS7jj3eZesAxG61Waui0nLLV9D82IOgNo/MJ\n",
              "lnX/L4izrBHXQjiP+309ZkgGuTOAefwhqCI1wWyHFKU8NipAVksMzl+hRP5yJyqYEt23cSeLagsY\n",
              "4FVh+I+gervKcvIKWQt7V3uljt9LbAAAAwAAAwAAAwAAAwAAAwAAAwAAAwFnAAAArEGaImxBL/61\n",
              "KoAAAAajMO3AFo4lfcFjo5qgMwApWxaPCFjVf5f+SWIpuYm/fXmdy5vneABxKY0g8PpxnUbaY8vb\n",
              "o1pJwH3jqXZvGeivi831Up9pXu0yQIMddAgRcDz+ljqxUwAAGJ3/x+QhHV2zPe/slLgOkx9CnqWi\n",
              "szIJcJCg+XqDHAArdEJKAAzVQq51N6+7QOnNeiRFw4ITrOO2C/iIBOJR4iBEqPVcAZcAAAA6AZ5B\n",
              "eQ//AAADAAAKgTuuQCEyQyHSThez+0JIaWAAAAdAZ0A20TlR/hPpz/4BlvHe3Jge5t7I5ABXwQAA\n",
              "AG9BmkQ8IZMphBL//rUqgAAAAwAAAwAAAwAAAwAAEQcHh7vapGliek3KrwAJ2bTKJsfF/vd0ibpi\n",
              "K72YXm4d1mVl5//nc4Hh1Ko3T/YDEiQ2uQNLT9PE6hPoXW+w7xUYnN+wSH7Md1c242oAAAMAi4AA\n",
              "AABHAZ5jakP/AAADAAADAAADAxAZa20GXqXb6EAAAAMC/B+Av0tADj20vEsL0+iztMvVmJC8vNgk\n",
              "VyKn/C7detPw8tT4rEqAD0kAAABoQZpmSeEPJlMFPBL//rUqgAAAAwAAAwAAAwAAAwAAEZ5q/icL\n",
              "CgEJUnJBoOJukJDzmiGxzGyNaLgJr9ZSzdH8MNzGkVKFURRe5s1dWeseUXpRzDhfbiWAqTaSY+gv\n",
              "XLICAMXH9rwAGLEAAABTAZ6FakP/AAADAAADAAADAavkn2mtkccAAAMA1/uijwGmDhlXmHvUQBDM\n",
              "3c+oorX3xFvcBI7emM7yZOih39+UrpjzMiX7+00arNxIj6VAo8nQBq0AAAAwQZqHSeEPJlMCCX/+\n",
              "tSqAAAADAAADAAADAAADAABMHqBQe1bxG6yB9GeGAAADAAS9AAAASkGaqUnhDyZTBRE8Ev/+tSqA\n",
              "AAADAAADAAADAAADAAFL6o6/bbPHcHleDsaJYtJiqpvLM3RLpZJvBtXD8PYuuMbMc5OAAAADAEfA\n",
              "AAAAOAGeyGpD/wAAAwAAAwAAAwGr5J9prZHHAAAPiD+OUm4s8lAXqW6nI4rlLNm4Fp18EQUmsE91\n",
              "wA3oAAAAN0Gay0nhDyZTBTwS//61KoAAAAMAAAMAAAMAAAMAAUv6IiCY6F1zZCzLgrkGeoQnhVpA\n",
              "AAADAZ8AAAA3AZ7qakP/AAADAAADAAADAavkn2mtkccAAA+GNn+H45Q8Wn+SE+Uncy+37ZeFfFOQ\n",
              "LMCCIgAi4AAAAFVBmu1J4Q8mUwU8Ev/+tSqAAAADAAADAAADAAADAAFC+iIgkr2BlY4APzMx/z8p\n",
              "Z8/3rPkp6kIgMz6voeYH4ztEVkx3OiSJNeJXOdBqQpuuAAADABOwAAAAOQGfDGpD/wAAAwAAAwAA\n",
              "AwGr5J9prZHHAAAPLjZ/h5MZwbreuJ1xlWlSUxtaYMxnvMLwxIB04wAasQAAAGBBmw9J4Q8mUwU8\n",
              "Ev/+tSqAAAADAAADAAADAAADAAE5+xnw/LK1ABwsdv/3+mq0I3Vyqp9ly7pbQuWXf+47pFwSeCNK\n",
              "9sJ68VJ6u9FSB0URlR4HsuDPQh+ZgYAAAAMApIEAAABeAZ8uakP/AAADAAADAAADAavkn2mtkccA\n",
              "AA7WNBiDl3gA12oV6y/Pf24j3x//+NVN18pg4whezZTGplrK1ktGrejURR40HcPdtJhdlhS/aytj\n",
              "x/rnXXpKdkQ8kYALKQAAADRBmzBJ4Q8mUwIJf/61KoAAAAMAAAMAAAMAAAMAATBJ0h3PMT4z24vz\n",
              "ltm+D9keQAAAAwD/AAAAMUGbUUnhDyZTAgl//rUqgAAAAwAAAwAAAwAAAwABKEkSEuarISqVcMkc\n",
              "abNAAAADARcAAAA3QZtySeEPJlMCCX/+tSqAAAADAAADAAADAAADAAEp6/7+BfjlfGSEbqefXIMN\n",
              "ruL8IAAAAwAIuQAAADJBm5NJ4Q8mUwIJf/61KoAAAAMAAAMAAAMAAAMAASBoTLIy/UFPLQdOvdR2\n",
              "PgAAAwDjgAAAADdBm7RJ4Q8mUwIJf/61KoAAAAMAAAMAAAMAAAMAASHr/v4F+NerPIgED565Bhjm\n",
              "efeqAAADABHwAAAAMkGb1UnhDyZTAgl//rUqgAAAAwAAAwAAAwAAAwABGGhlYjQ6QU8tB0691HY+\n",
              "AAADAOmBAAAARkGb9knhDyZTAgl//rUqgAAAAwAAAwAAAwAAAwABGev+/gWuMGndroHgAIxccja8\n",
              "s8xi8XcgZ6x/MLji5wb2dKjgAAADAWkAAABLQZoXSeEPJlMCCX/+tSqAAAADAAADAAADAAADAAEQ\n",
              "aGVm/yHEAG7jlLLv/IpXEvWZefms+G/gHwSM/wSwHWEohOOxvtZjAAADAANTAAAAYEGaOEnhDyZT\n",
              "Agl//rUqgAAAAwAAAwAAAwAAAwABEev/AWUv39AAcZfclCE9Q6ZS1kfZ//LAkQQq87ZlDQQjSxl9\n",
              "QTk3mazoZGWllxBxHzsbF7eaRMb+VWEwMAAAAwAXcQAAAE5BmllJ4Q8mUwIJf/61KoAAAAMAAAMA\n",
              "AAMAAAMAAQmk6zrQAEt8x/38n8fyB58pHNsPPX6JvmIYM6+WuzN840R52vmrNE+w5EsAAAMAAasA\n",
              "AABeQZp6SeEPJlMCCX/+tSqAAAADAAADAAADAAADAAEJ+yFbHNOgocG0q8C6tMu9zVfwdjRLFjBu\n",
              "0N/DEsZyzPE6sgNbtcyEM50ltoiIE5tB2rPVBSPYQAQHYwAAAwAakQAAADJBmptJ4Q8mUwIJf/61\n",
              "KoAAAAMAAAMAAAMAAAMAAQBJEIfmqyEq9iZFI/ZcsAAAAwAf4AAAADtBmrxJ4Q8mUwIJf/61KoAA\n",
              "AAMAAAMAAAMAAAMAAQHr/v4F+OV8ZIRup59cgw2u4vwb/GTu2mWgSAAQ8QAAADRBmt1J4Q8mUwIJ\n",
              "f/61KoAAAAMAAAMAAAMAAAMAAPm7a2/USVAXQI1Y5RKIMunlB6wSwAHTAAAASkGa/knhDyZTAgl/\n",
              "/rUqgAAAAwAAAwAAAwAAAwAA+vxvCToGVp3n/7/EJ4kGXMzN9ldKbxnglpu9uX1I638Z8zh02lMs\n",
              "AAADAJuAAAAARUGbAEnhDyZTBRE8Ev/+tSqAAAADAAADAAADAAADAAD1ch9ko0Dmqg6VzmsntMgt\n",
              "uAA6pN+oJBxlXgbIlr88hNW+sAB3QAAAADIBnz9qQ/8AAAMAAAMAAAMBq+Sfaa2RxwAAC+4D952x\n",
              "2esHKJ2qkQyl6QWZCFQbAJABNwAAAFdBmyFJ4Q8mUwIJf/61KoAAAAMAAAMAAAMAAAMAAO67fh25\n",
              "7nIsj8QArkcpZd7pRGMyZjE5z3j4v6iVHwSM7E5OQos26Lr+KjDG9S/DLFc8qibSgAAABgQAAABn\n",
              "QZtCSeEPJlMCCX/+tSqAAAADAAADAAADAAADAADv/GrRz5BJQAXLCiSWKocKasgLJg1f/3wFTC4G\n",
              "5TrgMYNPxAIppeMMiFzGui5GfHeEKDr5GQp96LU/3BRHL53adm1SpAAAAwAImQAAADxBm2RJ4Q8m\n",
              "UwURPBL//rUqgAAAAwAAAwAAAwAAAwAA6ReN+w1CF3GW2FWw776w5mH0E9ZR1WMAAAMAAakAAAA0\n",
              "AZ+DakP/AAADAAADAAADAavkn2mtkccAAAtWEy+1rRNol1U9QQ1b4CB4QKkIY8GcGgAUkQAAADZB\n",
              "m4ZJ4Q8mUwU8Ev/+tSqAAAADAAADAAADAAADAADjkB32IpVz1L7EDAULFrPnXwQAAAMAB4UAAAAz\n",
              "AZ+lakP/AAADAAADAAADAavkn2mtkccAAAs/5fcvyl/DMEvYzJ2Kip16hP06/DyOgAf5AAAAO0Gb\n",
              "qEnhDyZTBTwS//61KoAAAAMAAAMAAAMAAAMAAOT8ahBJXi6vyhZlwVyDPTrae9T7CYqKSWDSABBx\n",
              "AAAANAGfx2pD/wAAAwAAAwAAAwGr5J9prZHHAAALP+X8bVw/8FVEHLy/YtMXKXpRrV/QC1DAAekA\n",
              "AAA7QZvKSeEPJlMFPBL//rUqgAAAAwAAAwAAAwAAAwAA33xqEEleLq/KFmXBXIM9Otp71PsJiopJ\n",
              "YNIAEPAAAAA0AZ/pakP/AAADAAADAAADAavkn2mtkccAAArJlR39qtqZIkze5WV9mJ2NaJMiGAOe\n",
              "fABrQQAAAFFBm+tJ4Q8mUwIJf/61KoAAAAMAAAMAAAMAAAMAANpyH2Si/HMrio/dAA4WO35bxsTp\n",
              "kD1ZevRpCNJ0PxDMBu3KpFmK/VQujCk5CaAAAAMAJeAAAABiQZoMSeEPJlMCCX/+tSqAAAADAAAD\n",
              "AAADAAADAADUZ34ikAvjmoACZ1uSA/2K4qfwMr3Fp/z+CNBvcCxJegMaEKU+Cvr8zIzDtd3i3rs7\n",
              "TzcNXGInoSoQ3L+xMsYAAAMACHgAAABWQZotSeEPJlMCCX/+tSqAAAADAAADAAADAAADAADVch9m\n",
              "AEeEU/UAI8IXLLv/625obIJofFzZpIYvj5gYr6rDzuFQaJzyBbTyFX9u4RbZnlgAAAMADjkAAABR\n",
              "QZpOSeEPJlMCCX/+tSqAAAAGA2MHPK/71wAAAwAAAwAAF1b30+d4gBJHUkI7f/zfHm9rUha/vVM6\n",
              "6sbfHtPqEZOcrtHC+fRkxVOgAAADAD5hAAAAP0Gab0nhDyZTAgl//rUqgAAAAwAAAwAAAwAAAwAA\n",
              "0F5b/hK8mXbVPCTd7jKw1YrQvGpvKjFzV9ApHP2AAAAQcQAAAEJBmpBJ4Q8mUwIJ//61KoAAAAMA\n",
              "AAMAARByywhEPT4SSomIkEnI8OQAACOg16i3Gl+pLFdudt2Y57IszP1nM8IAF5AAAAA+QZqzSeEP\n",
              "JlMCCX/+tSqAAAADAAADAAADAAADAA5PVBerdpgF4sSETzQd9QONVP25yjnyf1fXVbKQAAADAR8A\n",
              "AAA5QZ7RRRE8EP8AAAMAAAMAAAMAwgT4fK9jt2NIJYAASWL1nTnhCNDPxztbr5rskC0AD7W7YLWn\n",
              "gAz5AAAAKQGe8mpD/wAAAwAAAwAAAwGv8dxYAAAbL34/qFzrawrWQCYAjpPjgAxYAAAAYUGa9Umo\n",
              "QWiZTBTwS//+tSqAAAADAAADAAADAAADAA48ckyg4ACE6AWDaf/6/Gzx9mcuM5Cis+ryLy32r4Jc\n",
              "P9HckFIOFF/AFksUt4vMl34DbPyJbPD6cW0UxgAAAwAAfMAAAAAxAZ8UakP/AAADAAADAAADAbAM\n",
              "tJICut3ngfgAFug2vkxGeFZm9p0w5e4IZnwlZagBlQAAAFRBmxdJ4QpSZTBSwS/+tSqAAAADAAAD\n",
              "AAADAAADAD0Id3D51jfjw6wAQe43/3/Ul503EUyOoJF5EcvXjUCqN6d8iCVq3NLZjG/9/vpvZAAA\n",
              "AwAAOmAAAABcAZ82akP/AAADAAADAAADAavkn2mtkccAAvwn45SbvHJgA4kcq3wzEtRB/5/jsdKQ\n",
              "P4p1nkCNGt1FLIUvf7zqWNwqWY3a9706k17RwDzYj1+f34PXm9pgL79QAccAAAA3QZs5SeEOiZTB\n",
              "RMEv/rUqgAAAAwAAAwAAAwAAAwEIeo6OrS+DxFPe57H1rd38jPMYAAADAAAbMQAAADQBn1hqQ/8A\n",
              "AAMAAAMAAAMBq+Sfaa2RxwAM4J+OUm7r2j/FafXNGIOVTYRS8yiQG6IwAJeAAAAAM0GbWknhDyZT\n",
              "Agn//rUqgAAAAwAAAwAAAwAAAwEIeoFCBVuPeEweoAiYHFJgAAADAAAakQAAADJBm3xJ4Q8mUwUR\n",
              "PBP//rUqgAAAAwAAAwAAAwAABIHqOjruM3oe/JIOrlgAAAMAAAMDpgAAADMBn5tqQ/8AAAMAAAMA\n",
              "AAMBq+Sfaa2RxwA3PuuhwPoS3tjjAvIWIDWPeQpeqaEG5pwAi4EAAAA7QZueSeEPJlMFPBP//rUq\n",
              "gAAAAwAAAwAAAwAAVTtXAoH7CbNUP0sl33JBKUsarzW3EPva+AAAAwAADlkAAAA2AZ+9akP/AAAD\n",
              "AAADAAADAavkn2mtkccA7Yk5SxjrMcYOPiWWxJz9dNANYOVwyq1RCat2AGVAAAAAc0GboEnhDyZT\n",
              "BTwT//61KoAAAAMAAAMAAAMAAFTNo6ZZAAmo47E1zJD8TMWskOd3v/wbGYWjOXZTPUQVdaE0FE8P\n",
              "ELv+IVDoRcPblLIl9vF2VK/QwOrHtFDq1t0cd62UmF8pv7yanvl2ryy+AAADAAADAxYAAABPAZ/f\n",
              "akP/AAADAAADAAADAavkn2mtkccD99W7tQAJYvOfuVTwJh2GxqrHNRBOjc/erCxFP/8zJWpdJdq/\n",
              "WLugsYCsN368BKmDpgUtIgBqQQAAADZBm8JJ4Q8mUwU8E//+tSqAAAADAAADAAADAAFuA1q3Ct0W\n",
              "33HmVirOUpR/qzxAAAADAAADAY0AAABZAZ/hakP/AAADAAADAAADAavkn2mtkccRWKl7gX5873xg\n",
              "A5MgAAQP7zQXSzMwAW+MXjEoBu4miAZfasHPCroqVN6kzBH6F+931NEi4D2CcyUvN1HBYmyAD0kA\n",
              "AAA1QZvkSeEPJlMFPBP//rUqgAAAAwAAAwAAAwAGK5pBIu4zfakZTCvSn5teYwAAAwAAAwAAk4AA\n",
              "AAA4AZ4DakP/AAADAAADAAADAavkn2mtkcdLYqnGBfn17QUGvA3kvU9E6RZnGAbYqAAkWNtEVg4A\n",
              "XcEAAAAzQZoGSeEPJlMFPBP//rUqgAAAAwAAAwAAAwAajmjo67jN6HvySDqeIXqAAAADAAADAAF3\n",
              "AAAAOAGeJWpD/wAAAwAAAwAAAwGr5J9prZHIRyyL0VgLBHaDuOxDX6r/X3SupjANr8egPu4GhpkJ\n",
              "gCXhAAAASkGaKEnhDyZTBTwT//61KoAAAAMAAAMAAAMAcmu/OlNuL526drdQAelS7Kqt/i2L5ut2\n",
              "25RE9maW2Zx7F56+V4hAAAADAAADAA2ZAAAANgGeR2pD/wAAAwAAAwAAAwGr5J9prZHMiY75tJu7\n",
              "NYRveRSFoXZAOKxGAbYE9AfeQNDTFYAHdAAAAD1BmktJ4Q8mUwIJf/61KoAAAAMAAAMAAAMB84H4\n",
              "4RWIXZuZmiB5fo2bkx+hNnLnvg0JulAAAAMAAAMAABFwAAAAW0GeaUURPBD/AAADAAADAAADAMIE\n",
              "9+xU7MxTXu1sm6QCfMAGWYA1s71uGRcsZDDqw7w+JlA5TGLHXDm3LeAgjjsuLF608lnP4j2VpP1c\n",
              "YBtY3MBl+IkKVnwAoIEAAABVAZ6KakP/AAADAAADAAADAa/x3GeeKub+aPv96hOABxJK8U4vikAf\n",
              "R6XoF4cAyWLS6KkRrmYkvdmndWVEeqT9hgUBFK3zCp2uO1TgoyoAABBVHggBNwAAAHZBmo1JqEFo\n",
              "mUwU8Ev//rUqgAAAAwAAAwAACEPUdeCxABnNcUBYQwX8jDbtVvVAK46VxhemnO1DI/hWVCIny3BZ\n",
              "7UAJdJv1oM3obhgnN8/AQUmgCtgOydS56vLFu/m2IckRPFvap+NnzlWMAAADAAADAAADALuAAAAA\n",
              "QwGerGpD/wAAAwAAAwAAAwGwDLLdQCt2DvcJRlVoAWwiIzfqQUs4MUuBId66TTG+4+QALb5fgRgA\n",
              "aUdQEchAE86ABbUAAADVQZquSeEKUmUwIJ///rUqgAAAAwAAAwAAJCIPAwAtQneCp6rZaiTWNdw2\n",
              "C96qf/jlCkd6g9QEDp5dS1tla+yqB4yLIS0sPjSJWvSe5Qywn8Uq1MgZBrCpctVEVfTEgtvS62No\n",
              "PBokZZgkYT6qg6IpswYnxzPrX71RA8KIvoPREVwqT7IV/KxyAZ++5SS4HSMZGI6u5jyYixOb0h24\n",
              "zZ1Gj86/rLWAF8ZdGk1BHmYG8wyfNw2d5UIP+G1z5evlxa2ZbPPAmkFr3uV4AAADAAADAAADAKmB\n",
              "AAAAvkGa0knhDomUwIJf/rUqgAAAAwAAAwAAJAhjEDrABdLjkg0HDmvZDihQmzWN5AztoGzKRPZE\n",
              "EFKKv6a8ecTTArJWZCl/+EntjDKtwW4IDioQyWz7WJsh+2wlzi+D5LYFH6nzhe0b22IBDOO4VyoO\n",
              "ziRykN43nsRW17QRiosZVLDeJ7rf6HISvKlBwdPxDP+ljcYhhPBbCNzyl3BAuJm3gR3bYAfk9z3c\n",
              "Q+tK9KNWyQbeVmEmgAAAAwAAAwAAC0kAAAC8QZ7wRRE8EP8AAAMAAAMAAAMAw+WbHyNYAOcvOSmy\n",
              "EJEpXdhvIXDtm+MwaoO75EPFoDvGv0Z/5KRt6cJgyVEhKhHUpcxsfIcQJMcIDt1tQsO1hzwtyM1S\n",
              "EAhy0P9lzn/cTel5P5pJgNUF4dD/xx4TrXnPSR9hNtbM3L8s886NLzOMMidPg5Wi6NktOICDJJ+j\n",
              "fGxEgEBrxLd9zu90Tc1sP+XHfwf3BpAf4WQCerGC81gFAIAA3EKA1zwANCAAAADJAZ8PdEP/AAAD\n",
              "AAADAAADAavkm2PmFaADtLssuSxCsFaO6amJ1leKbc4GAbIRBy9BnU8FRJS0SmVw9VdKaIdjXIQ3\n",
              "fWTtVxTrv+XQx52NXCbx6svus5qpzouikRVaJJnFkXLUQS/GfOOHVXdlSTwdte2xt4GnIDpcIUir\n",
              "l7K6E/vjV2mI3BvwKQG5Vr0DF1M+uv56VS7dyTkjFSdt1TxkLlN+txLzOIVWDjG3U7kWVErsZOhL\n",
              "9B/yoOtjAElZWbb+sAABHQD7AAesAAAAXAGfEWpD/wAAAwAAAwAAAwGr5JqTYuB/YNyQAOhIE8nT\n",
              "+Dp7b7KqlmSG8v2cJKMJetzHex+TnA5joXWfpky8tIIllgYc/JtXq/vPGiun4A78xhwmQAAGbdSw\n",
              "AHrBAAAATUGbE0moQWiZTAgl//61KoAAAAMAAAMAACMlq4QwzKCaoAJRnJACvRqWQIsp7Dz/7MVs\n",
              "SBfSkGkNgH367GzlmAGTcRjWsAAAAwAAAwKGAAAAbUGbNUnhClJlMFESwS/+tSqAAAADAAADAAAi\n",
              "PX/fwNBeAKABM/Mf8/KWf8geXFXvbL7uYlABmGyydWJJuwjKmiA6At6MVi7Gop9rQOux6ZxAeYoM\n",
              "hZGdjCBjGS7Cr5+LnDAAAAMAAAMAAAMAlYAAAABpAZ9UakP/AAADAAADAAADAavkn5bQC4yYmjD5\n",
              "oALswnNTGzEVs4R/+//cMivJQbMGlJ9NlzOCpQTDOTJB/3dkHubXMgXQHyN+gXRz845B8BuE1cvM\n",
              "BMrtp8UHAACiA9+A++3sEVooAPyBAAAAMEGbVknhDomUwIJf/rUqgAAAAwAAAwAAIRSHZ5aapeGI\n",
              "X/UkmAAAAwAAAwAAAwA1IAAAADpBm3dJ4Q8mUwIJf/61KoAAAAMAAAMAACElq4QwzKCap9gzH2sA\n",
              "JnQ/5HpxKIb4YAAAAwAAAwAAAwGrAAAAMkGbmUnhDyZTBRE8Ev/+tSqAAAADAAADAAAgP2MWklfK\n",
              "rmT5U3KkAAADAAADAAADAD7hAAAANQGfuGpD/wAAAwAAAwAAAwGr5J+TTHpOMUBDCSYFK7vpAwoC\n",
              "FdYiIWgAFWR/QL9kmCsWAAZ8AAAALkGbuknhDyZTAgn//rUqgAAAAwAAAwAAiD1AogsercX+rAvA\n",
              "AAADAAADAAADA9MAAAAzQZvcSeEPJlMFETwT//61KoAAAAMAAAMAAlOTlcLt/y12DXDvCVX8AAAD\n",
              "AAADAAADAAYEAAAAMwGf+2pD/wAAAwAAAwAABm/HeDoM33LpMIetULsyTaCqAcukDvRMAAqzA4B5\n",
              "1zwVkYABewAAAF5Bm/5J4Q8mUwU8E//+tSqAAAADAAADAAoH6lw/BXaqkUAE053gloJz7b70U0xs\n",
              "+s3e/9mgU4bsjOEnPzxhf1mxLvS8zzE3Z88TFcOuNLsPs08gAAADAAADAAADAA7pAAAASgGeHWpD\n",
              "/wAAAwAAAwAAG58dwBEslfAAHJkAACB/YUVPLGIALnpBG0wg9Y3yy1bMQqfnc7zi+Acs3hf6kgAE\n",
              "VjRwEamJQqEFABewAAAAOkGaAEnhDyZTBTwT//61KoAAAAMAAAMAK4bR0eCuKeZA1bmf+ITy/PK+\n",
              "D33r+AAAAwAAAwAAAwAApIAAAABLAZ4/akP/AAADAAADAAB2ux6QEvua2je3wAe3nMaZ94d+Clra\n",
              "4a2r4Cwbwk3L//7sQLMynJ937wEiekL8zIAAdZNtAfd4iDoBQAK/AAAAL0GaI0nhDyZTAgl//rUq\n",
              "gAAAAwAAAwC7myfxERTvepn/keQAAAMAAAMAAAMAABnwAAAANkGeQUURPBD/AAADAAADAADn39yI\n",
              "hVqZTxDf2/UaOnmM8l94CRPMdk8wAFD/zQL9IEiWpZgIOQAAACsBnmJqQ/8AAAMAAAMAAfvZpvoO\n",
              "NDWmCCksWNUrZwElT84RGAABJQwAACDgAAAAMkGaZUmoQWiZTBTwS//+tSqAAAADAAADAynMkxER\n",
              "Q9+3QDaI9/AAAAMAAAMAAAMAABFxAAAAMQGehGpD/wAAAwAAAwAIq7t5kc58uTA5kUOcdZso1uNg\n",
              "JKwshAAAvgAAO3CAeNIAOOEAAABEQZqHSeEKUmUwUsEv/rUqgAAAAwAADaQlE3lKAAt7dI2kMMYM\n",
              "5ajLb4wO28g0SjZfrAl/9tP4AAADAAADAAADAAADAf8AAAA2AZ6makP/AAADAAADACWnbVZ7Mr1B\n",
              "8f7O8wOnEYTLoLBs9IAHbMlPQ9AAQLO+AjXBcFcboAVtAAAASkGaqUnhDomUwUTBL/61KoAAAAMA\n",
              "ADpId3D8rxRweo2AF0gvv/f9P4kX/HlJpJn5Io9Ufe1ysCnqZ4+YfkAAAAMAAAMAAAMAAAUkAAAA\n",
              "VwGeyGpD/wAAAwAAAwCjm/c6gByNkbABzaIlWPhsRa11pbkilf98Dmi0eLE16hTi5AXZbkB08/Zv\n",
              "104f3EHPss5Pu/eAkT0hfmZAADrJtoD7vEQdAKABgwAAADxBmstJ4Q8mUwU8Ev/+tSqAAAADAAQB\n",
              "xiIBQ5Q0X+qHNIExUD/1rcp+14Z/g/gAAAMAAAMAAAMAAAMAJGEAAAA0AZ7qakP/AAADAAADAsSP\n",
              "uCNjKPP+N0c26Tb7B7JyYm8BIpkQ44IAB2dJwDzlTgrHQADpgAAAAD5BmuxJ4Q8mUwIJ//61KoAA\n",
              "AAMABEHHgl9R+do73PQzuF6rRKNWXryM0YA5X78/gAAAAwAAAwAAAwAAAwBnwAAAAEVBmw9J4Q8m\n",
              "UwIJf/61KoAAAAMABEe5ADvQsHY0SyRxZMeCnmMvBtXzZ8iKSjYmoej+H62kSwAAAwAAAwAAAwAA\n",
              "AwAAaEEAAAA8QZ8tRRE8EP8AAAMAAAWK0LY/HOexTtoAa2fkON9ADwV/aaL2QRNGt4CRHovq0wAD\n",
              "sqp4HhpDBLT8AFfBAAAAKwGfTmpD/wAAAwAADD5nD4UkImMWKUrACYtPRfb0ABpby9ksAABqBoAA\n",
              "EHEAAABMQZtRSahBaJlMFPBL//61KoAAAAMABCGiSveNKDiADdxyll388PhxwOCec9x+Pzarb1Hw\n",
              "SM/CH3S4ct+pgAAAAwAAAwAAAwAAAwBHwAAAADUBn3BqQ/8AAAMAAAvPJNiO4q2uyh3betqR3wAn\n",
              "M1M/CNbV5LwElsJ2AAAyGgAcKsBM8wAlYAAAAGpBm3NJ4QpSZTBSwR/+tSqAAAADAAQn7NjKHps4\n",
              "wArmNv///KS8B4oSTcnq6OPfCTQd801htky3XVefHYzH0nGSBIAa7Yii2aMqJR/WM8XYsEPvMx9j\n",
              "nDqKg8uAAAADAAADAAADAAADAAdNAAAAYQGfkmpD/wAAAwAAC88k1JQEnSZgWAEIKEfa1sKKncNR\n",
              "oYMN+itUtMk5vj+Xb9Jxxt6Bgr6c8Hm8w/j+YpKPpRiAoAs78+wskgTOZ3tgAs8xPNw+AAPB8AAR\n",
              "qPlCs6AAFlAAAAA0QZuUSeEOiZTAgj/+tSqAAAADAAQBFxCOlnB511R8M0oAMeT2IAAAAwAAAwAA\n",
              "AwAAAwAI+AAAAGRBm7VJ4Q8mUwII//61KoAAAAMAA+e8pTDZ75LgAZX5Jeqg0avHfZF969VGbB4B\n",
              "gDUh6LplLG5oySYXSKP7UPZ0lHnqAainjfs6RJm+MRqjX4DVmXPAAAADAAADAAADAAADABLxAAAA\n",
              "qkGb10nhDyZTBRE8P//+qZYAAAMAAB6vdF19kAAuUjd/GHVNMWqF0vYmU06SM1fJYKC694MXEyaU\n",
              "xC5qh6c4xY0LQ7H8rXF1jHVDoBe2avUOr/tvPmV51QWdwMzTxC9NbbeUgA4yC0mHDm1LC4t3AldK\n",
              "DadurPy6Kc0Uvz49o60arh0a1PtB4z62+bt0tFV4lbqtjokVc/9eVbKMAAADAAADAAADAAADAAGV\n",
              "AAAAdwGf9mpD/wAAAwAAC88lNvBSEbrRABtIpmr4cxBywrcIP+Boq3d4IJPW70dH6YY2c5zMfVqp\n",
              "z4XOw5T49mYR/M/TU8MrIpg/ujiedX1IEtCWi5HmvkI6KiBJkj+kx+a6Nj1MAA+6RPJEogAMbk5Q\n",
              "OGSYBa2wAGzBAAAIBG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAF3AAAEAAAEAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAIAAAcudHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAF3AAAAAAAAA\n",
              "AAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAOEAAADhAAAAAAA\n",
              "JGVkdHMAAAAcZWxzdAAAAAAAAAABAABdwAAAEAAAAQAAAAAGpm1kaWEAAAAgbWRoZAAAAAAAAAAA\n",
              "AAAAAAAAKAAAA8AAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5k\n",
              "bGVyAAAABlFtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEA\n",
              "AAAMdXJsIAAAAAEAAAYRc3RibAAAALlzdHNkAAAAAAAAAAEAAACpYXZjMQAAAAAAAAABAAAAAAAA\n",
              "AAAAAAAAAAAAAAOEA4QASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAABj//wAAADdhdmNDAWQAH//hABpnZAAfrNlA5Bz554QAAAMABAAAAwAoPGDGWAEABmjr48si\n",
              "wP34+AAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAHgAAAgA\n",
              "AAAAFHN0c3MAAAAAAAAAAQAAAAEAAAMAY3R0cwAAAAAAAABeAAAAAQAAEAAAAAABAAAYAAAAAAEA\n",
              "AAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAABAAAQAAAAAAEAABgAAAAAAQAA\n",
              "CAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAAPAAAQ\n",
              "AAAAAAEAABgAAAAAAQAACAAAAAACAAAQAAAAAAEAABgAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgA\n",
              "AAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAAGAAAQAAAAAAEAACAAAAAAAgAACAAA\n",
              "AAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAABAAAQAAAA\n",
              "AAEAABgAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAA\n",
              "AQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAAB\n",
              "AAAgAAAAAAIAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABAAAAAAAQAAKAAAAAABAAAQAAAAAAEA\n",
              "AAAAAAAAAQAACAAAAAABAAAQAAAAAAEAABgAAAAAAQAACAAAAAACAAAQAAAAAAEAABgAAAAAAQAA\n",
              "CAAAAAABAAAQAAAAAAEAABgAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAI\n",
              "AAAAAAEAACAAAAAAAgAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgA\n",
              "AAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAEAAAAAABAAAgAAAAAAIAAAgAAAAAAQAAGAAA\n",
              "AAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAACAAAQAAAAAAEAABgAAAAAAQAACAAAAAAcc3RzYwAA\n",
              "AAAAAAABAAAAAQAAAHgAAAABAAAB9HN0c3oAAAAAAAAAAAAAAHgAADqMAAAAsAAAAD4AAABzAAAA\n",
              "SwAAAGwAAABXAAAANAAAAE4AAAA8AAAAOwAAADsAAABZAAAAPQAAAGQAAABiAAAAOAAAADUAAAA7\n",
              "AAAANgAAADsAAAA2AAAASgAAAE8AAABkAAAAUgAAAGIAAAA2AAAAPwAAADgAAABOAAAASQAAADYA\n",
              "AABbAAAAawAAAEAAAAA4AAAAOgAAADcAAAA/AAAAOAAAAD8AAAA4AAAAVQAAAGYAAABaAAAAVQAA\n",
              "AEMAAABGAAAAQgAAAD0AAAAtAAAAZQAAADUAAABYAAAAYAAAADsAAAA4AAAANwAAADYAAAA3AAAA\n",
              "PwAAADoAAAB3AAAAUwAAADoAAABdAAAAOQAAADwAAAA3AAAAPAAAAE4AAAA6AAAAQQAAAF8AAABZ\n",
              "AAAAegAAAEcAAADZAAAAwgAAAMAAAADNAAAAYAAAAFEAAABxAAAAbQAAADQAAAA+AAAANgAAADkA\n",
              "AAAyAAAANwAAADcAAABiAAAATgAAAD4AAABPAAAAMwAAADoAAAAvAAAANgAAADUAAABIAAAAOgAA\n",
              "AE4AAABbAAAAQAAAADgAAABCAAAASQAAAEAAAAAvAAAAUAAAADkAAABuAAAAZQAAADgAAABoAAAA\n",
              "rgAAAHsAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAA\n",
              "AAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZm\n",
              "NTguNzYuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}